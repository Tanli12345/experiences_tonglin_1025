{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e655e345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ÊàêÂäüËÆæÁΩÆ‰∏≠ÊñáÂ≠ó‰Ωì: ['WenQuanYi Micro Hei']\n",
      "================================================================================\n",
      "üöÄ ÂºÄÂßãËÆ≠ÁªÉ MCLDNN Âπ≤Êâ∞ÂàÜÁ±ªÊ®°Âûã\n",
      "================================================================================\n",
      "‚è≥ Âä†ËΩΩÊï∞ÊçÆÈõÜ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 20:13:30.786106: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-10-21 20:13:30.788660: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-10-21 20:13:30.789541: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-10-21 20:13:30.905899: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-10-21 20:13:30.906791: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-10-21 20:13:30.907613: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üî• ËÆ≠ÁªÉ MCLDNN Ê®°Âûã 1...\n",
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 20:13:32.328606: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [56700,1024,1]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-10-21 20:13:32.328867: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [56700,1024,1]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2025-10-21 20:13:32.555584: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-10-21 20:13:32.556889: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-10-21 20:13:32.557742: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-10-21 20:13:32.673796: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-10-21 20:13:32.674759: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-10-21 20:13:32.675766: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-10-21 20:13:34.153225: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-10-21 20:13:34.154791: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-10-21 20:13:34.155635: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-10-21 20:13:34.261544: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-10-21 20:13:34.262398: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-10-21 20:13:34.263239: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-10-21 20:13:36.130125: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2025-10-21 20:13:36.726817: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-10-21 20:13:36.777341: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f34d97a1da0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-10-21 20:13:36.777392: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA vGPU-48GB, Compute Capability 8.9\n",
      "2025-10-21 20:13:36.784192: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-10-21 20:13:36.926801: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "443/443 [==============================] - ETA: 0s - loss: 1.7770 - sparse_categorical_accuracy: 0.3388"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 20:14:40.176986: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [12150,1024,1]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-10-21 20:14:40.177198: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_3' with dtype int32 and shape [12150]\n",
      "\t [[{{node Placeholder/_3}}]]\n",
      "2025-10-21 20:14:40.481266: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-10-21 20:14:40.482563: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-10-21 20:14:40.483367: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-10-21 20:14:40.593227: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-10-21 20:14:40.594085: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-10-21 20:14:40.594861: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "443/443 [==============================] - 74s 151ms/step - loss: 1.7770 - sparse_categorical_accuracy: 0.3388 - val_loss: 1.5238 - val_sparse_categorical_accuracy: 0.4151 - lr: 0.0010\n",
      "Epoch 2/120\n",
      "443/443 [==============================] - 67s 149ms/step - loss: 1.4974 - sparse_categorical_accuracy: 0.4367 - val_loss: 1.4475 - val_sparse_categorical_accuracy: 0.4474 - lr: 0.0010\n",
      "Epoch 3/120\n",
      "443/443 [==============================] - 66s 148ms/step - loss: 1.3949 - sparse_categorical_accuracy: 0.4679 - val_loss: 1.3052 - val_sparse_categorical_accuracy: 0.4926 - lr: 0.0010\n",
      "Epoch 4/120\n",
      "443/443 [==============================] - 65s 146ms/step - loss: 1.2778 - sparse_categorical_accuracy: 0.5063 - val_loss: 1.1578 - val_sparse_categorical_accuracy: 0.5434 - lr: 0.0010\n",
      "Epoch 5/120\n",
      "443/443 [==============================] - 65s 147ms/step - loss: 1.2501 - sparse_categorical_accuracy: 0.5244 - val_loss: 1.1804 - val_sparse_categorical_accuracy: 0.5507 - lr: 0.0010\n",
      "Epoch 6/120\n",
      "443/443 [==============================] - 65s 146ms/step - loss: 1.1355 - sparse_categorical_accuracy: 0.5663 - val_loss: 0.9632 - val_sparse_categorical_accuracy: 0.6086 - lr: 0.0010\n",
      "Epoch 7/120\n",
      "443/443 [==============================] - 66s 148ms/step - loss: 1.0314 - sparse_categorical_accuracy: 0.5949 - val_loss: 0.9387 - val_sparse_categorical_accuracy: 0.6197 - lr: 0.0010\n",
      "Epoch 8/120\n",
      "443/443 [==============================] - 66s 148ms/step - loss: 1.0443 - sparse_categorical_accuracy: 0.5932 - val_loss: 0.9491 - val_sparse_categorical_accuracy: 0.6158 - lr: 0.0010\n",
      "Epoch 9/120\n",
      "443/443 [==============================] - 65s 146ms/step - loss: 0.9922 - sparse_categorical_accuracy: 0.6075 - val_loss: 0.9354 - val_sparse_categorical_accuracy: 0.6192 - lr: 0.0010\n",
      "Epoch 10/120\n",
      "443/443 [==============================] - 66s 148ms/step - loss: 0.9486 - sparse_categorical_accuracy: 0.6224 - val_loss: 0.8797 - val_sparse_categorical_accuracy: 0.6345 - lr: 0.0010\n",
      "Epoch 11/120\n",
      "443/443 [==============================] - 65s 147ms/step - loss: 0.8986 - sparse_categorical_accuracy: 0.6340 - val_loss: 0.8744 - val_sparse_categorical_accuracy: 0.6365 - lr: 0.0010\n",
      "Epoch 12/120\n",
      "443/443 [==============================] - 65s 146ms/step - loss: 0.8851 - sparse_categorical_accuracy: 0.6397 - val_loss: 0.8164 - val_sparse_categorical_accuracy: 0.6514 - lr: 0.0010\n",
      "Epoch 13/120\n",
      "443/443 [==============================] - 66s 148ms/step - loss: 0.8438 - sparse_categorical_accuracy: 0.6502 - val_loss: 0.7962 - val_sparse_categorical_accuracy: 0.6543 - lr: 0.0010\n",
      "Epoch 14/120\n",
      "443/443 [==============================] - 66s 147ms/step - loss: 0.8316 - sparse_categorical_accuracy: 0.6535 - val_loss: 0.7771 - val_sparse_categorical_accuracy: 0.6627 - lr: 0.0010\n",
      "Epoch 15/120\n",
      "443/443 [==============================] - 66s 147ms/step - loss: 0.8174 - sparse_categorical_accuracy: 0.6578 - val_loss: 0.7551 - val_sparse_categorical_accuracy: 0.6725 - lr: 0.0010\n",
      "Epoch 16/120\n",
      "443/443 [==============================] - 65s 146ms/step - loss: 0.7929 - sparse_categorical_accuracy: 0.6648 - val_loss: 0.7474 - val_sparse_categorical_accuracy: 0.6762 - lr: 0.0010\n",
      "Epoch 17/120\n",
      "443/443 [==============================] - 65s 147ms/step - loss: 0.7796 - sparse_categorical_accuracy: 0.6674 - val_loss: 0.7266 - val_sparse_categorical_accuracy: 0.6803 - lr: 0.0010\n",
      "Epoch 18/120\n",
      "443/443 [==============================] - 64s 145ms/step - loss: 0.7605 - sparse_categorical_accuracy: 0.6753 - val_loss: 0.7247 - val_sparse_categorical_accuracy: 0.6857 - lr: 0.0010\n",
      "Epoch 19/120\n",
      "443/443 [==============================] - 65s 146ms/step - loss: 0.7610 - sparse_categorical_accuracy: 0.6777 - val_loss: 0.7153 - val_sparse_categorical_accuracy: 0.6956 - lr: 0.0010\n",
      "Epoch 20/120\n",
      "443/443 [==============================] - 65s 145ms/step - loss: 0.7448 - sparse_categorical_accuracy: 0.6834 - val_loss: 0.6852 - val_sparse_categorical_accuracy: 0.7018 - lr: 0.0010\n",
      "Epoch 21/120\n",
      "443/443 [==============================] - 65s 147ms/step - loss: 0.7317 - sparse_categorical_accuracy: 0.6891 - val_loss: 0.7147 - val_sparse_categorical_accuracy: 0.6924 - lr: 0.0010\n",
      "Epoch 22/120\n",
      "443/443 [==============================] - 65s 146ms/step - loss: 0.7173 - sparse_categorical_accuracy: 0.6944 - val_loss: 0.6749 - val_sparse_categorical_accuracy: 0.7072 - lr: 0.0010\n",
      "Epoch 23/120\n",
      "443/443 [==============================] - 65s 146ms/step - loss: 0.7112 - sparse_categorical_accuracy: 0.6981 - val_loss: 0.6826 - val_sparse_categorical_accuracy: 0.7068 - lr: 0.0010\n",
      "Epoch 24/120\n",
      "443/443 [==============================] - 66s 148ms/step - loss: 0.6948 - sparse_categorical_accuracy: 0.7044 - val_loss: 0.6762 - val_sparse_categorical_accuracy: 0.7055 - lr: 0.0010\n",
      "Epoch 25/120\n",
      "443/443 [==============================] - 64s 144ms/step - loss: 0.6884 - sparse_categorical_accuracy: 0.7082 - val_loss: 0.6374 - val_sparse_categorical_accuracy: 0.7155 - lr: 0.0010\n",
      "Epoch 26/120\n",
      "443/443 [==============================] - 64s 144ms/step - loss: 0.6669 - sparse_categorical_accuracy: 0.7146 - val_loss: 0.6439 - val_sparse_categorical_accuracy: 0.7206 - lr: 0.0010\n",
      "Epoch 27/120\n",
      "443/443 [==============================] - 66s 148ms/step - loss: 0.6666 - sparse_categorical_accuracy: 0.7178 - val_loss: 0.6283 - val_sparse_categorical_accuracy: 0.7294 - lr: 0.0010\n",
      "Epoch 28/120\n",
      "443/443 [==============================] - 65s 146ms/step - loss: 0.6459 - sparse_categorical_accuracy: 0.7245 - val_loss: 0.6340 - val_sparse_categorical_accuracy: 0.7283 - lr: 0.0010\n",
      "Epoch 29/120\n",
      "443/443 [==============================] - 65s 146ms/step - loss: 0.6319 - sparse_categorical_accuracy: 0.7331 - val_loss: 0.5992 - val_sparse_categorical_accuracy: 0.7420 - lr: 0.0010\n",
      "Epoch 30/120\n",
      "443/443 [==============================] - 66s 148ms/step - loss: 0.6261 - sparse_categorical_accuracy: 0.7368 - val_loss: 0.5873 - val_sparse_categorical_accuracy: 0.7489 - lr: 0.0010\n",
      "Epoch 31/120\n",
      "443/443 [==============================] - 65s 145ms/step - loss: 0.6039 - sparse_categorical_accuracy: 0.7437 - val_loss: 0.5850 - val_sparse_categorical_accuracy: 0.7481 - lr: 0.0010\n",
      "Epoch 32/120\n",
      "443/443 [==============================] - 65s 147ms/step - loss: 0.5936 - sparse_categorical_accuracy: 0.7469 - val_loss: 0.5620 - val_sparse_categorical_accuracy: 0.7588 - lr: 0.0010\n",
      "Epoch 33/120\n",
      "443/443 [==============================] - 66s 148ms/step - loss: 0.5879 - sparse_categorical_accuracy: 0.7522 - val_loss: 0.5688 - val_sparse_categorical_accuracy: 0.7564 - lr: 0.0010\n",
      "Epoch 34/120\n",
      "443/443 [==============================] - 66s 148ms/step - loss: 0.5780 - sparse_categorical_accuracy: 0.7524 - val_loss: 0.5455 - val_sparse_categorical_accuracy: 0.7611 - lr: 0.0010\n",
      "Epoch 35/120\n",
      "443/443 [==============================] - 65s 146ms/step - loss: 0.5703 - sparse_categorical_accuracy: 0.7575 - val_loss: 0.5493 - val_sparse_categorical_accuracy: 0.7636 - lr: 0.0010\n",
      "Epoch 36/120\n",
      "443/443 [==============================] - 65s 147ms/step - loss: 0.5607 - sparse_categorical_accuracy: 0.7614 - val_loss: 0.5434 - val_sparse_categorical_accuracy: 0.7663 - lr: 0.0010\n",
      "Epoch 37/120\n",
      "443/443 [==============================] - 65s 146ms/step - loss: 0.5585 - sparse_categorical_accuracy: 0.7608 - val_loss: 0.5294 - val_sparse_categorical_accuracy: 0.7705 - lr: 0.0010\n",
      "Epoch 38/120\n",
      "443/443 [==============================] - 65s 146ms/step - loss: 0.5505 - sparse_categorical_accuracy: 0.7626 - val_loss: 0.5342 - val_sparse_categorical_accuracy: 0.7691 - lr: 0.0010\n",
      "Epoch 39/120\n",
      "443/443 [==============================] - 65s 145ms/step - loss: 0.5474 - sparse_categorical_accuracy: 0.7669 - val_loss: 0.5228 - val_sparse_categorical_accuracy: 0.7688 - lr: 0.0010\n",
      "Epoch 40/120\n",
      "443/443 [==============================] - 65s 146ms/step - loss: 0.5340 - sparse_categorical_accuracy: 0.7698 - val_loss: 0.5187 - val_sparse_categorical_accuracy: 0.7725 - lr: 0.0010\n",
      "Epoch 41/120\n",
      "443/443 [==============================] - 65s 147ms/step - loss: 0.5347 - sparse_categorical_accuracy: 0.7677 - val_loss: 0.5406 - val_sparse_categorical_accuracy: 0.7649 - lr: 0.0010\n",
      "Epoch 42/120\n",
      "443/443 [==============================] - 65s 147ms/step - loss: 0.5355 - sparse_categorical_accuracy: 0.7714 - val_loss: 0.5260 - val_sparse_categorical_accuracy: 0.7725 - lr: 0.0010\n",
      "Epoch 43/120\n",
      "443/443 [==============================] - 64s 143ms/step - loss: 0.5209 - sparse_categorical_accuracy: 0.7734 - val_loss: 0.5120 - val_sparse_categorical_accuracy: 0.7759 - lr: 0.0010\n",
      "Epoch 44/120\n",
      "443/443 [==============================] - 64s 143ms/step - loss: 0.5197 - sparse_categorical_accuracy: 0.7756 - val_loss: 0.5036 - val_sparse_categorical_accuracy: 0.7751 - lr: 0.0010\n",
      "Epoch 45/120\n",
      "443/443 [==============================] - 65s 146ms/step - loss: 0.5195 - sparse_categorical_accuracy: 0.7727 - val_loss: 0.5152 - val_sparse_categorical_accuracy: 0.7713 - lr: 0.0010\n",
      "Epoch 46/120\n",
      "443/443 [==============================] - 65s 147ms/step - loss: 0.5136 - sparse_categorical_accuracy: 0.7759 - val_loss: 0.5016 - val_sparse_categorical_accuracy: 0.7818 - lr: 0.0010\n",
      "Epoch 47/120\n",
      "443/443 [==============================] - 65s 146ms/step - loss: 0.5196 - sparse_categorical_accuracy: 0.7741 - val_loss: 0.4939 - val_sparse_categorical_accuracy: 0.7793 - lr: 0.0010\n",
      "Epoch 48/120\n",
      "443/443 [==============================] - 65s 146ms/step - loss: 0.5126 - sparse_categorical_accuracy: 0.7748 - val_loss: 0.5067 - val_sparse_categorical_accuracy: 0.7762 - lr: 0.0010\n",
      "Epoch 49/120\n",
      "443/443 [==============================] - 65s 146ms/step - loss: 0.5041 - sparse_categorical_accuracy: 0.7774 - val_loss: 0.4886 - val_sparse_categorical_accuracy: 0.7838 - lr: 0.0010\n",
      "Epoch 50/120\n",
      "443/443 [==============================] - 65s 147ms/step - loss: 0.5039 - sparse_categorical_accuracy: 0.7769 - val_loss: 0.4820 - val_sparse_categorical_accuracy: 0.7830 - lr: 0.0010\n",
      "Epoch 51/120\n",
      "443/443 [==============================] - 65s 147ms/step - loss: 0.4979 - sparse_categorical_accuracy: 0.7834 - val_loss: 0.4929 - val_sparse_categorical_accuracy: 0.7804 - lr: 0.0010\n",
      "Epoch 52/120\n",
      "443/443 [==============================] - 66s 148ms/step - loss: 0.4966 - sparse_categorical_accuracy: 0.7808 - val_loss: 0.5241 - val_sparse_categorical_accuracy: 0.7757 - lr: 0.0010\n",
      "Epoch 53/120\n",
      "443/443 [==============================] - 65s 147ms/step - loss: 0.4931 - sparse_categorical_accuracy: 0.7793 - val_loss: 0.4807 - val_sparse_categorical_accuracy: 0.7840 - lr: 0.0010\n",
      "Epoch 54/120\n",
      "443/443 [==============================] - 66s 148ms/step - loss: 0.4899 - sparse_categorical_accuracy: 0.7830 - val_loss: 0.5158 - val_sparse_categorical_accuracy: 0.7762 - lr: 0.0010\n",
      "Epoch 55/120\n",
      "443/443 [==============================] - 66s 148ms/step - loss: 0.4840 - sparse_categorical_accuracy: 0.7862 - val_loss: 0.4797 - val_sparse_categorical_accuracy: 0.7832 - lr: 0.0010\n",
      "Epoch 56/120\n",
      "443/443 [==============================] - 66s 148ms/step - loss: 0.4837 - sparse_categorical_accuracy: 0.7854 - val_loss: 0.4748 - val_sparse_categorical_accuracy: 0.7895 - lr: 0.0010\n",
      "Epoch 57/120\n",
      "443/443 [==============================] - 65s 146ms/step - loss: 0.4886 - sparse_categorical_accuracy: 0.7856 - val_loss: 0.4696 - val_sparse_categorical_accuracy: 0.7870 - lr: 0.0010\n",
      "Epoch 58/120\n",
      "443/443 [==============================] - 65s 147ms/step - loss: 0.4753 - sparse_categorical_accuracy: 0.7910 - val_loss: 0.4700 - val_sparse_categorical_accuracy: 0.7951 - lr: 0.0010\n",
      "Epoch 59/120\n",
      "443/443 [==============================] - 65s 146ms/step - loss: 0.4770 - sparse_categorical_accuracy: 0.7909 - val_loss: 0.4705 - val_sparse_categorical_accuracy: 0.7949 - lr: 0.0010\n",
      "Epoch 60/120\n",
      "443/443 [==============================] - 66s 148ms/step - loss: 0.4741 - sparse_categorical_accuracy: 0.7933 - val_loss: 0.4719 - val_sparse_categorical_accuracy: 0.7969 - lr: 0.0010\n",
      "Epoch 61/120\n",
      "443/443 [==============================] - 64s 145ms/step - loss: 0.4674 - sparse_categorical_accuracy: 0.7971 - val_loss: 0.4840 - val_sparse_categorical_accuracy: 0.7963 - lr: 0.0010\n",
      "Epoch 62/120\n",
      "443/443 [==============================] - 65s 146ms/step - loss: 0.4668 - sparse_categorical_accuracy: 0.8008 - val_loss: 0.4741 - val_sparse_categorical_accuracy: 0.7914 - lr: 0.0010\n",
      "Epoch 63/120\n",
      "443/443 [==============================] - 65s 146ms/step - loss: 0.4721 - sparse_categorical_accuracy: 0.7994 - val_loss: 0.4642 - val_sparse_categorical_accuracy: 0.8049 - lr: 0.0010\n",
      "Epoch 64/120\n",
      "443/443 [==============================] - 64s 144ms/step - loss: 0.4616 - sparse_categorical_accuracy: 0.8040 - val_loss: 0.4690 - val_sparse_categorical_accuracy: 0.8036 - lr: 0.0010\n",
      "Epoch 65/120\n",
      "443/443 [==============================] - 59s 132ms/step - loss: 0.4554 - sparse_categorical_accuracy: 0.8078 - val_loss: 0.4575 - val_sparse_categorical_accuracy: 0.8100 - lr: 0.0010\n",
      "Epoch 66/120\n",
      "443/443 [==============================] - 43s 96ms/step - loss: 0.4557 - sparse_categorical_accuracy: 0.8087 - val_loss: 0.4540 - val_sparse_categorical_accuracy: 0.8097 - lr: 0.0010\n",
      "Epoch 67/120\n",
      "443/443 [==============================] - 45s 102ms/step - loss: 0.4529 - sparse_categorical_accuracy: 0.8114 - val_loss: 0.4552 - val_sparse_categorical_accuracy: 0.8111 - lr: 0.0010\n",
      "Epoch 68/120\n",
      "443/443 [==============================] - 59s 134ms/step - loss: 0.4461 - sparse_categorical_accuracy: 0.8162 - val_loss: 0.4697 - val_sparse_categorical_accuracy: 0.8127 - lr: 0.0010\n",
      "Epoch 69/120\n",
      "443/443 [==============================] - 65s 146ms/step - loss: 0.4455 - sparse_categorical_accuracy: 0.8178 - val_loss: 0.4549 - val_sparse_categorical_accuracy: 0.8154 - lr: 0.0010\n",
      "Epoch 70/120\n",
      "443/443 [==============================] - 64s 144ms/step - loss: 0.4373 - sparse_categorical_accuracy: 0.8191 - val_loss: 0.4463 - val_sparse_categorical_accuracy: 0.8197 - lr: 0.0010\n",
      "Epoch 71/120\n",
      "443/443 [==============================] - 65s 147ms/step - loss: 0.4408 - sparse_categorical_accuracy: 0.8205 - val_loss: 0.4409 - val_sparse_categorical_accuracy: 0.8182 - lr: 0.0010\n",
      "Epoch 72/120\n",
      "443/443 [==============================] - 65s 146ms/step - loss: 0.4374 - sparse_categorical_accuracy: 0.8198 - val_loss: 0.4477 - val_sparse_categorical_accuracy: 0.8127 - lr: 0.0010\n",
      "Epoch 73/120\n",
      "443/443 [==============================] - 65s 145ms/step - loss: 0.4361 - sparse_categorical_accuracy: 0.8229 - val_loss: 0.4564 - val_sparse_categorical_accuracy: 0.8166 - lr: 0.0010\n",
      "Epoch 74/120\n",
      "443/443 [==============================] - 66s 147ms/step - loss: 0.4328 - sparse_categorical_accuracy: 0.8224 - val_loss: 0.4337 - val_sparse_categorical_accuracy: 0.8277 - lr: 0.0010\n",
      "Epoch 75/120\n",
      "443/443 [==============================] - 65s 146ms/step - loss: 0.4288 - sparse_categorical_accuracy: 0.8258 - val_loss: 0.4325 - val_sparse_categorical_accuracy: 0.8239 - lr: 0.0010\n",
      "Epoch 76/120\n",
      "443/443 [==============================] - 65s 146ms/step - loss: 0.4350 - sparse_categorical_accuracy: 0.8239 - val_loss: 0.4595 - val_sparse_categorical_accuracy: 0.8177 - lr: 0.0010\n",
      "Epoch 77/120\n",
      "443/443 [==============================] - 65s 147ms/step - loss: 0.4276 - sparse_categorical_accuracy: 0.8257 - val_loss: 0.4221 - val_sparse_categorical_accuracy: 0.8319 - lr: 0.0010\n",
      "Epoch 78/120\n",
      "443/443 [==============================] - 65s 146ms/step - loss: 0.4293 - sparse_categorical_accuracy: 0.8268 - val_loss: 0.4198 - val_sparse_categorical_accuracy: 0.8301 - lr: 0.0010\n",
      "Epoch 79/120\n",
      "443/443 [==============================] - 65s 146ms/step - loss: 0.4237 - sparse_categorical_accuracy: 0.8273 - val_loss: 0.4327 - val_sparse_categorical_accuracy: 0.8245 - lr: 0.0010\n",
      "Epoch 80/120\n",
      "443/443 [==============================] - 65s 147ms/step - loss: 0.4217 - sparse_categorical_accuracy: 0.8292 - val_loss: 0.4392 - val_sparse_categorical_accuracy: 0.8255 - lr: 0.0010\n",
      "Epoch 81/120\n",
      "443/443 [==============================] - 65s 146ms/step - loss: 0.4178 - sparse_categorical_accuracy: 0.8299 - val_loss: 0.4339 - val_sparse_categorical_accuracy: 0.8281 - lr: 0.0010\n",
      "Epoch 82/120\n",
      "443/443 [==============================] - 65s 145ms/step - loss: 0.4148 - sparse_categorical_accuracy: 0.8325 - val_loss: 0.4240 - val_sparse_categorical_accuracy: 0.8255 - lr: 0.0010\n",
      "Epoch 83/120\n",
      "443/443 [==============================] - 65s 145ms/step - loss: 0.4149 - sparse_categorical_accuracy: 0.8344 - val_loss: 0.4147 - val_sparse_categorical_accuracy: 0.8317 - lr: 0.0010\n",
      "Epoch 84/120\n",
      "443/443 [==============================] - 65s 146ms/step - loss: 0.4131 - sparse_categorical_accuracy: 0.8322 - val_loss: 0.4221 - val_sparse_categorical_accuracy: 0.8328 - lr: 0.0010\n",
      "Epoch 85/120\n",
      "443/443 [==============================] - 65s 146ms/step - loss: 0.4086 - sparse_categorical_accuracy: 0.8362 - val_loss: 0.4451 - val_sparse_categorical_accuracy: 0.8231 - lr: 0.0010\n",
      "Epoch 86/120\n",
      "443/443 [==============================] - 66s 148ms/step - loss: 0.4095 - sparse_categorical_accuracy: 0.8351 - val_loss: 0.4034 - val_sparse_categorical_accuracy: 0.8408 - lr: 0.0010\n",
      "Epoch 87/120\n",
      "443/443 [==============================] - 65s 145ms/step - loss: 0.4076 - sparse_categorical_accuracy: 0.8371 - val_loss: 0.4296 - val_sparse_categorical_accuracy: 0.8341 - lr: 0.0010\n",
      "Epoch 88/120\n",
      "443/443 [==============================] - 65s 147ms/step - loss: 0.4162 - sparse_categorical_accuracy: 0.8357 - val_loss: 0.4150 - val_sparse_categorical_accuracy: 0.8353 - lr: 0.0010\n",
      "Epoch 89/120\n",
      "443/443 [==============================] - 65s 146ms/step - loss: 0.4054 - sparse_categorical_accuracy: 0.8373 - val_loss: 0.4139 - val_sparse_categorical_accuracy: 0.8341 - lr: 0.0010\n",
      "Epoch 90/120\n",
      "443/443 [==============================] - 65s 146ms/step - loss: 0.4002 - sparse_categorical_accuracy: 0.8386 - val_loss: 0.4042 - val_sparse_categorical_accuracy: 0.8379 - lr: 0.0010\n",
      "Epoch 91/120\n",
      "443/443 [==============================] - 65s 146ms/step - loss: 0.4018 - sparse_categorical_accuracy: 0.8385 - val_loss: 0.4205 - val_sparse_categorical_accuracy: 0.8340 - lr: 0.0010\n",
      "Epoch 92/120\n",
      "443/443 [==============================] - 65s 146ms/step - loss: 0.3988 - sparse_categorical_accuracy: 0.8416 - val_loss: 0.4024 - val_sparse_categorical_accuracy: 0.8424 - lr: 0.0010\n",
      "Epoch 93/120\n",
      "443/443 [==============================] - 65s 147ms/step - loss: 0.3943 - sparse_categorical_accuracy: 0.8428 - val_loss: 0.4130 - val_sparse_categorical_accuracy: 0.8369 - lr: 0.0010\n",
      "Epoch 94/120\n",
      "443/443 [==============================] - 64s 144ms/step - loss: 0.3997 - sparse_categorical_accuracy: 0.8423 - val_loss: 0.4188 - val_sparse_categorical_accuracy: 0.8365 - lr: 0.0010\n",
      "Epoch 95/120\n",
      "443/443 [==============================] - 65s 145ms/step - loss: 0.3998 - sparse_categorical_accuracy: 0.8426 - val_loss: 0.4351 - val_sparse_categorical_accuracy: 0.8310 - lr: 0.0010\n",
      "Epoch 96/120\n",
      "443/443 [==============================] - 64s 144ms/step - loss: 0.4028 - sparse_categorical_accuracy: 0.8369 - val_loss: 0.4120 - val_sparse_categorical_accuracy: 0.8329 - lr: 0.0010\n",
      "Epoch 97/120\n",
      "443/443 [==============================] - 65s 146ms/step - loss: 0.3936 - sparse_categorical_accuracy: 0.8426 - val_loss: 0.4052 - val_sparse_categorical_accuracy: 0.8367 - lr: 0.0010\n",
      "Epoch 98/120\n",
      "443/443 [==============================] - 64s 144ms/step - loss: 0.3869 - sparse_categorical_accuracy: 0.8452 - val_loss: 0.4150 - val_sparse_categorical_accuracy: 0.8384 - lr: 0.0010\n",
      "Epoch 99/120\n",
      "443/443 [==============================] - 65s 145ms/step - loss: 0.3859 - sparse_categorical_accuracy: 0.8468 - val_loss: 0.4257 - val_sparse_categorical_accuracy: 0.8419 - lr: 0.0010\n",
      "Epoch 100/120\n",
      "443/443 [==============================] - 64s 143ms/step - loss: 0.3947 - sparse_categorical_accuracy: 0.8435 - val_loss: 0.4137 - val_sparse_categorical_accuracy: 0.8391 - lr: 0.0010\n",
      "Epoch 101/120\n",
      "443/443 [==============================] - 64s 144ms/step - loss: 0.3881 - sparse_categorical_accuracy: 0.8440 - val_loss: 0.3975 - val_sparse_categorical_accuracy: 0.8429 - lr: 0.0010\n",
      "Epoch 102/120\n",
      "443/443 [==============================] - 64s 145ms/step - loss: 0.3847 - sparse_categorical_accuracy: 0.8484 - val_loss: 0.3987 - val_sparse_categorical_accuracy: 0.8475 - lr: 0.0010\n",
      "Epoch 103/120\n",
      "443/443 [==============================] - 65s 145ms/step - loss: 0.3850 - sparse_categorical_accuracy: 0.8476 - val_loss: 0.4015 - val_sparse_categorical_accuracy: 0.8388 - lr: 0.0010\n",
      "Epoch 104/120\n",
      "443/443 [==============================] - 65s 146ms/step - loss: 0.3958 - sparse_categorical_accuracy: 0.8468 - val_loss: 0.3919 - val_sparse_categorical_accuracy: 0.8438 - lr: 0.0010\n",
      "Epoch 105/120\n",
      "443/443 [==============================] - 65s 145ms/step - loss: 0.3841 - sparse_categorical_accuracy: 0.8492 - val_loss: 0.4233 - val_sparse_categorical_accuracy: 0.8314 - lr: 0.0010\n",
      "Epoch 106/120\n",
      "443/443 [==============================] - 65s 146ms/step - loss: 0.3808 - sparse_categorical_accuracy: 0.8481 - val_loss: 0.3857 - val_sparse_categorical_accuracy: 0.8486 - lr: 0.0010\n",
      "Epoch 107/120\n",
      "443/443 [==============================] - 65s 145ms/step - loss: 0.3800 - sparse_categorical_accuracy: 0.8483 - val_loss: 0.4106 - val_sparse_categorical_accuracy: 0.8333 - lr: 0.0010\n",
      "Epoch 108/120\n",
      "443/443 [==============================] - 64s 145ms/step - loss: 0.3810 - sparse_categorical_accuracy: 0.8493 - val_loss: 0.3954 - val_sparse_categorical_accuracy: 0.8480 - lr: 0.0010\n",
      "Epoch 109/120\n",
      "443/443 [==============================] - 65s 146ms/step - loss: 0.3768 - sparse_categorical_accuracy: 0.8518 - val_loss: 0.4189 - val_sparse_categorical_accuracy: 0.8396 - lr: 0.0010\n",
      "Epoch 110/120\n",
      "443/443 [==============================] - 65s 145ms/step - loss: 0.3854 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.4084 - val_sparse_categorical_accuracy: 0.8446 - lr: 0.0010\n",
      "Epoch 111/120\n",
      "443/443 [==============================] - 64s 143ms/step - loss: 0.3736 - sparse_categorical_accuracy: 0.8509 - val_loss: 0.4063 - val_sparse_categorical_accuracy: 0.8400 - lr: 0.0010\n",
      "Epoch 112/120\n",
      "443/443 [==============================] - 64s 145ms/step - loss: 0.3747 - sparse_categorical_accuracy: 0.8538 - val_loss: 0.3962 - val_sparse_categorical_accuracy: 0.8475 - lr: 0.0010\n",
      "Epoch 113/120\n",
      "443/443 [==============================] - 64s 144ms/step - loss: 0.3738 - sparse_categorical_accuracy: 0.8519 - val_loss: 0.3776 - val_sparse_categorical_accuracy: 0.8506 - lr: 0.0010\n",
      "Epoch 114/120\n",
      "443/443 [==============================] - 64s 143ms/step - loss: 0.3740 - sparse_categorical_accuracy: 0.8502 - val_loss: 0.4069 - val_sparse_categorical_accuracy: 0.8431 - lr: 0.0010\n",
      "Epoch 115/120\n",
      "443/443 [==============================] - 65s 145ms/step - loss: 0.3667 - sparse_categorical_accuracy: 0.8549 - val_loss: 0.3824 - val_sparse_categorical_accuracy: 0.8562 - lr: 0.0010\n",
      "Epoch 116/120\n",
      "443/443 [==============================] - 65s 146ms/step - loss: 0.3648 - sparse_categorical_accuracy: 0.8547 - val_loss: 0.3909 - val_sparse_categorical_accuracy: 0.8514 - lr: 0.0010\n",
      "Epoch 117/120\n",
      "443/443 [==============================] - 64s 145ms/step - loss: 0.3920 - sparse_categorical_accuracy: 0.8483 - val_loss: 0.3989 - val_sparse_categorical_accuracy: 0.8447 - lr: 0.0010\n",
      "Epoch 118/120\n",
      "443/443 [==============================] - 65s 145ms/step - loss: 0.3677 - sparse_categorical_accuracy: 0.8537 - val_loss: 0.3956 - val_sparse_categorical_accuracy: 0.8452 - lr: 0.0010\n",
      "Epoch 119/120\n",
      "443/443 [==============================] - 65s 146ms/step - loss: 0.3673 - sparse_categorical_accuracy: 0.8555 - val_loss: 0.3873 - val_sparse_categorical_accuracy: 0.8494 - lr: 0.0010\n",
      "Epoch 120/120\n",
      "443/443 [==============================] - 65s 145ms/step - loss: 0.3622 - sparse_categorical_accuracy: 0.8566 - val_loss: 0.3828 - val_sparse_categorical_accuracy: 0.8537 - lr: 0.0010\n",
      "\n",
      "üìä ÊµãËØïÈõÜÂáÜÁ°ÆÁéá: 0.8806\n",
      "\n",
      "‚úÖ ËÆ≠ÁªÉÂÆåÊàêÔºÅÊ®°ÂûãÂ∑≤‰øùÂ≠òËá≥ models/mcldnn_classifier_final.keras\n"
     ]
    }
   ],
   "source": [
    "# train_mcldnn_classifier_fixed.py\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Conv2D, Conv1D, MaxPooling1D,\n",
    "                                     Dense, Dropout, BatchNormalization,\n",
    "                                     Flatten, Reshape, LSTM, concatenate)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import (EarlyStopping, ReduceLROnPlateau,\n",
    "                                      ModelCheckpoint)\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from scipy.signal import hilbert\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# ---------- GPU ÈÖçÁΩÆ ----------\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# ---------- ‰∏≠ÊñáÂ≠ó‰Ωì ----------\n",
    "def set_chinese_font():\n",
    "    try:\n",
    "        font_paths = ['/usr/share/fonts/truetype/wqy/wqy-microhei.ttc',\n",
    "                      'C:/Windows/Fonts/simhei.ttf',\n",
    "                      '/System/Library/Fonts/PingFang.ttc']\n",
    "        for path in font_paths:\n",
    "            if os.path.exists(path):\n",
    "                fm.fontManager.addfont(path)\n",
    "                plt.rcParams['font.family'] = fm.FontProperties(fname=path).get_name()\n",
    "                plt.rcParams['axes.unicode_minus'] = False\n",
    "                print(f\"‚úÖ ÊàêÂäüËÆæÁΩÆ‰∏≠ÊñáÂ≠ó‰Ωì: {plt.rcParams['font.family']}\")\n",
    "                return True\n",
    "        plt.rcParams['font.family'] = ['SimHei', 'Arial Unicode MS']\n",
    "        plt.rcParams['axes.unicode_minus'] = False\n",
    "        print(\"‚ö†Ô∏è ‰ΩøÁî®Á≥ªÁªüÈªòËÆ§‰∏≠ÊñáÂ≠ó‰Ωì\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Â≠ó‰ΩìËÆæÁΩÆÂ§±Ë¥•: {e}\")\n",
    "        return False\n",
    "set_chinese_font()\n",
    "\n",
    "# ---------- Âπ≤Êâ∞Á±ªÂûã ----------\n",
    "INTERFERENCE_TYPES = [\n",
    "    \"satellite_signal\",  # 0\n",
    "    \"single_tone\",\n",
    "    \"comb_spectra\",\n",
    "    \"sweeping\",\n",
    "    \"pulse\",\n",
    "    \"frequency_hopping\",\n",
    "    \"same_frequency\",\n",
    "    \"noise_fm\",\n",
    "    \"noise_am\",\n",
    "    \"random_combination\"\n",
    "]\n",
    "NUM_CLASSES = len(INTERFERENCE_TYPES)\n",
    "\n",
    "# ---------- Âä†ËΩΩÊï∞ÊçÆÈõÜ ----------\n",
    "def load_dataset(npz_path):\n",
    "    data = np.load(npz_path, allow_pickle=True)\n",
    "    if \"interference_type_names\" in data:\n",
    "        type_names = data[\"interference_type_names\"].item() \\\n",
    "            if isinstance(data[\"interference_type_names\"], np.ndarray) \\\n",
    "            else data[\"interference_type_names\"]\n",
    "    else:\n",
    "        type_names = {k: k.replace(\"_\", \" \").title() for k in INTERFERENCE_TYPES}\n",
    "        print(\"‚ö†Ô∏è Êú™ÊâæÂà∞Âπ≤Êâ∞Á±ªÂûãÂêçÁß∞Ôºå‰ΩøÁî®ÈªòËÆ§ÂÄº\")\n",
    "    if \"type_to_label\" in data:\n",
    "        type2label = data[\"type_to_label\"].item() \\\n",
    "            if isinstance(data[\"type_to_label\"], np.ndarray) \\\n",
    "            else data[\"type_to_label\"]\n",
    "    else:\n",
    "        type2label = {name: i for i, name in enumerate(INTERFERENCE_TYPES)}\n",
    "    return {\n",
    "        \"signals\": data[\"signals\"],\n",
    "        \"labels\": data[\"labels\"].astype(np.int32),\n",
    "        \"type2label\": type2label,\n",
    "        \"label2name\": {i: type_names[k] for k, i in type2label.items()},\n",
    "        \"L\": int(data[\"L\"])\n",
    "    }\n",
    "\n",
    "# ---------- Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜ ----------\n",
    "def preprocess_data(dataset):\n",
    "    signals = np.array([StandardScaler().fit_transform(s.reshape(-1, 1)).ravel()\n",
    "                        for s in dataset[\"signals\"]], dtype=np.float32)\n",
    "    L = signals.shape[1]\n",
    "    signals_complex = np.zeros((signals.shape[0], 2, L), dtype=np.float32)\n",
    "    for i in range(signals.shape[0]):\n",
    "        analytic = hilbert(signals[i])\n",
    "        signals_complex[i, 0] = signals[i]          # I\n",
    "        signals_complex[i, 1] = np.imag(analytic)   # Q\n",
    "\n",
    "    X1 = signals_complex[:, :, :, np.newaxis]       # (N, 2, L, 1)\n",
    "    X2 = signals_complex[:, 0, :, np.newaxis]       # (N, L, 1)\n",
    "    X3 = signals_complex[:, 1, :, np.newaxis]       # (N, L, 1)\n",
    "    return {\n",
    "        \"X1\": X1,\n",
    "        \"X2\": X2,\n",
    "        \"X3\": X3,\n",
    "        \"y\": dataset[\"labels\"],\n",
    "        \"label2name\": dataset[\"label2name\"],\n",
    "        \"L\": L\n",
    "    }\n",
    "\n",
    "# ---------- MCLDNN Ê®°Âûã ----------\n",
    "def build_mcldnn(input_shape1=(2, 1024, 1),\n",
    "                 input_shape2=(1024, 1),\n",
    "                 input_shape3=(1024, 1),\n",
    "                 num_classes=10):\n",
    "    input1 = Input(shape=input_shape1, name='complex_input')  # (None,2,L,1)\n",
    "    input2 = Input(shape=input_shape2, name='I_input')        # (None,L,1)\n",
    "    input3 = Input(shape=input_shape3, name='Q_input')        # (None,L,1)\n",
    "\n",
    "    # ÂàÜÊîØ 1Ôºö2D Âç∑ÁßØ\n",
    "    x1 = Conv2D(50, (2, 8), padding='same', activation='relu')(input1)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = Reshape((input_shape1[1], 100))(x1)        # (None,L,100)\n",
    "\n",
    "    # ÂàÜÊîØ 2/3Ôºö1D Âç∑ÁßØ\n",
    "    x2 = Conv1D(50, 8, padding='same', activation='relu')(input2)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x3 = Conv1D(50, 8, padding='same', activation='relu')(input3)\n",
    "    x3 = BatchNormalization()(x3)\n",
    "\n",
    "    # ÂêàÂπ∂\n",
    "    x = concatenate([x1, x2, x3], axis=-1)          # (None,L,200)\n",
    "    x = Conv1D(100, 5, activation='relu')(x)        # (None,L-4,100)\n",
    "\n",
    "    # Êó∂Â∫è\n",
    "    x = LSTM(128, return_sequences=True)(x)\n",
    "    x = LSTM(128)(x)\n",
    "\n",
    "    # ÂàÜÁ±ªÂ§¥\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=[input1, input2, input3], outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# ---------- Êï∞ÊçÆÂ¢ûÂº∫ ----------\n",
    "@tf.function\n",
    "def aug_fn(x1, x2, x3):\n",
    "    \"\"\"x1:(...,2,L,1)  x2/x3:(...,L,1)  ÊîØÊåÅ‰ªªÊÑèÂâçÁºÄÁª¥Â∫¶\"\"\"\n",
    "    x1 = tf.cast(x1, tf.float32)\n",
    "    x2 = tf.cast(x2, tf.float32)\n",
    "    x3 = tf.cast(x3, tf.float32)\n",
    "\n",
    "    # ÂêåÊ≠•Âô™Â£∞\n",
    "    if tf.random.uniform([]) > 0.2:\n",
    "        snr = tf.random.uniform([], 5., 25.)\n",
    "        noise = tf.random.normal(tf.shape(x2)) * tf.math.reduce_std(x2) * (10.0 ** (-snr / 20.0))\n",
    "        x2 = x2 + noise\n",
    "        x3 = x3 + noise\n",
    "\n",
    "    # ÂêåÊ≠•Áßª‰Ωç\n",
    "    if tf.random.uniform([]) > 0.3:\n",
    "        shift = tf.random.uniform([], -100, 100, dtype=tf.int32)\n",
    "        x2 = tf.roll(x2, shift, axis=-2)\n",
    "        x3 = tf.roll(x3, shift, axis=-2)\n",
    "\n",
    "    # ÂêåÊ≠•Áº©Êîæ\n",
    "    if tf.random.uniform([]) > 0.3:\n",
    "        scale = tf.random.uniform([], 0.7, 1.3)\n",
    "        x2 = x2 * scale\n",
    "        x3 = x3 * scale\n",
    "\n",
    "    # ÈáçÊñ∞ÊãºÂõû (...,2,L,1)\n",
    "    x1 = tf.stack([tf.squeeze(x2, axis=-1),\n",
    "                   tf.squeeze(x3, axis=-1)], axis=-2)[..., tf.newaxis]\n",
    "    return x1, x2, x3\n",
    "\n",
    "# ---------- ËÆ≠ÁªÉ ----------\n",
    "def train_single_model(data, model_idx=0, epochs=120, batch=128):\n",
    "    model = build_mcldnn(input_shape1=(2, data[\"L\"], 1),\n",
    "                         input_shape2=(data[\"L\"], 1),\n",
    "                         input_shape3=(data[\"L\"], 1),\n",
    "                         num_classes=len(data[\"label2name\"]))\n",
    "\n",
    "    # ---- Á±ªÂà´ÊùÉÈáçÔºàÂ≠óÂÖ∏Ôºâ ----\n",
    "    cls_weights = compute_class_weight('balanced',\n",
    "                                     classes=np.unique(data['y_train']),\n",
    "                                     y=data['y_train'])\n",
    "    class_weight_dict = {i: float(w) for i, w in enumerate(cls_weights)}\n",
    "\n",
    "    # ---- Êï∞ÊçÆÁÆ°ÈÅìÔºàÊó† sample_weightÔºâ ----\n",
    "    def create_dataset(X1, X2, X3, y):\n",
    "        def map_func(x, y):\n",
    "            x1, x2, x3 = aug_fn(x['complex_input'], x['I_input'], x['Q_input'])\n",
    "            return {'complex_input': x1, 'I_input': x2, 'Q_input': x3}, y\n",
    "\n",
    "        ds = tf.data.Dataset.from_tensor_slices(\n",
    "            ({'complex_input': X1, 'I_input': X2, 'Q_input': X3}, y))\n",
    "        return ds.map(map_func, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    train_ds = create_dataset(data['X1_train'], data['X2_train'], data['X3_train'], data['y_train'])\n",
    "    train_ds = train_ds.shuffle(10000).batch(batch).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    val_ds = create_dataset(data['X1_val'], data['X2_val'], data['X3_val'], data['y_val'])\n",
    "    val_ds = val_ds.batch(batch).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    # ---- ÂõûË∞É ----\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    ckpt = f\"models/mcldnn_classifier_{model_idx}.keras\"\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_sparse_categorical_accuracy', patience=20, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_sparse_categorical_accuracy', factor=0.5, patience=10),\n",
    "        ModelCheckpoint(ckpt, save_best_only=True, monitor='val_sparse_categorical_accuracy', save_format=\"tf\")\n",
    "    ]\n",
    "\n",
    "    model.compile(optimizer=Adam(1e-3),\n",
    "                loss=SparseCategoricalCrossentropy(),\n",
    "                metrics=[SparseCategoricalAccuracy()])\n",
    "\n",
    "    print(f\"\\nüî• ËÆ≠ÁªÉ MCLDNN Ê®°Âûã {model_idx + 1}...\")\n",
    "    history = model.fit(train_ds,\n",
    "                      validation_data=val_ds,\n",
    "                      epochs=epochs,\n",
    "                      callbacks=callbacks,\n",
    "                      class_weight=class_weight_dict,   # ‚Üê ÂÖ≥ÈîÆ\n",
    "                      verbose=1)\n",
    "    return model\n",
    "\n",
    "# ---------- ‰∏ªÂáΩÊï∞ ----------\n",
    "def main():\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    print(\"=\" * 80)\n",
    "    print(\"üöÄ ÂºÄÂßãËÆ≠ÁªÉ MCLDNN Âπ≤Êâ∞ÂàÜÁ±ªÊ®°Âûã\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Âä†ËΩΩÊï∞ÊçÆ\n",
    "    print(\"‚è≥ Âä†ËΩΩÊï∞ÊçÆÈõÜ...\")\n",
    "    dataset = load_dataset(\"/root/yxun/20250826/dataset/interference_signals_natural_same_freq_1019.npz\")\n",
    "    data = preprocess_data(dataset)\n",
    "\n",
    "    # Êï∞ÊçÆÈõÜÂàíÂàÜ\n",
    "    X1_train, X1_test, y_train, y_test = train_test_split(\n",
    "        data[\"X1\"], data[\"y\"], test_size=0.3, random_state=42, stratify=data[\"y\"])\n",
    "    X1_val, X1_test, y_val, y_test = train_test_split(\n",
    "        X1_test, y_test, test_size=0.5, random_state=42, stratify=y_test)\n",
    "\n",
    "    # ÊãÜÂàÜ I/Q\n",
    "    X2_train, X3_train = X1_train[:, 0, :, :], X1_train[:, 1, :, :]\n",
    "    X2_val, X3_val = X1_val[:, 0, :, :], X1_val[:, 1, :, :]\n",
    "    X2_test, X3_test = X1_test[:, 0, :, :], X1_test[:, 1, :, :]\n",
    "\n",
    "    train_data = {\n",
    "        \"X1_train\": X1_train, \"X2_train\": X2_train, \"X3_train\": X3_train,\n",
    "        \"y_train\": y_train,\n",
    "        \"X1_val\": X1_val, \"X2_val\": X2_val, \"X3_val\": X3_val,\n",
    "        \"y_val\": y_val,\n",
    "        \"X1_test\": X1_test, \"X2_test\": X2_test, \"X3_test\": X3_test,\n",
    "        \"y_test\": y_test,\n",
    "        \"label2name\": data[\"label2name\"],\n",
    "        \"L\": data[\"L\"]\n",
    "    }\n",
    "\n",
    "    # ËÆ≠ÁªÉ\n",
    "    model = train_single_model(train_data, model_idx=0, epochs=120, batch=128)\n",
    "\n",
    "    # ÊµãËØïËØÑ‰º∞\n",
    "    test_loss, test_acc = model.evaluate(\n",
    "        {\"complex_input\": X1_test, \"I_input\": X2_test, \"Q_input\": X3_test},\n",
    "        y_test, verbose=0)\n",
    "    print(f\"\\nüìä ÊµãËØïÈõÜÂáÜÁ°ÆÁéá: {test_acc:.4f}\")\n",
    "\n",
    "    # ‰øùÂ≠òÊúÄÁªàÊ®°Âûã\n",
    "    model.save(\"models/mcldnn_classifier_final.keras\", save_format=\"tf\")\n",
    "    print(\"\\n‚úÖ ËÆ≠ÁªÉÂÆåÊàêÔºÅÊ®°ÂûãÂ∑≤‰øùÂ≠òËá≥ models/mcldnn_classifier_final.keras\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5079391c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ÊàêÂäüËÆæÁΩÆ‰∏≠ÊñáÂ≠ó‰Ωì: ['WenQuanYi Micro Hei']\n",
      "üîÅ Âä†ËΩΩÊ®°Âûã: models/mcldnn_classifier_final.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-23 15:14:03.739042: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-10-23 15:14:03.739950: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-10-23 15:14:03.741100: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-10-23 15:14:03.847226: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-10-23 15:14:03.848050: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-10-23 15:14:03.848770: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-10-23 15:14:04.147383: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-10-23 15:14:04.148676: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-10-23 15:14:04.149392: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-10-23 15:14:04.249573: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-10-23 15:14:04.250365: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-10-23 15:14:04.251102: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "È¢ÑÊµãÊó∂Èó¥: 10.53 Áßí\n",
      "Ê®°ÂûãËæìÂá∫Á±ªÂûã: <class 'numpy.ndarray'>\n",
      "Ê®°ÂûãËæìÂá∫ÂΩ¢Áä∂: (8100, 9)\n",
      "  NaN Êï∞Èáè: 0\n",
      "  Inf Êï∞Èáè: 0\n",
      "  ËåÉÂõ¥: [0.0, 1.0]\n",
      "Ë∞ÉËØï‰ø°ÊÅØ:\n",
      "  y_param_test ËåÉÂõ¥: [-inf, 30.0]\n",
      "  avg_reg ËåÉÂõ¥: [0.0, 0.0]\n",
      "  y_param_test ‰∏≠ NaN Êï∞Èáè: 0\n",
      "  y_param_test ‰∏≠ Inf Êï∞Èáè: 906\n",
      "  avg_reg ‰∏≠ NaN Êï∞Èáè: 0\n",
      "  avg_reg ‰∏≠ Inf Êï∞Èáè: 0\n",
      "‚ö†Ô∏è  ÂèëÁé∞ 906 ‰∏™Êó†ÊïàÂÄº\n",
      "\n",
      "==================================================\n",
      "üìä ËØÑ‰º∞ÁªìÊûú\n",
      "==================================================\n",
      "Ê£ÄÊµãÂáÜÁ°ÆÁéá: 0.9585\n",
      "ÂàÜÁ±ªÂáÜÁ°ÆÁéá: 0.8974\n",
      "ÂàÜÁ±ªÁ≤æÁ°ÆÁéá: 0.9050, Âè¨ÂõûÁéá: 0.8974, F1: 0.8978\n",
      "ÂèÇÊï∞ MAE: Ëµ∑ÂßãÊó∂Èó¥: 0.126749s, ÁªìÊùüÊó∂Èó¥: 0.763075s, Âº∫Â∫¶: 11.9580dB\n",
      "\n",
      "JNR ÂáÜÁ°ÆÁéá:\n",
      "  -10dB: 0.5164\n",
      "  -5dB: 0.7746\n",
      "  0dB: 0.9163\n",
      "  5dB: 0.9484\n",
      "  10dB: 0.9664\n",
      "  15dB: 0.9761\n",
      "  20dB: 0.9889\n",
      "  25dB: 0.9838\n",
      "  30dB: 0.9891\n",
      "\n",
      "‚úÖ ËØÑ‰º∞ÂÆåÊàêÔºÅÊ∑∑Ê∑ÜÁü©Èòµ‰∏éÊä•ÂëäÂ∑≤‰øùÂ≠ò„ÄÇ\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "evaluate_mcldnn.py\n",
    "MCLDNN Ê®°ÂûãËØÑ‰º∞ËÑöÊú¨\n",
    "\"\"\"\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (confusion_matrix, accuracy_score, precision_score,\n",
    "                             recall_score, f1_score, mean_absolute_error)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib import font_manager as fm\n",
    "from scipy.signal import hilbert\n",
    "import time\n",
    "\n",
    "# ----------------------\n",
    "# ‚úÖ 1. ËÆæÁΩÆ‰∏≠ÊñáÂ≠ó‰ΩìÔºàÂèØÈÄâÔºâ\n",
    "# ----------------------\n",
    "def set_chinese_font():\n",
    "    try:\n",
    "        font_paths = ['/usr/share/fonts/truetype/wqy/wqy-microhei.ttc',\n",
    "                      'C:/Windows/Fonts/simhei.ttf',\n",
    "                      '/System/Library/Fonts/PingFang.ttc']\n",
    "        for font_path in font_paths:\n",
    "            if os.path.exists(font_path):\n",
    "                fm.fontManager.addfont(font_path)\n",
    "                plt.rcParams['font.family'] = fm.FontProperties(fname=font_path).get_name()\n",
    "                plt.rcParams['axes.unicode_minus'] = False\n",
    "                print(f\"‚úÖ ÊàêÂäüËÆæÁΩÆ‰∏≠ÊñáÂ≠ó‰Ωì: {plt.rcParams['font.family']}\")\n",
    "                return True\n",
    "        plt.rcParams['font.family'] = ['SimHei', 'Arial Unicode MS']\n",
    "        plt.rcParams['axes.unicode_minus'] = False\n",
    "        print(\"‚ö†Ô∏è Êú™ÊâæÂà∞ÊåáÂÆöÂ≠ó‰ΩìÔºå‰ΩøÁî®ÈªòËÆ§ÂÖºÂÆπÂ≠ó‰Ωì\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Â≠ó‰ΩìËÆæÁΩÆÂ§±Ë¥•: {e}\")\n",
    "        return False\n",
    "set_chinese_font()\n",
    "\n",
    "# -------------------------------\n",
    "# ‚úÖ 2. Âä†ËΩΩÊï∞ÊçÆÈõÜ\n",
    "# -------------------------------\n",
    "def load_dataset(npz_path=\"/root/yxun/20250826/dataset/interference_signals_natural_same_freq_1019.npz\"):\n",
    "    data = np.load(npz_path, allow_pickle=True)\n",
    "    signals = data[\"signals\"]\n",
    "    labels = data[\"labels\"].astype(np.int32)\n",
    "    jnr_vals = data[\"jnr_values\"].astype(np.float32)\n",
    "    fs = float(data[\"fs\"])\n",
    "    L = int(data[\"L\"])\n",
    "    metadata = data[\"metadata\"]\n",
    "    type2label = data[\"type_to_label\"].item()\n",
    "    label2type = {v: k for k, v in type2label.items()}  # ‰ªétype2labelÂàõÂª∫label2type\n",
    "    type2name = data[\"interference_type_names\"].item()\n",
    "    label2name = {i: type2name[k] for k, i in type2label.items()}\n",
    "    return {\n",
    "        \"signals\": signals,\n",
    "        \"labels\": labels,\n",
    "        \"jnr_values\": jnr_vals,\n",
    "        \"fs\": fs,\n",
    "        \"L\": L,\n",
    "        \"metadata\": metadata,\n",
    "        \"type2label\": type2label,\n",
    "        \"label2type\": label2type,  # Ê∑ªÂä†Ëøô‰∏™Â≠óÊÆµ\n",
    "        \"label2name\": label2name,\n",
    "        \"type2name\": type2name\n",
    "    }\n",
    "\n",
    "# -------------------------------\n",
    "# ‚úÖ 3. Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜ (‰∏éËÆ≠ÁªÉ‰ª£Á†Å‰øùÊåÅ‰∏ÄËá¥)\n",
    "# -------------------------------\n",
    "def preprocess_data(dataset):\n",
    "    signals = dataset[\"signals\"]\n",
    "    labels = dataset[\"labels\"]\n",
    "    jnr_values = dataset[\"jnr_values\"]\n",
    "    metadata = dataset[\"metadata\"]\n",
    "    type2label = dataset[\"type2label\"]\n",
    "    label2type = dataset[\"label2type\"]\n",
    "\n",
    "    # Ê†áÂáÜÂåñ\n",
    "    signals = np.array([StandardScaler().fit_transform(s.reshape(-1, 1)).ravel() for s in signals])\n",
    "\n",
    "    # Â§ç‰ø°Âè∑ I/Q ÊûÑÈÄ†\n",
    "    signals_complex = np.zeros((signals.shape[0], 2, signals.shape[1]))\n",
    "    for i in range(signals.shape[0]):\n",
    "        analytic_signal = hilbert(signals[i])\n",
    "        signals_complex[i, 0, :] = signals[i]            # I: ÂÆûÈÉ®\n",
    "        signals_complex[i, 1, :] = np.imag(analytic_signal)  # Q: ËôöÈÉ®\n",
    "\n",
    "    # Ê®°ÂûãËæìÂÖ•1: [N, 2, 1024, 1]\n",
    "    X1 = np.expand_dims(signals_complex, axis=-1)  # [N, 2, 1024, 1]\n",
    "\n",
    "    # Ê®°ÂûãËæìÂÖ•2, 3: IË∑Ø [N, 1024, 1], QË∑Ø [N, 1024, 1]\n",
    "    X2 = signals_complex[:, 0, :, None]  # I: [N, 1024, 1]\n",
    "    X3 = signals_complex[:, 1, :, None]  # Q: [N, 1024, 1]\n",
    "\n",
    "    # Ê†áÁ≠æÂ§ÑÁêÜ (‰∏éËÆ≠ÁªÉ‰ª£Á†Å‰øùÊåÅ‰∏ÄËá¥)\n",
    "    no_interference_key = \"satellite_signal\"\n",
    "    det_labels = (labels != list(dataset[\"type2label\"].values())[0]).astype(np.int32)\n",
    "\n",
    "    y_type = np.array([dataset[\"type2label\"][label2type.get(label, 0)] for label in labels])\n",
    "\n",
    "    # ÂèÇÊï∞Ê†áÁ≠æ\n",
    "    param_labels = []\n",
    "    for m in metadata:\n",
    "        p = m.get(\"params\", {})\n",
    "        start = float(p.get(\"start_time\", 0))\n",
    "        end = float(p.get(\"end_time\", 0))\n",
    "        strength = float(p.get(\"jnr_db\", 0))\n",
    "        param_labels.append([start, end, strength])\n",
    "    y_param = np.array(param_labels, dtype=np.float32)\n",
    "\n",
    "    return {\n",
    "        'X1': X1,  # [N, 2, 1024, 1]\n",
    "        'X2': X2,  # [N, 1024, 1]\n",
    "        'X3': X3,  # [N, 1024, 1]\n",
    "        'y_det': det_labels,\n",
    "        'y_type': y_type,\n",
    "        'y_param': y_param,\n",
    "        'jnr_values': jnr_values\n",
    "    }\n",
    "\n",
    "# -------------------------------\n",
    "# ‚úÖ 4. ÂàíÂàÜÊï∞ÊçÆ (‰∏éËÆ≠ÁªÉ‰ª£Á†Å‰øùÊåÅ‰∏ÄËá¥)\n",
    "# -------------------------------\n",
    "def split_data(data):\n",
    "    X1 = data['X1']\n",
    "    X2 = data['X2']\n",
    "    X3 = data['X3']\n",
    "    y_det = data['y_det']\n",
    "    y_type = data['y_type']\n",
    "    y_param = data['y_param']\n",
    "    jnr_values = data['jnr_values']\n",
    "\n",
    "    X1_train, X1_tmp, X2_train, X2_tmp, X3_train, X3_tmp, \\\n",
    "    y_det_train, y_det_tmp, y_type_train, y_type_tmp, \\\n",
    "    y_param_train, y_param_tmp, jnr_train, jnr_tmp = train_test_split(\n",
    "        X1, X2, X3, y_det, y_type, y_param, jnr_values, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    X1_val, X1_test, X2_val, X2_test, X3_val, X3_test, \\\n",
    "    y_det_val, y_det_test, y_type_val, y_type_test, \\\n",
    "    y_param_val, y_param_test, jnr_val, jnr_test = train_test_split(\n",
    "        X1_tmp, X2_tmp, X3_tmp, y_det_tmp, y_type_tmp, y_param_tmp, jnr_tmp, test_size=0.5, random_state=42\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'train': {'X1': X1_train, 'X2': X2_train, 'X3': X3_train, 'y_det': y_det_train, 'y_type': y_type_train, 'y_param': y_param_train, 'jnr': jnr_train},\n",
    "        'val': {'X1': X1_val, 'X2': X2_val, 'X3': X3_val, 'y_det': y_det_val, 'y_type': y_type_val, 'y_param': y_param_val, 'jnr': jnr_val},\n",
    "        'test': {'X1': X1_test, 'X2': X2_test, 'X3': X3_test, 'y_det': y_det_test, 'y_type': y_type_test, 'y_param': y_param_test, 'jnr': jnr_test}\n",
    "    }\n",
    "\n",
    "# ----------------------\n",
    "# ‚úÖ 5. Âä†ËΩΩÊ®°ÂûãÂπ∂È¢ÑÊµã (‰øÆÂ§çÁâàÊú¨)\n",
    "# ----------------------\n",
    "def load_and_predict(model_path, X1_test, X2_test, X3_test):\n",
    "    print(f\"üîÅ Âä†ËΩΩÊ®°Âûã: {model_path}\")\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    start_time = time.time()\n",
    "    # ‰øÆÂ§çÔºöÊ†πÊçÆÂÆûÈôÖÊ®°ÂûãËæìÂá∫Ë∞ÉÊï¥\n",
    "    predictions = model.predict([X1_test, X2_test, X3_test], verbose=0)\n",
    "    end_time = time.time()\n",
    "    prediction_time = end_time - start_time\n",
    "    print(f\"È¢ÑÊµãÊó∂Èó¥: {prediction_time:.2f} Áßí\")\n",
    "    \n",
    "    # Ê£ÄÊü•Ê®°ÂûãËæìÂá∫\n",
    "    print(f\"Ê®°ÂûãËæìÂá∫Á±ªÂûã: {type(predictions)}\")\n",
    "    if isinstance(predictions, list):\n",
    "        print(f\"Ê®°ÂûãËæìÂá∫ÈïøÂ∫¶: {len(predictions)}\")\n",
    "        for i, pred in enumerate(predictions):\n",
    "            print(f\"  ËæìÂá∫ {i} ÂΩ¢Áä∂: {pred.shape}\")\n",
    "            # Ê£ÄÊü•ÊòØÂê¶ÊúâÊó†ÊïàÂÄº\n",
    "            print(f\"    NaN Êï∞Èáè: {np.sum(np.isnan(pred))}\")\n",
    "            print(f\"    Inf Êï∞Èáè: {np.sum(np.isinf(pred))}\")\n",
    "            print(f\"    ËåÉÂõ¥: [{np.min(pred[np.isfinite(pred)]) if np.any(np.isfinite(pred)) else 'N/A'}, {np.max(pred[np.isfinite(pred)]) if np.any(np.isfinite(pred)) else 'N/A'}]\")\n",
    "    else:\n",
    "        print(f\"Ê®°ÂûãËæìÂá∫ÂΩ¢Áä∂: {predictions.shape}\")\n",
    "        print(f\"  NaN Êï∞Èáè: {np.sum(np.isnan(predictions))}\")\n",
    "        print(f\"  Inf Êï∞Èáè: {np.sum(np.isinf(predictions))}\")\n",
    "        print(f\"  ËåÉÂõ¥: [{np.min(predictions[np.isfinite(predictions)]) if np.any(np.isfinite(predictions)) else 'N/A'}, {np.max(predictions[np.isfinite(predictions)]) if np.any(np.isfinite(predictions)) else 'N/A'}]\")\n",
    "    \n",
    "    # Ê†πÊçÆÊ®°ÂûãÂÆûÈôÖËæìÂá∫Ë∞ÉÊï¥ËøîÂõûÂÄº\n",
    "    if isinstance(predictions, list) and len(predictions) == 2:\n",
    "        # Â¶ÇÊûúÊ®°ÂûãÁ°ÆÂÆûËøîÂõû‰∏§‰∏™ËæìÂá∫ÔºàÂàÜÁ±ªÂíåÂõûÂΩíÔºâ\n",
    "        cls_pred, reg_pred = predictions[0], predictions[1]\n",
    "        \n",
    "        # Â§ÑÁêÜÂõûÂΩíËæìÂá∫‰∏≠ÁöÑÊó†ÊïàÂÄº\n",
    "        if np.any(np.isnan(reg_pred)) or np.any(np.isinf(reg_pred)):\n",
    "            print(\"‚ö†Ô∏è  ÂõûÂΩíËæìÂá∫‰∏≠ÂèëÁé∞Êó†ÊïàÂÄºÔºåÂ∞ÜÁî®0ÊõøÊç¢\")\n",
    "            reg_pred = np.nan_to_num(reg_pred, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        \n",
    "        return cls_pred, reg_pred\n",
    "    else:\n",
    "        # Â¶ÇÊûúÊ®°ÂûãÂè™ËøîÂõûÂàÜÁ±ªËæìÂá∫\n",
    "        # ÂàõÂª∫‰∏Ä‰∏™ÈªòËÆ§ÁöÑÂõûÂΩíËæìÂá∫ÔºàÊàñËÄÖÊ†πÊçÆÈúÄË¶ÅË∞ÉÊï¥Ôºâ\n",
    "        dummy_reg = np.zeros((predictions.shape[0], 3))  # ÂÅáËÆæ3‰∏™ÂèÇÊï∞\n",
    "        return predictions, dummy_reg\n",
    "\n",
    "# ----------------------\n",
    "# ‚úÖ 6. ÁªòÂà∂Ê∑∑Ê∑ÜÁü©ÈòµÔºàÊîØÊåÅÂΩí‰∏ÄÂåñ„ÄÅxËΩ¥ÊóãËΩ¨Ôºâ\n",
    "# ----------------------\n",
    "def plot_confusion_matrix(cm, labels, title, xlabel, ylabel, filename, dpi=150, rotate_x=False):\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
    "    cm_normalized = np.nan_to_num(cm_normalized)\n",
    "\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    ax = sns.heatmap(cm_normalized,\n",
    "                     annot=True,\n",
    "                     fmt='.2f',\n",
    "                     cmap='Blues',\n",
    "                     xticklabels=labels,\n",
    "                     yticklabels=labels,\n",
    "                     square=True,\n",
    "                     annot_kws={\"size\": 14})\n",
    "\n",
    "    # ---------- ÂÖ≥ÈîÆÔºöcolorbar Â≠ó‰Ωì ----------\n",
    "    cbar = ax.collections[0].colorbar\n",
    "    cbar.ax.tick_params(labelsize=14)   # ÂàªÂ∫¶Â≠óÂè∑\n",
    "    # ----------------------------------------\n",
    "\n",
    "    plt.title(title, pad=20, fontsize=18)\n",
    "    plt.xlabel(xlabel, fontsize=16)\n",
    "    plt.ylabel(ylabel, fontsize=16)\n",
    "    plt.xticks(rotation=45 if rotate_x else 0, ha='right' if rotate_x else 'center', fontsize=14)\n",
    "    plt.yticks(rotation=0, fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, dpi=dpi)\n",
    "    plt.close()\n",
    "\n",
    "# ----------------------\n",
    "# ‚úÖ 7. ‰∏ªËØÑ‰º∞ÂáΩÊï∞ (‰øÆÂ§çÁâàÊú¨)\n",
    "# ----------------------\n",
    "def evaluate(models_dir=\"models\", npz_path=\"/root/yxun/20250826/dataset/interference_signals_natural_same_freq_1019.npz\"):\n",
    "    os.makedirs(\"visualizations\", exist_ok=True)\n",
    "    os.makedirs(\"reports\", exist_ok=True)\n",
    "\n",
    "    dataset = load_dataset(npz_path)\n",
    "    data = preprocess_data(dataset)\n",
    "    splits = split_data(data)\n",
    "\n",
    "    # ‰ΩøÁî®ÊµãËØïÈõÜÊï∞ÊçÆ\n",
    "    X1_test = splits['test']['X1']\n",
    "    X2_test = splits['test']['X2']\n",
    "    X3_test = splits['test']['X3']\n",
    "    y_det_test = splits['test']['y_det']\n",
    "    y_type_test = splits['test']['y_type']\n",
    "    y_param_test = splits['test']['y_param']\n",
    "    jnr_test = splits['test']['jnr']\n",
    "    \n",
    "    # Ëé∑ÂèñÊ†áÁ≠æÂêçÁß∞\n",
    "    label2name = dataset[\"label2name\"]\n",
    "\n",
    "    # ‰øÆÂ§çÔºö‰ΩøÁî®ÂÆûÈôÖ‰øùÂ≠òÁöÑÊ®°ÂûãÊñá‰ª∂Âêç\n",
    "    model_path = os.path.join(models_dir, \"mcldnn_classifier_final.keras\")\n",
    "\n",
    "    # Âä†ËΩΩÊ®°ÂûãÂπ∂È¢ÑÊµã\n",
    "    avg_cls, avg_reg = load_and_predict(model_path, X1_test, X2_test, X3_test)\n",
    "    avg_cls_labels = np.argmax(avg_cls, axis=1)\n",
    "\n",
    "    # ËÆ°ÁÆóÊ£ÄÊµãÊ†áÁ≠æÔºà0Ë°®Á§∫Êó†Âπ≤Êâ∞ÔºåÈùû0Ë°®Á§∫ÊúâÂπ≤Êâ∞Ôºâ\n",
    "    avg_det = (avg_cls_labels != 0).astype(int)\n",
    "\n",
    "    # 1. Ê£ÄÊµãÊ∑∑Ê∑ÜÁü©Èòµ\n",
    "    cm_det = confusion_matrix(y_det_test, avg_det)\n",
    "    plot_confusion_matrix(\n",
    "        cm=cm_det,\n",
    "        labels=['No Interference', 'Interference'],\n",
    "        title='MCLDNN Interference Detection Confusion Matrix',\n",
    "        xlabel='Predicted',\n",
    "        ylabel='True',\n",
    "        filename='visualizations/MCLDNN detection_confusion_matrix.png',\n",
    "        dpi=150,\n",
    "        rotate_x=False\n",
    "    )\n",
    "\n",
    "    # 2. ÂàÜÁ±ªÊ∑∑Ê∑ÜÁü©ÈòµÔºàxËΩ¥ÊóãËΩ¨45Â∫¶Ôºâ\n",
    "    cm_type = confusion_matrix(y_type_test, avg_cls_labels)\n",
    "    plot_confusion_matrix(\n",
    "        cm=cm_type,\n",
    "        labels=[label2name[i] for i in sorted(label2name.keys())],\n",
    "        title='MCLDNN Classification Confusion Matrix',\n",
    "        xlabel='Predicted',\n",
    "        ylabel='True',\n",
    "        filename='visualizations/MCLDNN interference_type_confusion_matrix.png',\n",
    "        dpi=150,\n",
    "        rotate_x=True\n",
    "    )\n",
    "\n",
    "    # 3. JNR vs ÂáÜÁ°ÆÁéá\n",
    "    wanted_jnr = np.arange(-10, 31, 5)\n",
    "    jnr_acc = []\n",
    "    for jnr in wanted_jnr:\n",
    "        mask = jnr_test == jnr\n",
    "        acc = np.nan if np.sum(mask) == 0 else accuracy_score(y_type_test[mask], avg_cls_labels[mask])\n",
    "        jnr_acc.append(acc)\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    valid_mask = ~np.isnan(jnr_acc)\n",
    "    plt.plot(wanted_jnr[valid_mask], np.array(jnr_acc)[valid_mask], marker='o', linewidth=2)\n",
    "    if np.any(~valid_mask):\n",
    "        plt.scatter(wanted_jnr[~valid_mask], [1.0] * np.sum(~valid_mask), facecolors='none', edgecolors='r', s=60)\n",
    "    plt.xlabel('JNR (dB)')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Classification Accuracy vs JNR')\n",
    "    plt.xticks(wanted_jnr)\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('visualizations/MCLDNN jnr_vs_accuracy.png', dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "    # 4. ÊåáÊ†á & Êä•Âëä\n",
    "    det_acc = accuracy_score(y_det_test, avg_det)\n",
    "    cls_acc = accuracy_score(y_type_test, avg_cls_labels)\n",
    "    cls_precision = precision_score(y_type_test, avg_cls_labels, average='weighted')\n",
    "    cls_recall = recall_score(y_type_test, avg_cls_labels, average='weighted')\n",
    "    cls_f1 = f1_score(y_type_test, avg_cls_labels, average='weighted')\n",
    "    \n",
    "    # Âè™ÊúâÂú®ÂõûÂΩíËæìÂá∫ÊúâÊïàÊó∂ÊâçËÆ°ÁÆóÂèÇÊï∞MAE\n",
    "    param_mae = [0, 0, 0]  # ÈªòËÆ§ÂÄº\n",
    "    if avg_reg is not None and avg_reg.shape[0] == y_param_test.shape[0]:\n",
    "        # Ê£ÄÊü•Âπ∂Â§ÑÁêÜÊó†ÊïàÂÄº\n",
    "        print(f\"Ë∞ÉËØï‰ø°ÊÅØ:\")\n",
    "        print(f\"  y_param_test ËåÉÂõ¥: [{np.min(y_param_test)}, {np.max(y_param_test)}]\")\n",
    "        print(f\"  avg_reg ËåÉÂõ¥: [{np.min(avg_reg)}, {np.max(avg_reg)}]\")\n",
    "        print(f\"  y_param_test ‰∏≠ NaN Êï∞Èáè: {np.sum(np.isnan(y_param_test))}\")\n",
    "        print(f\"  y_param_test ‰∏≠ Inf Êï∞Èáè: {np.sum(np.isinf(y_param_test))}\")\n",
    "        print(f\"  avg_reg ‰∏≠ NaN Êï∞Èáè: {np.sum(np.isnan(avg_reg))}\")\n",
    "        print(f\"  avg_reg ‰∏≠ Inf Êï∞Èáè: {np.sum(np.isinf(avg_reg))}\")\n",
    "        \n",
    "        # Ê£ÄÊü•ÊòØÂê¶Â≠òÂú®Êó†Á©∑Â§ßÊàñNaNÂÄº\n",
    "        invalid_mask = (np.isnan(y_param_test) | np.isinf(y_param_test) | \n",
    "                        np.isnan(avg_reg) | np.isinf(avg_reg))\n",
    "        \n",
    "        if np.any(invalid_mask):\n",
    "            print(f\"‚ö†Ô∏è  ÂèëÁé∞ {np.sum(invalid_mask)} ‰∏™Êó†ÊïàÂÄº\")\n",
    "            # ÂàõÂª∫Ê∏ÖÁêÜÂêéÁöÑÊï∞ÊçÆ\n",
    "            y_param_test_clean = np.where(invalid_mask, 0, y_param_test)\n",
    "            avg_reg_clean = np.where(invalid_mask, 0, avg_reg)\n",
    "        else:\n",
    "            y_param_test_clean = y_param_test\n",
    "            avg_reg_clean = avg_reg\n",
    "        \n",
    "        # ÈôêÂà∂Êï∞ÂÄºËåÉÂõ¥‰ª•ÈÄÇÂ∫îfloat32\n",
    "        float32_max = np.finfo(np.float32).max\n",
    "        y_param_test_clean = np.clip(y_param_test_clean, -float32_max, float32_max)\n",
    "        avg_reg_clean = np.clip(avg_reg_clean, -float32_max, float32_max)\n",
    "        \n",
    "        # ËÆ°ÁÆóMAE\n",
    "        try:\n",
    "            param_mae = mean_absolute_error(y_param_test_clean, avg_reg_clean, multioutput='raw_values')\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  ËÆ°ÁÆóÂèÇÊï∞MAEÊó∂Âá∫Èîô: {e}\")\n",
    "            param_mae = [0, 0, 0]  # ‰ΩøÁî®ÈªòËÆ§ÂÄº\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"üìä ËØÑ‰º∞ÁªìÊûú\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Ê£ÄÊµãÂáÜÁ°ÆÁéá: {det_acc:.4f}\")\n",
    "    print(f\"ÂàÜÁ±ªÂáÜÁ°ÆÁéá: {cls_acc:.4f}\")\n",
    "    print(f\"ÂàÜÁ±ªÁ≤æÁ°ÆÁéá: {cls_precision:.4f}, Âè¨ÂõûÁéá: {cls_recall:.4f}, F1: {cls_f1:.4f}\")\n",
    "    print(f\"ÂèÇÊï∞ MAE: Ëµ∑ÂßãÊó∂Èó¥: {param_mae[0]:.6f}s, ÁªìÊùüÊó∂Èó¥: {param_mae[1]:.6f}s, Âº∫Â∫¶: {param_mae[2]:.4f}dB\")\n",
    "    print(\"\\nJNR ÂáÜÁ°ÆÁéá:\")\n",
    "    for j, acc in zip(wanted_jnr, jnr_acc):\n",
    "        acc_str = f\"{acc:.4f}\" if not np.isnan(acc) else \"N/A\"\n",
    "        print(f\"  {int(j)}dB: {acc_str}\")\n",
    "\n",
    "    report = {\n",
    "        \"detection_accuracy\": float(det_acc),\n",
    "        \"classification_accuracy\": float(cls_acc),\n",
    "        \"classification_precision\": float(cls_precision),\n",
    "        \"classification_recall\": float(cls_recall),\n",
    "        \"classification_f1\": float(cls_f1),\n",
    "        \"parameter_mae\": [float(m) for m in param_mae],\n",
    "        \"jnr_accuracies\": {f\"{int(j)}dB\": float(acc) if not np.isnan(acc) else None for j, acc in zip(wanted_jnr, jnr_acc)}\n",
    "    }\n",
    "    with open(\"reports/MCLDNN_evaluation_report.json\", \"w\", encoding='utf-8') as f:\n",
    "        json.dump(report, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "    print(\"\\n‚úÖ ËØÑ‰º∞ÂÆåÊàêÔºÅÊ∑∑Ê∑ÜÁü©Èòµ‰∏éÊä•ÂëäÂ∑≤‰øùÂ≠ò„ÄÇ\")\n",
    "\n",
    "# ----------------------\n",
    "# ‚úÖ 8. ‰∏ªÂáΩÊï∞\n",
    "# ----------------------\n",
    "if __name__ == \"__main__\":\n",
    "    evaluate(models_dir=\"models\", npz_path=\"/root/yxun/20250826/dataset/interference_signals_natural_same_freq_1019.npz\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
