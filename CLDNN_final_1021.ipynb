{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "212db529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ÊàêÂäüËÆæÁΩÆ‰∏≠ÊñáÂ≠ó‰Ωì: ['WenQuanYi Micro Hei']\n",
      "================================================================================\n",
      "üöÄ ÂºÄÂßãËÆ≠ÁªÉCLDNNÂπ≤Êâ∞ÂàÜÁ±ªÊ®°Âûã\n",
      "================================================================================\n",
      "‚è≥ Âä†ËΩΩÊï∞ÊçÆÈõÜ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 23:25:20.777666: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-10-21 23:25:20.779228: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-10-21 23:25:20.779960: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-10-21 23:25:20.892935: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-10-21 23:25:20.893678: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-10-21 23:25:20.894440: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üî• ËÆ≠ÁªÉCLDNNÊ®°Âûã 1...\n",
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 23:25:21.339222: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_3' with dtype float and shape [56700]\n",
      "\t [[{{node Placeholder/_3}}]]\n",
      "2025-10-21 23:25:21.339439: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_3' with dtype float and shape [56700]\n",
      "\t [[{{node Placeholder/_3}}]]\n",
      "2025-10-21 23:25:21.526030: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-10-21 23:25:21.526884: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-10-21 23:25:21.527600: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-10-21 23:25:21.640011: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-10-21 23:25:21.641424: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-10-21 23:25:21.642229: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-10-21 23:25:22.530661: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-10-21 23:25:22.532134: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-10-21 23:25:22.532992: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-10-21 23:25:22.640204: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-10-21 23:25:22.641101: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-10-21 23:25:22.641921: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-10-21 23:25:24.386765: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2025-10-21 23:25:24.689296: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-10-21 23:25:24.723666: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f0564015bb0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-10-21 23:25:24.723713: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA vGPU-48GB, Compute Capability 8.9\n",
      "2025-10-21 23:25:24.735045: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-10-21 23:25:24.873429: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "443/443 [==============================] - ETA: 0s - loss: 1.3535 - sparse_categorical_accuracy: 0.4941"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 23:25:37.950026: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int32 and shape [12150]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2025-10-21 23:25:37.950227: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int32 and shape [12150]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2025-10-21 23:25:38.214660: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-10-21 23:25:38.215809: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-10-21 23:25:38.216517: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-10-21 23:25:38.319620: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-10-21 23:25:38.320388: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-10-21 23:25:38.321089: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "443/443 [==============================] - 18s 30ms/step - loss: 1.3535 - sparse_categorical_accuracy: 0.4941 - val_loss: 1.8888 - val_sparse_categorical_accuracy: 0.4004 - lr: 0.0010\n",
      "Epoch 2/120\n",
      "443/443 [==============================] - 12s 28ms/step - loss: 0.9688 - sparse_categorical_accuracy: 0.6119 - val_loss: 0.8749 - val_sparse_categorical_accuracy: 0.6374 - lr: 0.0010\n",
      "Epoch 3/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.8667 - sparse_categorical_accuracy: 0.6446 - val_loss: 0.8637 - val_sparse_categorical_accuracy: 0.6417 - lr: 0.0010\n",
      "Epoch 4/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.8253 - sparse_categorical_accuracy: 0.6551 - val_loss: 0.7565 - val_sparse_categorical_accuracy: 0.6709 - lr: 0.0010\n",
      "Epoch 5/120\n",
      "443/443 [==============================] - 12s 28ms/step - loss: 0.8036 - sparse_categorical_accuracy: 0.6638 - val_loss: 0.8148 - val_sparse_categorical_accuracy: 0.6566 - lr: 0.0010\n",
      "Epoch 6/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.7750 - sparse_categorical_accuracy: 0.6705 - val_loss: 0.7944 - val_sparse_categorical_accuracy: 0.6632 - lr: 0.0010\n",
      "Epoch 7/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.7683 - sparse_categorical_accuracy: 0.6736 - val_loss: 0.7623 - val_sparse_categorical_accuracy: 0.6737 - lr: 0.0010\n",
      "Epoch 8/120\n",
      "443/443 [==============================] - 12s 27ms/step - loss: 0.7505 - sparse_categorical_accuracy: 0.6762 - val_loss: 0.7335 - val_sparse_categorical_accuracy: 0.6798 - lr: 0.0010\n",
      "Epoch 9/120\n",
      "443/443 [==============================] - 12s 28ms/step - loss: 0.7345 - sparse_categorical_accuracy: 0.6821 - val_loss: 0.6924 - val_sparse_categorical_accuracy: 0.6870 - lr: 0.0010\n",
      "Epoch 10/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.7211 - sparse_categorical_accuracy: 0.6852 - val_loss: 0.6958 - val_sparse_categorical_accuracy: 0.6974 - lr: 0.0010\n",
      "Epoch 11/120\n",
      "443/443 [==============================] - 12s 27ms/step - loss: 0.7017 - sparse_categorical_accuracy: 0.6898 - val_loss: 0.7210 - val_sparse_categorical_accuracy: 0.6869 - lr: 0.0010\n",
      "Epoch 12/120\n",
      "443/443 [==============================] - 12s 28ms/step - loss: 0.7024 - sparse_categorical_accuracy: 0.6908 - val_loss: 0.6643 - val_sparse_categorical_accuracy: 0.6978 - lr: 0.0010\n",
      "Epoch 13/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.6933 - sparse_categorical_accuracy: 0.6938 - val_loss: 0.6605 - val_sparse_categorical_accuracy: 0.6979 - lr: 0.0010\n",
      "Epoch 14/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.6896 - sparse_categorical_accuracy: 0.6956 - val_loss: 0.6643 - val_sparse_categorical_accuracy: 0.7016 - lr: 0.0010\n",
      "Epoch 15/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.6827 - sparse_categorical_accuracy: 0.6971 - val_loss: 0.6540 - val_sparse_categorical_accuracy: 0.7021 - lr: 0.0010\n",
      "Epoch 16/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.6785 - sparse_categorical_accuracy: 0.7014 - val_loss: 0.6806 - val_sparse_categorical_accuracy: 0.7035 - lr: 0.0010\n",
      "Epoch 17/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.6645 - sparse_categorical_accuracy: 0.7058 - val_loss: 0.6520 - val_sparse_categorical_accuracy: 0.7086 - lr: 0.0010\n",
      "Epoch 18/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.6588 - sparse_categorical_accuracy: 0.7116 - val_loss: 0.6762 - val_sparse_categorical_accuracy: 0.7058 - lr: 0.0010\n",
      "Epoch 19/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.6453 - sparse_categorical_accuracy: 0.7175 - val_loss: 0.6490 - val_sparse_categorical_accuracy: 0.7158 - lr: 0.0010\n",
      "Epoch 20/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.6423 - sparse_categorical_accuracy: 0.7201 - val_loss: 0.6329 - val_sparse_categorical_accuracy: 0.7261 - lr: 0.0010\n",
      "Epoch 21/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.6237 - sparse_categorical_accuracy: 0.7279 - val_loss: 0.6249 - val_sparse_categorical_accuracy: 0.7251 - lr: 0.0010\n",
      "Epoch 22/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.6201 - sparse_categorical_accuracy: 0.7307 - val_loss: 0.6247 - val_sparse_categorical_accuracy: 0.7281 - lr: 0.0010\n",
      "Epoch 23/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.6050 - sparse_categorical_accuracy: 0.7403 - val_loss: 0.5922 - val_sparse_categorical_accuracy: 0.7447 - lr: 0.0010\n",
      "Epoch 24/120\n",
      "443/443 [==============================] - 12s 28ms/step - loss: 0.6019 - sparse_categorical_accuracy: 0.7419 - val_loss: 0.5806 - val_sparse_categorical_accuracy: 0.7505 - lr: 0.0010\n",
      "Epoch 25/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.5818 - sparse_categorical_accuracy: 0.7508 - val_loss: 0.6046 - val_sparse_categorical_accuracy: 0.7508 - lr: 0.0010\n",
      "Epoch 26/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.5836 - sparse_categorical_accuracy: 0.7526 - val_loss: 0.6169 - val_sparse_categorical_accuracy: 0.7385 - lr: 0.0010\n",
      "Epoch 27/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.5741 - sparse_categorical_accuracy: 0.7554 - val_loss: 0.5729 - val_sparse_categorical_accuracy: 0.7574 - lr: 0.0010\n",
      "Epoch 28/120\n",
      "443/443 [==============================] - 12s 28ms/step - loss: 0.5631 - sparse_categorical_accuracy: 0.7632 - val_loss: 0.5601 - val_sparse_categorical_accuracy: 0.7637 - lr: 0.0010\n",
      "Epoch 29/120\n",
      "443/443 [==============================] - 12s 27ms/step - loss: 0.5554 - sparse_categorical_accuracy: 0.7687 - val_loss: 0.5954 - val_sparse_categorical_accuracy: 0.7560 - lr: 0.0010\n",
      "Epoch 30/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.5460 - sparse_categorical_accuracy: 0.7714 - val_loss: 0.5630 - val_sparse_categorical_accuracy: 0.7693 - lr: 0.0010\n",
      "Epoch 31/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.5344 - sparse_categorical_accuracy: 0.7775 - val_loss: 0.5695 - val_sparse_categorical_accuracy: 0.7644 - lr: 0.0010\n",
      "Epoch 32/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.5280 - sparse_categorical_accuracy: 0.7799 - val_loss: 0.5376 - val_sparse_categorical_accuracy: 0.7766 - lr: 0.0010\n",
      "Epoch 33/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.5211 - sparse_categorical_accuracy: 0.7855 - val_loss: 0.5686 - val_sparse_categorical_accuracy: 0.7711 - lr: 0.0010\n",
      "Epoch 34/120\n",
      "443/443 [==============================] - 12s 27ms/step - loss: 0.5111 - sparse_categorical_accuracy: 0.7874 - val_loss: 0.5140 - val_sparse_categorical_accuracy: 0.7914 - lr: 0.0010\n",
      "Epoch 35/120\n",
      "443/443 [==============================] - 12s 28ms/step - loss: 0.5017 - sparse_categorical_accuracy: 0.7929 - val_loss: 0.5757 - val_sparse_categorical_accuracy: 0.7720 - lr: 0.0010\n",
      "Epoch 36/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.5010 - sparse_categorical_accuracy: 0.7925 - val_loss: 0.5273 - val_sparse_categorical_accuracy: 0.7849 - lr: 0.0010\n",
      "Epoch 37/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.4982 - sparse_categorical_accuracy: 0.7933 - val_loss: 0.5229 - val_sparse_categorical_accuracy: 0.7840 - lr: 0.0010\n",
      "Epoch 38/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.4878 - sparse_categorical_accuracy: 0.7981 - val_loss: 0.5248 - val_sparse_categorical_accuracy: 0.7850 - lr: 0.0010\n",
      "Epoch 39/120\n",
      "443/443 [==============================] - 12s 27ms/step - loss: 0.4868 - sparse_categorical_accuracy: 0.7988 - val_loss: 0.5133 - val_sparse_categorical_accuracy: 0.7950 - lr: 0.0010\n",
      "Epoch 40/120\n",
      "443/443 [==============================] - 12s 27ms/step - loss: 0.4851 - sparse_categorical_accuracy: 0.7999 - val_loss: 0.5584 - val_sparse_categorical_accuracy: 0.7806 - lr: 0.0010\n",
      "Epoch 41/120\n",
      "443/443 [==============================] - 12s 28ms/step - loss: 0.4795 - sparse_categorical_accuracy: 0.8033 - val_loss: 0.4924 - val_sparse_categorical_accuracy: 0.7972 - lr: 0.0010\n",
      "Epoch 42/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.4852 - sparse_categorical_accuracy: 0.7997 - val_loss: 0.4950 - val_sparse_categorical_accuracy: 0.8002 - lr: 0.0010\n",
      "Epoch 43/120\n",
      "443/443 [==============================] - 12s 26ms/step - loss: 0.4730 - sparse_categorical_accuracy: 0.8047 - val_loss: 0.5091 - val_sparse_categorical_accuracy: 0.7925 - lr: 0.0010\n",
      "Epoch 44/120\n",
      "443/443 [==============================] - 12s 27ms/step - loss: 0.4705 - sparse_categorical_accuracy: 0.8056 - val_loss: 0.4998 - val_sparse_categorical_accuracy: 0.7975 - lr: 0.0010\n",
      "Epoch 45/120\n",
      "443/443 [==============================] - 12s 27ms/step - loss: 0.4672 - sparse_categorical_accuracy: 0.8075 - val_loss: 0.4850 - val_sparse_categorical_accuracy: 0.7995 - lr: 0.0010\n",
      "Epoch 46/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.4676 - sparse_categorical_accuracy: 0.8066 - val_loss: 0.4839 - val_sparse_categorical_accuracy: 0.8049 - lr: 0.0010\n",
      "Epoch 47/120\n",
      "443/443 [==============================] - 12s 28ms/step - loss: 0.4603 - sparse_categorical_accuracy: 0.8095 - val_loss: 0.5324 - val_sparse_categorical_accuracy: 0.7941 - lr: 0.0010\n",
      "Epoch 48/120\n",
      "443/443 [==============================] - 12s 28ms/step - loss: 0.4596 - sparse_categorical_accuracy: 0.8096 - val_loss: 0.5100 - val_sparse_categorical_accuracy: 0.7905 - lr: 0.0010\n",
      "Epoch 49/120\n",
      "443/443 [==============================] - 12s 27ms/step - loss: 0.4537 - sparse_categorical_accuracy: 0.8114 - val_loss: 0.4810 - val_sparse_categorical_accuracy: 0.8020 - lr: 0.0010\n",
      "Epoch 50/120\n",
      "443/443 [==============================] - 12s 28ms/step - loss: 0.4591 - sparse_categorical_accuracy: 0.8113 - val_loss: 0.4926 - val_sparse_categorical_accuracy: 0.8022 - lr: 0.0010\n",
      "Epoch 51/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.4497 - sparse_categorical_accuracy: 0.8135 - val_loss: 0.4652 - val_sparse_categorical_accuracy: 0.8126 - lr: 0.0010\n",
      "Epoch 52/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.4497 - sparse_categorical_accuracy: 0.8134 - val_loss: 0.4715 - val_sparse_categorical_accuracy: 0.8067 - lr: 0.0010\n",
      "Epoch 53/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.4450 - sparse_categorical_accuracy: 0.8152 - val_loss: 0.4861 - val_sparse_categorical_accuracy: 0.8001 - lr: 0.0010\n",
      "Epoch 54/120\n",
      "443/443 [==============================] - 12s 28ms/step - loss: 0.4461 - sparse_categorical_accuracy: 0.8152 - val_loss: 0.5252 - val_sparse_categorical_accuracy: 0.7914 - lr: 0.0010\n",
      "Epoch 55/120\n",
      "443/443 [==============================] - 12s 28ms/step - loss: 0.4469 - sparse_categorical_accuracy: 0.8159 - val_loss: 0.4957 - val_sparse_categorical_accuracy: 0.8051 - lr: 0.0010\n",
      "Epoch 56/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.4405 - sparse_categorical_accuracy: 0.8181 - val_loss: 0.4730 - val_sparse_categorical_accuracy: 0.8113 - lr: 0.0010\n",
      "Epoch 57/120\n",
      "443/443 [==============================] - 12s 28ms/step - loss: 0.4418 - sparse_categorical_accuracy: 0.8177 - val_loss: 0.4715 - val_sparse_categorical_accuracy: 0.8125 - lr: 0.0010\n",
      "Epoch 58/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.4382 - sparse_categorical_accuracy: 0.8175 - val_loss: 0.5044 - val_sparse_categorical_accuracy: 0.8004 - lr: 0.0010\n",
      "Epoch 59/120\n",
      "443/443 [==============================] - 12s 27ms/step - loss: 0.4386 - sparse_categorical_accuracy: 0.8195 - val_loss: 0.5113 - val_sparse_categorical_accuracy: 0.7955 - lr: 0.0010\n",
      "Epoch 60/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.4379 - sparse_categorical_accuracy: 0.8191 - val_loss: 0.4679 - val_sparse_categorical_accuracy: 0.8144 - lr: 0.0010\n",
      "Epoch 61/120\n",
      "443/443 [==============================] - 12s 28ms/step - loss: 0.4315 - sparse_categorical_accuracy: 0.8219 - val_loss: 0.4845 - val_sparse_categorical_accuracy: 0.8085 - lr: 0.0010\n",
      "Epoch 62/120\n",
      "443/443 [==============================] - 12s 28ms/step - loss: 0.4298 - sparse_categorical_accuracy: 0.8199 - val_loss: 0.4966 - val_sparse_categorical_accuracy: 0.8013 - lr: 0.0010\n",
      "Epoch 63/120\n",
      "443/443 [==============================] - 12s 27ms/step - loss: 0.4332 - sparse_categorical_accuracy: 0.8195 - val_loss: 0.4732 - val_sparse_categorical_accuracy: 0.8128 - lr: 0.0010\n",
      "Epoch 64/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.4309 - sparse_categorical_accuracy: 0.8211 - val_loss: 0.4677 - val_sparse_categorical_accuracy: 0.8110 - lr: 0.0010\n",
      "Epoch 65/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.4271 - sparse_categorical_accuracy: 0.8237 - val_loss: 0.4956 - val_sparse_categorical_accuracy: 0.8067 - lr: 0.0010\n",
      "Epoch 66/120\n",
      "443/443 [==============================] - 12s 28ms/step - loss: 0.4249 - sparse_categorical_accuracy: 0.8245 - val_loss: 0.4737 - val_sparse_categorical_accuracy: 0.8072 - lr: 0.0010\n",
      "Epoch 67/120\n",
      "443/443 [==============================] - 12s 28ms/step - loss: 0.4230 - sparse_categorical_accuracy: 0.8248 - val_loss: 0.4798 - val_sparse_categorical_accuracy: 0.8078 - lr: 0.0010\n",
      "Epoch 68/120\n",
      "443/443 [==============================] - 12s 28ms/step - loss: 0.4228 - sparse_categorical_accuracy: 0.8254 - val_loss: 0.4677 - val_sparse_categorical_accuracy: 0.8155 - lr: 0.0010\n",
      "Epoch 69/120\n",
      "443/443 [==============================] - 12s 28ms/step - loss: 0.4213 - sparse_categorical_accuracy: 0.8241 - val_loss: 0.5110 - val_sparse_categorical_accuracy: 0.7970 - lr: 0.0010\n",
      "Epoch 70/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.4178 - sparse_categorical_accuracy: 0.8271 - val_loss: 0.4811 - val_sparse_categorical_accuracy: 0.8109 - lr: 0.0010\n",
      "Epoch 71/120\n",
      "443/443 [==============================] - 12s 27ms/step - loss: 0.4169 - sparse_categorical_accuracy: 0.8273 - val_loss: 0.4595 - val_sparse_categorical_accuracy: 0.8142 - lr: 0.0010\n",
      "Epoch 72/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.4179 - sparse_categorical_accuracy: 0.8280 - val_loss: 0.4781 - val_sparse_categorical_accuracy: 0.8105 - lr: 0.0010\n",
      "Epoch 73/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.4130 - sparse_categorical_accuracy: 0.8313 - val_loss: 0.4744 - val_sparse_categorical_accuracy: 0.8108 - lr: 0.0010\n",
      "Epoch 74/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.4135 - sparse_categorical_accuracy: 0.8292 - val_loss: 0.5094 - val_sparse_categorical_accuracy: 0.8058 - lr: 0.0010\n",
      "Epoch 75/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.4130 - sparse_categorical_accuracy: 0.8294 - val_loss: 0.4589 - val_sparse_categorical_accuracy: 0.8136 - lr: 0.0010\n",
      "Epoch 76/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.4110 - sparse_categorical_accuracy: 0.8289 - val_loss: 0.4603 - val_sparse_categorical_accuracy: 0.8133 - lr: 0.0010\n",
      "Epoch 77/120\n",
      "443/443 [==============================] - 12s 28ms/step - loss: 0.4083 - sparse_categorical_accuracy: 0.8305 - val_loss: 0.4605 - val_sparse_categorical_accuracy: 0.8104 - lr: 0.0010\n",
      "Epoch 78/120\n",
      "443/443 [==============================] - 12s 27ms/step - loss: 0.4118 - sparse_categorical_accuracy: 0.8303 - val_loss: 0.4594 - val_sparse_categorical_accuracy: 0.8125 - lr: 0.0010\n",
      "Epoch 79/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.3857 - sparse_categorical_accuracy: 0.8365 - val_loss: 0.4412 - val_sparse_categorical_accuracy: 0.8222 - lr: 5.0000e-04\n",
      "Epoch 80/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.3882 - sparse_categorical_accuracy: 0.8369 - val_loss: 0.4416 - val_sparse_categorical_accuracy: 0.8212 - lr: 5.0000e-04\n",
      "Epoch 81/120\n",
      "443/443 [==============================] - 12s 27ms/step - loss: 0.3789 - sparse_categorical_accuracy: 0.8412 - val_loss: 0.4391 - val_sparse_categorical_accuracy: 0.8246 - lr: 5.0000e-04\n",
      "Epoch 82/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.3755 - sparse_categorical_accuracy: 0.8427 - val_loss: 0.4525 - val_sparse_categorical_accuracy: 0.8213 - lr: 5.0000e-04\n",
      "Epoch 83/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.3787 - sparse_categorical_accuracy: 0.8425 - val_loss: 0.4366 - val_sparse_categorical_accuracy: 0.8237 - lr: 5.0000e-04\n",
      "Epoch 84/120\n",
      "443/443 [==============================] - 12s 28ms/step - loss: 0.3733 - sparse_categorical_accuracy: 0.8429 - val_loss: 0.4543 - val_sparse_categorical_accuracy: 0.8176 - lr: 5.0000e-04\n",
      "Epoch 85/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.3766 - sparse_categorical_accuracy: 0.8421 - val_loss: 0.4474 - val_sparse_categorical_accuracy: 0.8193 - lr: 5.0000e-04\n",
      "Epoch 86/120\n",
      "443/443 [==============================] - 12s 28ms/step - loss: 0.3750 - sparse_categorical_accuracy: 0.8435 - val_loss: 0.4477 - val_sparse_categorical_accuracy: 0.8213 - lr: 5.0000e-04\n",
      "Epoch 87/120\n",
      "443/443 [==============================] - 12s 28ms/step - loss: 0.3733 - sparse_categorical_accuracy: 0.8437 - val_loss: 0.4380 - val_sparse_categorical_accuracy: 0.8252 - lr: 5.0000e-04\n",
      "Epoch 88/120\n",
      "443/443 [==============================] - 12s 27ms/step - loss: 0.3720 - sparse_categorical_accuracy: 0.8449 - val_loss: 0.4486 - val_sparse_categorical_accuracy: 0.8219 - lr: 5.0000e-04\n",
      "Epoch 89/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.3736 - sparse_categorical_accuracy: 0.8434 - val_loss: 0.4538 - val_sparse_categorical_accuracy: 0.8218 - lr: 5.0000e-04\n",
      "Epoch 90/120\n",
      "443/443 [==============================] - 12s 28ms/step - loss: 0.3684 - sparse_categorical_accuracy: 0.8462 - val_loss: 0.4482 - val_sparse_categorical_accuracy: 0.8229 - lr: 5.0000e-04\n",
      "Epoch 91/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.3708 - sparse_categorical_accuracy: 0.8456 - val_loss: 0.4395 - val_sparse_categorical_accuracy: 0.8272 - lr: 5.0000e-04\n",
      "Epoch 92/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.3689 - sparse_categorical_accuracy: 0.8475 - val_loss: 0.4689 - val_sparse_categorical_accuracy: 0.8154 - lr: 5.0000e-04\n",
      "Epoch 93/120\n",
      "443/443 [==============================] - 12s 27ms/step - loss: 0.3688 - sparse_categorical_accuracy: 0.8468 - val_loss: 0.4518 - val_sparse_categorical_accuracy: 0.8222 - lr: 5.0000e-04\n",
      "Epoch 94/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.3657 - sparse_categorical_accuracy: 0.8470 - val_loss: 0.4385 - val_sparse_categorical_accuracy: 0.8210 - lr: 5.0000e-04\n",
      "Epoch 95/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.3676 - sparse_categorical_accuracy: 0.8462 - val_loss: 0.4431 - val_sparse_categorical_accuracy: 0.8238 - lr: 5.0000e-04\n",
      "Epoch 96/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.3653 - sparse_categorical_accuracy: 0.8469 - val_loss: 0.4470 - val_sparse_categorical_accuracy: 0.8240 - lr: 5.0000e-04\n",
      "Epoch 97/120\n",
      "443/443 [==============================] - 13s 29ms/step - loss: 0.3654 - sparse_categorical_accuracy: 0.8468 - val_loss: 0.4514 - val_sparse_categorical_accuracy: 0.8198 - lr: 5.0000e-04\n",
      "Epoch 98/120\n",
      "443/443 [==============================] - 12s 27ms/step - loss: 0.3651 - sparse_categorical_accuracy: 0.8480 - val_loss: 0.4409 - val_sparse_categorical_accuracy: 0.8258 - lr: 5.0000e-04\n",
      "Epoch 99/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.3616 - sparse_categorical_accuracy: 0.8489 - val_loss: 0.4442 - val_sparse_categorical_accuracy: 0.8247 - lr: 5.0000e-04\n",
      "Epoch 100/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.3658 - sparse_categorical_accuracy: 0.8474 - val_loss: 0.4425 - val_sparse_categorical_accuracy: 0.8247 - lr: 5.0000e-04\n",
      "Epoch 101/120\n",
      "443/443 [==============================] - 12s 27ms/step - loss: 0.3622 - sparse_categorical_accuracy: 0.8484 - val_loss: 0.4504 - val_sparse_categorical_accuracy: 0.8224 - lr: 5.0000e-04\n",
      "Epoch 102/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.3506 - sparse_categorical_accuracy: 0.8514 - val_loss: 0.4304 - val_sparse_categorical_accuracy: 0.8277 - lr: 2.5000e-04\n",
      "Epoch 103/120\n",
      "443/443 [==============================] - 12s 28ms/step - loss: 0.3485 - sparse_categorical_accuracy: 0.8541 - val_loss: 0.4361 - val_sparse_categorical_accuracy: 0.8261 - lr: 2.5000e-04\n",
      "Epoch 104/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.3496 - sparse_categorical_accuracy: 0.8519 - val_loss: 0.4431 - val_sparse_categorical_accuracy: 0.8283 - lr: 2.5000e-04\n",
      "Epoch 105/120\n",
      "443/443 [==============================] - 12s 27ms/step - loss: 0.3462 - sparse_categorical_accuracy: 0.8547 - val_loss: 0.4287 - val_sparse_categorical_accuracy: 0.8323 - lr: 2.5000e-04\n",
      "Epoch 106/120\n",
      "443/443 [==============================] - 12s 27ms/step - loss: 0.3465 - sparse_categorical_accuracy: 0.8544 - val_loss: 0.4255 - val_sparse_categorical_accuracy: 0.8302 - lr: 2.5000e-04\n",
      "Epoch 107/120\n",
      "443/443 [==============================] - 12s 28ms/step - loss: 0.3472 - sparse_categorical_accuracy: 0.8545 - val_loss: 0.4417 - val_sparse_categorical_accuracy: 0.8276 - lr: 2.5000e-04\n",
      "Epoch 108/120\n",
      "443/443 [==============================] - 12s 27ms/step - loss: 0.3444 - sparse_categorical_accuracy: 0.8555 - val_loss: 0.4381 - val_sparse_categorical_accuracy: 0.8268 - lr: 2.5000e-04\n",
      "Epoch 109/120\n",
      "443/443 [==============================] - 12s 27ms/step - loss: 0.3456 - sparse_categorical_accuracy: 0.8541 - val_loss: 0.4289 - val_sparse_categorical_accuracy: 0.8291 - lr: 2.5000e-04\n",
      "Epoch 110/120\n",
      "443/443 [==============================] - 12s 27ms/step - loss: 0.3435 - sparse_categorical_accuracy: 0.8553 - val_loss: 0.4419 - val_sparse_categorical_accuracy: 0.8271 - lr: 2.5000e-04\n",
      "Epoch 111/120\n",
      "443/443 [==============================] - 12s 27ms/step - loss: 0.3434 - sparse_categorical_accuracy: 0.8562 - val_loss: 0.4334 - val_sparse_categorical_accuracy: 0.8309 - lr: 2.5000e-04\n",
      "Epoch 112/120\n",
      "443/443 [==============================] - 12s 27ms/step - loss: 0.3412 - sparse_categorical_accuracy: 0.8564 - val_loss: 0.4424 - val_sparse_categorical_accuracy: 0.8262 - lr: 2.5000e-04\n",
      "Epoch 113/120\n",
      "443/443 [==============================] - 12s 28ms/step - loss: 0.3408 - sparse_categorical_accuracy: 0.8574 - val_loss: 0.4352 - val_sparse_categorical_accuracy: 0.8289 - lr: 2.5000e-04\n",
      "Epoch 114/120\n",
      "443/443 [==============================] - 11s 25ms/step - loss: 0.3408 - sparse_categorical_accuracy: 0.8573 - val_loss: 0.4495 - val_sparse_categorical_accuracy: 0.8259 - lr: 2.5000e-04\n",
      "Epoch 115/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.3432 - sparse_categorical_accuracy: 0.8573 - val_loss: 0.4406 - val_sparse_categorical_accuracy: 0.8250 - lr: 2.5000e-04\n",
      "Epoch 116/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.3338 - sparse_categorical_accuracy: 0.8604 - val_loss: 0.4262 - val_sparse_categorical_accuracy: 0.8322 - lr: 1.2500e-04\n",
      "Epoch 117/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.3343 - sparse_categorical_accuracy: 0.8600 - val_loss: 0.4235 - val_sparse_categorical_accuracy: 0.8338 - lr: 1.2500e-04\n",
      "Epoch 118/120\n",
      "443/443 [==============================] - 12s 28ms/step - loss: 0.3340 - sparse_categorical_accuracy: 0.8604 - val_loss: 0.4366 - val_sparse_categorical_accuracy: 0.8290 - lr: 1.2500e-04\n",
      "Epoch 119/120\n",
      "443/443 [==============================] - 12s 27ms/step - loss: 0.3344 - sparse_categorical_accuracy: 0.8592 - val_loss: 0.4365 - val_sparse_categorical_accuracy: 0.8298 - lr: 1.2500e-04\n",
      "Epoch 120/120\n",
      "443/443 [==============================] - 12s 28ms/step - loss: 0.3360 - sparse_categorical_accuracy: 0.8586 - val_loss: 0.4256 - val_sparse_categorical_accuracy: 0.8342 - lr: 1.2500e-04\n",
      "\n",
      "üìä ÊµãËØïÈõÜÂáÜÁ°ÆÁéá: 0.8458\n",
      "\n",
      "‚úÖ ËÆ≠ÁªÉÂÆåÊàêÔºÅÊ®°ÂûãÂ∑≤‰øùÂ≠òËá≥ models/cldnn_classifier_final.keras\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "train_cldnn_fixed.py\n",
    "‰øÆÂ§çÊ†∑Êú¨ÊùÉÈáçÁª¥Â∫¶ÈóÆÈ¢òÁöÑCLDNNÂπ≤Êâ∞ÂàÜÁ±ªÊ®°ÂûãËÆ≠ÁªÉ\n",
    "\"\"\"\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Conv1D, MaxPooling1D, \n",
    "                                   Dense, Dropout, BatchNormalization,\n",
    "                                   Reshape, LSTM)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import (EarlyStopping, ReduceLROnPlateau, \n",
    "                                      ModelCheckpoint)\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# ---------- GPUÈÖçÁΩÆ ----------\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# ---------- ‰∏≠ÊñáÂ≠ó‰ΩìËÆæÁΩÆ ----------\n",
    "def set_chinese_font():\n",
    "    \"\"\"ÂÆâÂÖ®ËÆæÁΩÆ‰∏≠ÊñáÂ≠ó‰Ωì\"\"\"\n",
    "    try:\n",
    "        font_paths = ['/usr/share/fonts/truetype/wqy/wqy-microhei.ttc',\n",
    "                     'C:/Windows/Fonts/simhei.ttf',\n",
    "                     '/System/Library/Fonts/PingFang.ttc']\n",
    "        for path in font_paths:\n",
    "            if os.path.exists(path):\n",
    "                fm.fontManager.addfont(path)\n",
    "                plt.rcParams['font.family'] = fm.FontProperties(fname=path).get_name()\n",
    "                plt.rcParams['axes.unicode_minus'] = False\n",
    "                print(f\"‚úÖ ÊàêÂäüËÆæÁΩÆ‰∏≠ÊñáÂ≠ó‰Ωì: {plt.rcParams['font.family']}\")\n",
    "                return True\n",
    "        plt.rcParams['font.family'] = ['SimHei', 'Arial Unicode MS']\n",
    "        plt.rcParams['axes.unicode_minus'] = False\n",
    "        print(\"‚ö†Ô∏è ‰ΩøÁî®Á≥ªÁªüÈªòËÆ§‰∏≠ÊñáÂ≠ó‰Ωì\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Â≠ó‰ΩìËÆæÁΩÆÂ§±Ë¥•: {e}\")\n",
    "        return False\n",
    "set_chinese_font()\n",
    "\n",
    "# ---------- Âπ≤Êâ∞Á±ªÂûãÂÆö‰πâ ----------\n",
    "INTERFERENCE_TYPES = [\n",
    "    \"satellite_signal\",  # 0: Êó†Âπ≤Êâ∞\n",
    "    \"single_tone\",       # 1\n",
    "    \"comb_spectra\",      # 2\n",
    "    \"sweeping\",          # 3\n",
    "    \"pulse\",             # 4\n",
    "    \"frequency_hopping\", # 5\n",
    "    \"same_frequency\",    # 6\n",
    "    \"noise_fm\",          # 7\n",
    "    \"noise_am\",          # 8\n",
    "    \"random_combination\" # 9\n",
    "]\n",
    "NUM_CLASSES = len(INTERFERENCE_TYPES)\n",
    "\n",
    "# ---------- Âä†ËΩΩÊï∞ÊçÆÈõÜ ----------\n",
    "def load_dataset(npz_path):\n",
    "    \"\"\"Âä†ËΩΩÂπ∂Â§ÑÁêÜÊï∞ÊçÆÈõÜ\"\"\"\n",
    "    data = np.load(npz_path, allow_pickle=True)\n",
    "    \n",
    "    # Âü∫Á°ÄÊï∞ÊçÆ\n",
    "    dataset = {\n",
    "        \"signals\": data[\"signals\"],\n",
    "        \"labels\": data[\"labels\"].astype(np.int32),\n",
    "        \"fs\": float(data[\"fs\"]),\n",
    "        \"L\": int(data[\"L\"])\n",
    "    }\n",
    "    \n",
    "    # Â§ÑÁêÜÂπ≤Êâ∞Á±ªÂûãÂêçÁß∞\n",
    "    if \"interference_type_names\" in data:\n",
    "        type_names = data[\"interference_type_names\"].item() if isinstance(data[\"interference_type_names\"], np.ndarray) else data[\"interference_type_names\"]\n",
    "    else:\n",
    "        type_names = {\n",
    "            \"satellite_signal\": \"Satellite_Signal\",\n",
    "            \"single_tone\": \"Single_Tone\",\n",
    "            \"comb_spectra\": \"Comb_Spectra\",\n",
    "            \"sweeping\": \"Sweeping-LFM\",\n",
    "            \"pulse\": \"Pulse\",\n",
    "            \"frequency_hopping\": \"Frequency_Hopping\",\n",
    "            \"same_frequency\": \"Same_Frequency\",\n",
    "            \"noise_fm\": \"Noise_FM\",\n",
    "            \"noise_am\": \"Noise_AM\",\n",
    "            \"random_combination\": \"Random_Combination\"\n",
    "        }\n",
    "        print(\"‚ö†Ô∏è Êú™ÊâæÂà∞Âπ≤Êâ∞Á±ªÂûãÂêçÁß∞Ôºå‰ΩøÁî®ÈªòËÆ§ÂÄº\")\n",
    "    \n",
    "    # ÂàõÂª∫Ê†áÁ≠æÊò†Â∞Ñ\n",
    "    if \"type_to_label\" in data:\n",
    "        type2label = data[\"type_to_label\"].item() if isinstance(data[\"type_to_label\"], np.ndarray) else data[\"type_to_label\"]\n",
    "    else:\n",
    "        type2label = {name: i for i, name in enumerate(INTERFERENCE_TYPES)}\n",
    "    \n",
    "    return {\n",
    "        \"signals\": data[\"signals\"],\n",
    "        \"labels\": data[\"labels\"].astype(np.int32),\n",
    "        \"type2label\": type2label,\n",
    "        \"label2name\": {i: type_names[k] for k, i in type2label.items()},\n",
    "        \"L\": int(data[\"L\"])\n",
    "    }\n",
    "\n",
    "# ---------- Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜ ----------\n",
    "def preprocess_data(dataset):\n",
    "    \"\"\"È¢ÑÂ§ÑÁêÜÊï∞ÊçÆÔºàÂ§ç‰ø°Âè∑ÊûÑÈÄ†Ôºâ\"\"\"\n",
    "    # ‰ø°Âè∑Ê†áÂáÜÂåñÂπ∂ËΩ¨Êç¢‰∏∫float32\n",
    "    signals = np.array([StandardScaler().fit_transform(s.reshape(-1, 1)).ravel() \n",
    "                       for s in dataset[\"signals\"]], dtype=np.float32)\n",
    "    \n",
    "    # Êï∞ÊçÆÈõÜÂàÜÂâ≤Ôºà‰øùÊåÅÂàÜÂ±ÇÊäΩÊ†∑Ôºâ\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        signals, dataset[\"labels\"],\n",
    "        test_size=0.3, random_state=42, \n",
    "        stratify=dataset[\"labels\"]\n",
    "    )\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_test, y_test,\n",
    "        test_size=0.5, random_state=42,\n",
    "        stratify=y_test\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"X_train\": X_train, \"X_val\": X_val, \"X_test\": X_test,\n",
    "        \"y_train\": y_train, \"y_val\": y_val, \"y_test\": y_test,\n",
    "        \"label2name\": dataset[\"label2name\"],\n",
    "        \"L\": dataset[\"L\"]\n",
    "    }\n",
    "\n",
    "# ---------- CLDNNÊ®°ÂûãÊûÑÂª∫ ----------\n",
    "def build_cldnn(input_shape, num_classes):\n",
    "    \"\"\"ÊûÑÂª∫CLDNNÂàÜÁ±ªÊ®°Âûã\"\"\"\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Reshape((input_shape[0], 1))(inputs)  # [batch, length, 1]\n",
    "    \n",
    "    # CNNÁâπÂæÅÊèêÂèñ\n",
    "    x = Conv1D(32, 7, activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    \n",
    "    x = Conv1D(64, 5, activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    \n",
    "    x = Conv1D(128, 3, activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    \n",
    "    # LSTMÊó∂Â∫èÂª∫Ê®°\n",
    "    x = LSTM(64, return_sequences=True)(x)\n",
    "    x = LSTM(32)(x)\n",
    "    \n",
    "    # ÂàÜÁ±ªÂ§¥\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(\n",
    "        optimizer=Adam(1e-3),\n",
    "        loss=SparseCategoricalCrossentropy(),\n",
    "        metrics=[SparseCategoricalAccuracy()]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# ---------- Êï∞ÊçÆÂ¢ûÂº∫ ----------\n",
    "@tf.function\n",
    "def aug_fn(x):\n",
    "    \"\"\"‰ø°Âè∑Â¢ûÂº∫ÔºàÁ°Æ‰øùÊï∞ÊçÆÁ±ªÂûãÂíåÁª¥Â∫¶Ê≠£Á°ÆÔºâ\"\"\"\n",
    "    x = tf.cast(x, tf.float32)\n",
    "    \n",
    "    # Âô™Â£∞Â¢ûÂº∫\n",
    "    if tf.random.uniform([], dtype=tf.float32) > 0.2:\n",
    "        snr = tf.random.uniform([], 5., 25., dtype=tf.float32)\n",
    "        noise = tf.random.normal(tf.shape(x), dtype=tf.float32) * tf.math.reduce_std(x) * 10.0**(-snr/20.0)\n",
    "        x = x + noise\n",
    "    \n",
    "    # ‰ΩçÁßªÂ¢ûÂº∫\n",
    "    if tf.random.uniform([], dtype=tf.float32) > 0.3:\n",
    "        shift = tf.random.uniform([], -100, 100, dtype=tf.int32)\n",
    "        x = tf.roll(x, shift=shift, axis=0)\n",
    "    \n",
    "    # Áº©ÊîæÂ¢ûÂº∫\n",
    "    if tf.random.uniform([], dtype=tf.float32) > 0.3:\n",
    "        scale = tf.random.uniform([], 0.7, 1.3, dtype=tf.float32)\n",
    "        x = x * scale\n",
    "    \n",
    "    return x\n",
    "\n",
    "# ---------- ËÆ≠ÁªÉÂáΩÊï∞ ----------\n",
    "# ‰øÆÊîπ train_single_model ÂáΩÊï∞‰∏≠ÁöÑÊï∞ÊçÆÈõÜÂàõÂª∫ÈÉ®ÂàÜ\n",
    "def train_single_model(data, model_idx=0, epochs=120, batch=128):\n",
    "    \"\"\"ËÆ≠ÁªÉÂçï‰∏™CLDNNÊ®°Âûã\"\"\"\n",
    "    model = build_cldnn((data[\"L\"],), len(data[\"label2name\"]))\n",
    "    \n",
    "    # Á±ªÂà´ÊùÉÈáçÔºàÂ§ÑÁêÜ‰∏çÂπ≥Ë°°Ôºâ\n",
    "    cls_weights = compute_class_weight('balanced', \n",
    "                                     classes=np.unique(data['y_train']), \n",
    "                                     y=data['y_train'])\n",
    "    sample_weights = np.array([cls_weights[lab] for lab in data['y_train']], dtype=np.float32)\n",
    "    \n",
    "    # Êï∞ÊçÆÁÆ°ÈÅì\n",
    "    def create_dataset(X, y, w=None):\n",
    "        ds = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "        if w is not None:\n",
    "            # Ê≠£Á°ÆÁöÑÊñπÂºèÔºöÂ∞ÜÊ†∑Êú¨ÊùÉÈáç‰Ωú‰∏∫ÂÖÉÁªÑÁöÑÁ¨¨‰∏â‰∏™ÂÖÉÁ¥†‰º†ÈÄí\n",
    "            ds_w = tf.data.Dataset.from_tensor_slices(w)\n",
    "            ds = tf.data.Dataset.zip((ds, ds_w))\n",
    "            ds = ds.map(lambda xy, w: (aug_fn(xy[0]), xy[1], w), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        else:\n",
    "            ds = ds.map(lambda x, y: (aug_fn(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        return ds\n",
    "    \n",
    "    train_ds = create_dataset(data['X_train'], data['y_train'], sample_weights)\n",
    "    train_ds = train_ds.shuffle(10000).batch(batch).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    val_ds = create_dataset(data['X_val'], data['y_val'])\n",
    "    val_ds = val_ds.batch(batch).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    # ÂõûË∞ÉÂáΩÊï∞\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    ckpt = f\"models/cldnn_classifier_{model_idx}.keras\"\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_sparse_categorical_accuracy', patience=20, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_sparse_categorical_accuracy', factor=0.5, patience=10),\n",
    "        ModelCheckpoint(ckpt, save_best_only=True, monitor='val_sparse_categorical_accuracy', save_format=\"tf\")\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nüî• ËÆ≠ÁªÉCLDNNÊ®°Âûã {model_idx + 1}...\")\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# ---------- ‰∏ªÂáΩÊï∞ ----------\n",
    "def main():\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    os.makedirs(\"visualizations\", exist_ok=True)\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"üöÄ ÂºÄÂßãËÆ≠ÁªÉCLDNNÂπ≤Êâ∞ÂàÜÁ±ªÊ®°Âûã\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Âä†ËΩΩÊï∞ÊçÆ\n",
    "    print(\"‚è≥ Âä†ËΩΩÊï∞ÊçÆÈõÜ...\")\n",
    "    dataset = load_dataset(\"/root/yxun/20250826/dataset/interference_signals_natural_same_freq_1019.npz\")\n",
    "    data = preprocess_data(dataset)\n",
    "    \n",
    "    # ËÆ≠ÁªÉÂèÇÊï∞\n",
    "    n_models = 1  # ËÆ≠ÁªÉÂçï‰∏™Ê®°ÂûãÔºàÂ¶ÇÈúÄÈõÜÊàêÂèØÊîπ‰∏∫3Ôºâ\n",
    "    epochs = 120\n",
    "    batch_size = 128\n",
    "\n",
    "    # ËÆ≠ÁªÉÊ®°Âûã\n",
    "    model = train_single_model(data, model_idx=0, epochs=epochs, batch=batch_size)\n",
    "    \n",
    "    # ËØÑ‰º∞ÊµãËØïÈõÜ\n",
    "    test_loss, test_acc = model.evaluate(\n",
    "        data['X_test'], data['y_test'],\n",
    "        batch_size=batch_size, verbose=0\n",
    "    )\n",
    "    print(f\"\\nüìä ÊµãËØïÈõÜÂáÜÁ°ÆÁéá: {test_acc:.4f}\")\n",
    "    \n",
    "    # ‰øùÂ≠òÊúÄÁªàÊ®°Âûã\n",
    "    model.save(\"models/cldnn_classifier_final.keras\", save_format=\"tf\")\n",
    "    print(\"\\n‚úÖ ËÆ≠ÁªÉÂÆåÊàêÔºÅÊ®°ÂûãÂ∑≤‰øùÂ≠òËá≥ models/cldnn_classifier_final.keras\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a0bf377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ÊàêÂäüËÆæÁΩÆ‰∏≠ÊñáÂ≠ó‰Ωì: ['WenQuanYi Micro Hei']\n",
      "================================================================================\n",
      "üöÄ CLDNNÂπ≤Êâ∞ÂàÜÁ±ªÊ®°ÂûãËØÑ‰º∞\n",
      "================================================================================\n",
      "\n",
      "üîç Âä†ËΩΩÊï∞ÊçÆÈõÜ...\n",
      "\n",
      "üîß Âä†ËΩΩËÆ≠ÁªÉÂ•ΩÁöÑÊ®°Âûã...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 00:01:52.124582: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-10-22 00:01:52.125528: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-10-22 00:01:52.126596: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-10-22 00:01:52.237183: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-10-22 00:01:52.237961: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-10-22 00:01:52.238677: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ÊàêÂäüÂä†ËΩΩÊ®°Âûã: models/cldnn_classifier_final.keras\n",
      "\n",
      "üîÆ ËøõË°åÊ®°ÂûãÈ¢ÑÊµã...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 00:01:52.858117: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-10-22 00:01:52.859371: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-10-22 00:01:52.860144: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-10-22 00:01:52.962749: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-10-22 00:01:52.963560: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-10-22 00:01:52.964313: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2532/2532 [==============================] - 22s 8ms/step\n",
      "\n",
      "üé® ÁîüÊàêÊ∑∑Ê∑ÜÁü©Èòµ...\n",
      "\n",
      "üìà ÁîüÊàêJNRÂáÜÁ°ÆÁéáÊõ≤Á∫ø...\n",
      "\n",
      "üìù ÁîüÊàêËØÑ‰º∞Êä•Âëä...\n",
      "\n",
      "==================================================\n",
      "üìä ËØÑ‰º∞ÁªìÊûúÊëòË¶Å\n",
      "==================================================\n",
      "Êï¥‰ΩìÂàÜÁ±ªÂáÜÁ°ÆÁéá: 0.8864\n",
      "\n",
      "ÂêÑJNR‰∏ãÁöÑÂàÜÁ±ªÂáÜÁ°ÆÁéá:\n",
      "  JNR=-10dB: 0.6071\n",
      "  JNR=-5dB: 0.7481\n",
      "  JNR=0dB: 0.8433\n",
      "  JNR=5dB: 0.9063\n",
      "  JNR=10dB: 0.9464\n",
      "  JNR=15dB: 0.9716\n",
      "  JNR=20dB: 0.9837\n",
      "  JNR=25dB: 0.9848\n",
      "  JNR=30dB: 0.9862\n",
      "\n",
      "‚úÖ ËØÑ‰º∞ÂÆåÊàêÔºÅÁªìÊûúÂ∑≤‰øùÂ≠òËá≥ reports/cldnn_evaluation_report.json\n"
     ]
    }
   ],
   "source": [
    "# evaluate_cldnn_classifier.py\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (accuracy_score, confusion_matrix, \n",
    "                           classification_report)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# ---------- ‰∏≠ÊñáÂ≠ó‰ΩìËÆæÁΩÆ ----------\n",
    "def set_chinese_font():\n",
    "    \"\"\"ÂÆâÂÖ®ËÆæÁΩÆ‰∏≠ÊñáÂ≠ó‰Ωì\"\"\"\n",
    "    try:\n",
    "        font_paths = ['/usr/share/fonts/truetype/wqy/wqy-microhei.ttc',\n",
    "                     'C:/Windows/Fonts/simhei.ttf',\n",
    "                     '/System/Library/Fonts/PingFang.ttc']\n",
    "        for path in font_paths:\n",
    "            if os.path.exists(path):\n",
    "                fm.fontManager.addfont(path)\n",
    "                plt.rcParams['font.family'] = fm.FontProperties(fname=path).get_name()\n",
    "                plt.rcParams['axes.unicode_minus'] = False\n",
    "                print(f\"‚úÖ ÊàêÂäüËÆæÁΩÆ‰∏≠ÊñáÂ≠ó‰Ωì: {plt.rcParams['font.family']}\")\n",
    "                return True\n",
    "        plt.rcParams['font.family'] = ['SimHei', 'Arial Unicode MS']\n",
    "        plt.rcParams['axes.unicode_minus'] = False\n",
    "        print(\"‚ö†Ô∏è ‰ΩøÁî®Á≥ªÁªüÈªòËÆ§‰∏≠ÊñáÂ≠ó‰Ωì\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Â≠ó‰ΩìËÆæÁΩÆÂ§±Ë¥•: {e}\")\n",
    "        return False\n",
    "set_chinese_font()\n",
    "\n",
    "# ---------- Âä†ËΩΩÊï∞ÊçÆÈõÜ ----------\n",
    "def load_dataset(npz_path):\n",
    "    \"\"\"Âä†ËΩΩÊï∞ÊçÆÈõÜÂπ∂Â§ÑÁêÜÁ±ªÂûãËΩ¨Êç¢\"\"\"\n",
    "    data = np.load(npz_path, allow_pickle=True)\n",
    "    \n",
    "    # Âü∫Á°ÄÊï∞ÊçÆ\n",
    "    dataset = {\n",
    "        \"signals\": data[\"signals\"],\n",
    "        \"labels\": data[\"labels\"].astype(np.int32),\n",
    "        \"jnr_values\": data[\"jnr_values\"].astype(np.float32),\n",
    "        \"fs\": float(data[\"fs\"]),\n",
    "        \"L\": int(data[\"L\"])\n",
    "    }\n",
    "    \n",
    "    # Â§ÑÁêÜÂπ≤Êâ∞Á±ªÂûãÂêçÁß∞\n",
    "    if \"interference_type_names\" in data:\n",
    "        type_names = data[\"interference_type_names\"].item() if isinstance(data[\"interference_type_names\"], np.ndarray) else data[\"interference_type_names\"]\n",
    "    else:\n",
    "        type_names = {\n",
    "            \"satellite_signal\": \"Satellite_Signal\",\n",
    "            \"single_tone\": \"Single_Tone\",\n",
    "            \"comb_spectra\": \"Comb_Spectra\",\n",
    "            \"sweeping\": \"Sweeping-LFM\",\n",
    "            \"pulse\": \"Pulse\",\n",
    "            \"frequency_hopping\": \"Frequency_Hopping\",\n",
    "            \"noise_fm\": \"Noise_FM\",\n",
    "            \"noise_am\": \"Noise_AM\",\n",
    "            \"random_combination\": \"Random_Combination\"\n",
    "        }\n",
    "        print(\"‚ö†Ô∏è Êú™ÊâæÂà∞Âπ≤Êâ∞Á±ªÂûãÂêçÁß∞Ôºå‰ΩøÁî®ÈªòËÆ§ÂÄº\")\n",
    "    \n",
    "    # ÂàõÂª∫Ê†áÁ≠æÊò†Â∞Ñ\n",
    "    if \"type_to_label\" in data:\n",
    "        type2label = data[\"type_to_label\"].item() if isinstance(data[\"type_to_label\"], np.ndarray) else data[\"type_to_label\"]\n",
    "    else:\n",
    "        type2label = {\n",
    "            \"satellite_signal\": 0,\n",
    "            \"single_tone\": 1,\n",
    "            \"comb_spectra\": 2,\n",
    "            \"sweeping\": 3,\n",
    "            \"pulse\": 4,\n",
    "            \"frequency_hopping\": 5,\n",
    "            \"noise_fm\": 6,\n",
    "            \"noise_am\": 7,\n",
    "            \"random_combination\": 8\n",
    "        }\n",
    "    \n",
    "    label2name = {int(i): str(type_names[k]) for k, i in type2label.items()}\n",
    "    \n",
    "    return {\n",
    "        \"signals\": data[\"signals\"],\n",
    "        \"labels\": data[\"labels\"].astype(np.int32),\n",
    "        \"jnr_values\": data[\"jnr_values\"].astype(np.float32),\n",
    "        \"label2name\": label2name,\n",
    "        \"L\": int(data[\"L\"])\n",
    "    }\n",
    "\n",
    "# ---------- Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜ ----------\n",
    "def preprocess_data(dataset):\n",
    "    \"\"\"È¢ÑÂ§ÑÁêÜÊï∞ÊçÆÔºà‰ªÖÂàÜÁ±ª‰ªªÂä°Ôºâ\"\"\"\n",
    "    # ‰ø°Âè∑Ê†áÂáÜÂåñ\n",
    "    signals = np.array([StandardScaler().fit_transform(s.reshape(-1, 1)).ravel() \n",
    "                       for s in dataset[\"signals\"]])\n",
    "\n",
    "    return signals, dataset[\"labels\"], dataset[\"jnr_values\"], dataset[\"label2name\"]\n",
    "\n",
    "# ---------- Âä†ËΩΩÊ®°Âûã ----------\n",
    "def load_model(model_path):\n",
    "    \"\"\"Âä†ËΩΩËÆ≠ÁªÉÂ•ΩÁöÑCLDNNÊ®°Âûã\"\"\"\n",
    "    if os.path.exists(model_path):\n",
    "        try:\n",
    "            model = tf.keras.models.load_model(model_path)\n",
    "            print(f\"‚úÖ ÊàêÂäüÂä†ËΩΩÊ®°Âûã: {model_path}\")\n",
    "            return model\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Âä†ËΩΩÊ®°ÂûãÂ§±Ë¥•: {e}\")\n",
    "            return None\n",
    "    print(f\"‚ö†Ô∏è Êú™ÊâæÂà∞Ê®°Âûã: {model_path}\")\n",
    "    return None\n",
    "\n",
    "# ---------- ËÆ°ÁÆóJNRÂáÜÁ°ÆÁéá ----------\n",
    "def calculate_jnr_accuracy(y_true, y_pred, jnr_values, jnr_range):\n",
    "    \"\"\"ËÆ°ÁÆóÊØè‰∏™JNR‰∏ãÁöÑÂàÜÁ±ªÂáÜÁ°ÆÁéá\"\"\"\n",
    "    jnr_acc = {}\n",
    "    for jnr in jnr_range:\n",
    "        mask = jnr_values == jnr\n",
    "        if np.sum(mask) > 0:\n",
    "            jnr_acc[jnr] = accuracy_score(y_true[mask], y_pred[mask])\n",
    "        else:\n",
    "            jnr_acc[jnr] = np.nan\n",
    "    return jnr_acc\n",
    "\n",
    "# ---------------------- ÁªòÂà∂Ê∑∑Ê∑ÜÁü©Èòµ ----------------------\n",
    "def plot_confusion_matrix(cm, labels, title, xlabel, ylabel, filename, dpi=150, rotate_x=False):\n",
    "    \"\"\"‰∏ì‰∏öÊ∑∑Ê∑ÜÁü©ÈòµÂèØËßÜÂåñ\"\"\"\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
    "    cm_normalized = np.nan_to_num(cm_normalized)\n",
    "\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    ax = sns.heatmap(cm_normalized,\n",
    "                     annot=True,\n",
    "                     fmt='.2f',\n",
    "                     cmap='Blues',\n",
    "                     xticklabels=labels,\n",
    "                     yticklabels=labels,\n",
    "                     square=True,\n",
    "                     annot_kws={\"size\": 14})\n",
    "    cbar = ax.collections[0].colorbar\n",
    "    cbar.ax.tick_params(labelsize=14)\n",
    "\n",
    "    plt.title(title, pad=20, fontsize=18)\n",
    "    plt.xlabel(xlabel, fontsize=16)\n",
    "    plt.ylabel(ylabel, fontsize=16)\n",
    "    plt.xticks(rotation=45 if rotate_x else 0, ha='right' if rotate_x else 'center', fontsize=14)\n",
    "    plt.yticks(rotation=0, fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, dpi=dpi)\n",
    "    plt.close()\n",
    "    \n",
    "# ---------- ÁªòÂà∂JNRÂáÜÁ°ÆÁéáÊõ≤Á∫ø ----------\n",
    "def plot_jnr_accuracy(jnr_acc, filename):\n",
    "    \"\"\"ÁªòÂà∂JNR-ÂáÜÁ°ÆÁéáÊõ≤Á∫ø\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    valid_jnr = [j for j in jnr_acc if not np.isnan(jnr_acc[j])]\n",
    "    valid_acc = [jnr_acc[j] for j in valid_jnr]\n",
    "    \n",
    "    plt.plot(valid_jnr, valid_acc, 'o-', linewidth=2, markersize=8)\n",
    "    plt.xlabel('JNR (dB)', fontsize=12)\n",
    "    plt.ylabel('ÂàÜÁ±ªÂáÜÁ°ÆÁéá', fontsize=12)\n",
    "    plt.title('‰∏çÂêåJNR‰∏ãÁöÑÂπ≤Êâ∞ËØÜÂà´ÂáÜÁ°ÆÁéá', fontsize=14)\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.xticks(list(jnr_acc.keys()))\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.savefig(filename, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "# ---------- ‰∏ªËØÑ‰º∞ÂáΩÊï∞ ----------\n",
    "def evaluate(model_path=\"models/cldnn_classifier_final.keras\", \n",
    "             npz_path=\"/path/to/dataset.npz\"):\n",
    "    \"\"\"‰∏ªËØÑ‰º∞ÊµÅÁ®ã\"\"\"\n",
    "    os.makedirs(\"visualizations\", exist_ok=True)\n",
    "    os.makedirs(\"reports\", exist_ok=True)\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"üöÄ CLDNNÂπ≤Êâ∞ÂàÜÁ±ªÊ®°ÂûãËØÑ‰º∞\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # 1. Âä†ËΩΩÊï∞ÊçÆ\n",
    "    print(\"\\nüîç Âä†ËΩΩÊï∞ÊçÆÈõÜ...\")\n",
    "    dataset = load_dataset(npz_path)\n",
    "    X_test, y_test, jnr_test, label2name = preprocess_data(dataset)\n",
    "    \n",
    "    # 2. Âä†ËΩΩÊ®°Âûã\n",
    "    print(\"\\nüîß Âä†ËΩΩËÆ≠ÁªÉÂ•ΩÁöÑÊ®°Âûã...\")\n",
    "    model = load_model(model_path)\n",
    "    if not model:\n",
    "        raise ValueError(\"‚ùå Ê≤°ÊúâÂèØÁî®ÁöÑÊ®°ÂûãËøõË°åËØÑ‰º∞\")\n",
    "    \n",
    "    # 3. Ê®°ÂûãÈ¢ÑÊµã\n",
    "    print(\"\\nüîÆ ËøõË°åÊ®°ÂûãÈ¢ÑÊµã...\")\n",
    "    y_pred = np.argmax(model.predict(X_test, verbose=1), axis=1)\n",
    "    \n",
    "    # 4. ËÆ°ÁÆóJNRÂáÜÁ°ÆÁéá\n",
    "    jnr_range = np.arange(-10, 31, 5)  # [-10, -5, 0, 5, ..., 30]\n",
    "    jnr_acc = calculate_jnr_accuracy(y_test, y_pred, jnr_test, jnr_range)\n",
    "    \n",
    "    # 5. ÁîüÊàêÊ∑∑Ê∑ÜÁü©Èòµ\n",
    "    print(\"\\nüé® ÁîüÊàêÊ∑∑Ê∑ÜÁü©Èòµ...\")\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    class_names = [label2name[i] for i in sorted(label2name.keys())]\n",
    "    plot_confusion_matrix(\n",
    "        cm=cm,\n",
    "        labels=class_names,\n",
    "        title=\"CLDNN Classfication Confusion Matrix\",\n",
    "        xlabel=\"Predicted\",\n",
    "        ylabel=\"True\",\n",
    "        filename=\"visualizations/cldnn_confusion_matrix.png\",\n",
    "        dpi=300,\n",
    "        rotate_x=True\n",
    "    )\n",
    "    \n",
    "    # 6. ÁªòÂà∂JNRÂáÜÁ°ÆÁéáÊõ≤Á∫ø\n",
    "    print(\"\\nüìà ÁîüÊàêJNRÂáÜÁ°ÆÁéáÊõ≤Á∫ø...\")\n",
    "    plot_jnr_accuracy(jnr_acc, \"visualizations/cldnn_jnr_accuracy.png\")\n",
    "    \n",
    "    # 7. ‰øùÂ≠òËØÑ‰º∞Êä•Âëä\n",
    "    print(\"\\nüìù ÁîüÊàêËØÑ‰º∞Êä•Âëä...\")\n",
    "    report = {\n",
    "        \"overall_accuracy\": float(accuracy_score(y_test, y_pred)),\n",
    "        \"jnr_accuracy\": {int(j): float(acc) if not np.isnan(acc) else None \n",
    "                         for j, acc in jnr_acc.items()},\n",
    "        \"confusion_matrix\": cm.tolist(),\n",
    "        \"class_names\": class_names,\n",
    "        \"classification_report\": classification_report(\n",
    "            y_test, y_pred, \n",
    "            target_names=class_names,\n",
    "            output_dict=True\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    with open(\"reports/cldnn_evaluation_report.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(report, f, indent=4, ensure_ascii=False)\n",
    "    \n",
    "    # 8. ÊâìÂç∞ÁªìÊûú\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"üìä ËØÑ‰º∞ÁªìÊûúÊëòË¶Å\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Êï¥‰ΩìÂàÜÁ±ªÂáÜÁ°ÆÁéá: {report['overall_accuracy']:.4f}\")\n",
    "    \n",
    "    print(\"\\nÂêÑJNR‰∏ãÁöÑÂàÜÁ±ªÂáÜÁ°ÆÁéá:\")\n",
    "    for jnr in sorted(jnr_acc.keys()):\n",
    "        acc = jnr_acc[jnr]\n",
    "        acc_str = f\"{acc:.4f}\" if not np.isnan(acc) else \"N/A\"\n",
    "        print(f\"  JNR={jnr}dB: {acc_str}\")\n",
    "    \n",
    "    print(\"\\n‚úÖ ËØÑ‰º∞ÂÆåÊàêÔºÅÁªìÊûúÂ∑≤‰øùÂ≠òËá≥ reports/cldnn_evaluation_report.json\")\n",
    "\n",
    "# ---------- ‰∏ªÁ®ãÂ∫è ----------\n",
    "if __name__ == \"__main__\":\n",
    "    evaluate(\n",
    "        model_path=\"models/cldnn_classifier_final.keras\",\n",
    "        npz_path=\"/root/yxun/20250826/dataset/interference_signals_natural_same_freq_1019.npz\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2698a9e9",
   "metadata": {},
   "source": [
    "CLDNN_final_1021.ipynbËØÑ‰º∞ÁªìÊûúÊëòË¶Å\n",
    "==================================================\n",
    "Êï¥‰ΩìÂàÜÁ±ªÂáÜÁ°ÆÁéá: 0.8864\n",
    "\n",
    "ÂêÑJNR‰∏ãÁöÑÂàÜÁ±ªÂáÜÁ°ÆÁéá:\n",
    "  JNR=-10dB: 0.6071\n",
    "  JNR=-5dB: 0.7481\n",
    "  JNR=0dB: 0.8433\n",
    "  JNR=5dB: 0.9063\n",
    "  JNR=10dB: 0.9464\n",
    "  JNR=15dB: 0.9716\n",
    "  JNR=20dB: 0.9837\n",
    "  JNR=25dB: 0.9848\n",
    "  JNR=30dB: 0.9862"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
