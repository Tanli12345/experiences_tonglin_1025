{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1543fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 18:06:37.355519: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-21 18:06:37.394079: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-21 18:06:37.924485: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 成功设置中文字体: ['WenQuanYi Micro Hei']\n",
      "================================================================================\n",
      "🚀 开始训练ResNet干扰分类模型\n",
      "================================================================================\n",
      "⏳ 加载数据集...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 18:06:57.551110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46590 MB memory:  -> device: 0, name: NVIDIA vGPU-48GB, pci bus id: 0000:d8:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔥 训练ResNet模型 1...\n",
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 18:06:58.774609: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int32 and shape [56700]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2025-10-21 18:06:58.774824: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int32 and shape [56700]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2025-10-21 18:07:03.435966: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2025-10-21 18:07:03.689309: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-10-21 18:07:03.717926: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f45cdd9fb20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-10-21 18:07:03.717944: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA vGPU-48GB, Compute Capability 8.9\n",
      "2025-10-21 18:07:03.721607: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-10-21 18:07:03.829662: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "443/443 [==============================] - ETA: 0s - loss: 1.0382 - sparse_categorical_accuracy: 0.5909"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 18:07:21.247813: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int32 and shape [12150]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "443/443 [==============================] - 24s 31ms/step - loss: 1.0382 - sparse_categorical_accuracy: 0.5909 - val_loss: 0.8729 - val_sparse_categorical_accuracy: 0.6290 - lr: 0.0010\n",
      "Epoch 2/120\n",
      "443/443 [==============================] - 14s 30ms/step - loss: 0.8388 - sparse_categorical_accuracy: 0.6524 - val_loss: 0.8267 - val_sparse_categorical_accuracy: 0.6600 - lr: 0.0010\n",
      "Epoch 3/120\n",
      "443/443 [==============================] - 14s 30ms/step - loss: 0.7816 - sparse_categorical_accuracy: 0.6692 - val_loss: 0.7220 - val_sparse_categorical_accuracy: 0.6930 - lr: 0.0010\n",
      "Epoch 4/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.7551 - sparse_categorical_accuracy: 0.6797 - val_loss: 1.4538 - val_sparse_categorical_accuracy: 0.5230 - lr: 0.0010\n",
      "Epoch 5/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.7348 - sparse_categorical_accuracy: 0.6864 - val_loss: 1.1451 - val_sparse_categorical_accuracy: 0.5851 - lr: 0.0010\n",
      "Epoch 6/120\n",
      "443/443 [==============================] - 13s 29ms/step - loss: 0.7118 - sparse_categorical_accuracy: 0.6939 - val_loss: 0.8131 - val_sparse_categorical_accuracy: 0.6721 - lr: 0.0010\n",
      "Epoch 7/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.6897 - sparse_categorical_accuracy: 0.7039 - val_loss: 0.6767 - val_sparse_categorical_accuracy: 0.7093 - lr: 0.0010\n",
      "Epoch 8/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.6612 - sparse_categorical_accuracy: 0.7208 - val_loss: 0.6527 - val_sparse_categorical_accuracy: 0.7058 - lr: 0.0010\n",
      "Epoch 9/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.6379 - sparse_categorical_accuracy: 0.7292 - val_loss: 0.6520 - val_sparse_categorical_accuracy: 0.7241 - lr: 0.0010\n",
      "Epoch 10/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.6253 - sparse_categorical_accuracy: 0.7339 - val_loss: 0.5648 - val_sparse_categorical_accuracy: 0.7527 - lr: 0.0010\n",
      "Epoch 11/120\n",
      "443/443 [==============================] - 14s 28ms/step - loss: 0.6102 - sparse_categorical_accuracy: 0.7471 - val_loss: 0.6425 - val_sparse_categorical_accuracy: 0.7443 - lr: 0.0010\n",
      "Epoch 12/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.5886 - sparse_categorical_accuracy: 0.7560 - val_loss: 0.8517 - val_sparse_categorical_accuracy: 0.6839 - lr: 0.0010\n",
      "Epoch 13/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.5772 - sparse_categorical_accuracy: 0.7633 - val_loss: 0.7490 - val_sparse_categorical_accuracy: 0.7049 - lr: 0.0010\n",
      "Epoch 14/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.5603 - sparse_categorical_accuracy: 0.7680 - val_loss: 0.5712 - val_sparse_categorical_accuracy: 0.7799 - lr: 0.0010\n",
      "Epoch 15/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.5619 - sparse_categorical_accuracy: 0.7704 - val_loss: 0.5829 - val_sparse_categorical_accuracy: 0.7597 - lr: 0.0010\n",
      "Epoch 16/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.5477 - sparse_categorical_accuracy: 0.7762 - val_loss: 0.5981 - val_sparse_categorical_accuracy: 0.7577 - lr: 0.0010\n",
      "Epoch 17/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.5358 - sparse_categorical_accuracy: 0.7829 - val_loss: 0.5520 - val_sparse_categorical_accuracy: 0.7886 - lr: 0.0010\n",
      "Epoch 18/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.5326 - sparse_categorical_accuracy: 0.7803 - val_loss: 0.5643 - val_sparse_categorical_accuracy: 0.7823 - lr: 0.0010\n",
      "Epoch 19/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.5268 - sparse_categorical_accuracy: 0.7843 - val_loss: 0.7515 - val_sparse_categorical_accuracy: 0.7202 - lr: 0.0010\n",
      "Epoch 20/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.5187 - sparse_categorical_accuracy: 0.7871 - val_loss: 0.5476 - val_sparse_categorical_accuracy: 0.7942 - lr: 0.0010\n",
      "Epoch 21/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.5179 - sparse_categorical_accuracy: 0.7876 - val_loss: 0.5298 - val_sparse_categorical_accuracy: 0.7970 - lr: 0.0010\n",
      "Epoch 22/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.5096 - sparse_categorical_accuracy: 0.7910 - val_loss: 0.5326 - val_sparse_categorical_accuracy: 0.7841 - lr: 0.0010\n",
      "Epoch 23/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.5039 - sparse_categorical_accuracy: 0.7949 - val_loss: 0.7072 - val_sparse_categorical_accuracy: 0.7467 - lr: 0.0010\n",
      "Epoch 24/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.5007 - sparse_categorical_accuracy: 0.7963 - val_loss: 0.6954 - val_sparse_categorical_accuracy: 0.7441 - lr: 0.0010\n",
      "Epoch 25/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.4960 - sparse_categorical_accuracy: 0.7974 - val_loss: 0.5321 - val_sparse_categorical_accuracy: 0.7952 - lr: 0.0010\n",
      "Epoch 26/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.4882 - sparse_categorical_accuracy: 0.7989 - val_loss: 0.5852 - val_sparse_categorical_accuracy: 0.7783 - lr: 0.0010\n",
      "Epoch 27/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.4901 - sparse_categorical_accuracy: 0.7993 - val_loss: 0.5659 - val_sparse_categorical_accuracy: 0.7802 - lr: 0.0010\n",
      "Epoch 28/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.4863 - sparse_categorical_accuracy: 0.8002 - val_loss: 0.5722 - val_sparse_categorical_accuracy: 0.7802 - lr: 0.0010\n",
      "Epoch 29/120\n",
      "443/443 [==============================] - 13s 27ms/step - loss: 0.4803 - sparse_categorical_accuracy: 0.8035 - val_loss: 0.4668 - val_sparse_categorical_accuracy: 0.8104 - lr: 0.0010\n",
      "Epoch 30/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.4752 - sparse_categorical_accuracy: 0.8057 - val_loss: 0.7003 - val_sparse_categorical_accuracy: 0.7555 - lr: 0.0010\n",
      "Epoch 31/120\n",
      "443/443 [==============================] - 14s 28ms/step - loss: 0.4745 - sparse_categorical_accuracy: 0.8054 - val_loss: 0.5769 - val_sparse_categorical_accuracy: 0.7931 - lr: 0.0010\n",
      "Epoch 32/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.4712 - sparse_categorical_accuracy: 0.8051 - val_loss: 0.4481 - val_sparse_categorical_accuracy: 0.8187 - lr: 0.0010\n",
      "Epoch 33/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.4698 - sparse_categorical_accuracy: 0.8072 - val_loss: 0.4122 - val_sparse_categorical_accuracy: 0.8351 - lr: 0.0010\n",
      "Epoch 34/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.4644 - sparse_categorical_accuracy: 0.8085 - val_loss: 1.0331 - val_sparse_categorical_accuracy: 0.6896 - lr: 0.0010\n",
      "Epoch 35/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.4595 - sparse_categorical_accuracy: 0.8101 - val_loss: 0.4819 - val_sparse_categorical_accuracy: 0.8147 - lr: 0.0010\n",
      "Epoch 36/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.4600 - sparse_categorical_accuracy: 0.8098 - val_loss: 0.8445 - val_sparse_categorical_accuracy: 0.7242 - lr: 0.0010\n",
      "Epoch 37/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.4569 - sparse_categorical_accuracy: 0.8126 - val_loss: 0.8701 - val_sparse_categorical_accuracy: 0.7333 - lr: 0.0010\n",
      "Epoch 38/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.4532 - sparse_categorical_accuracy: 0.8127 - val_loss: 0.5454 - val_sparse_categorical_accuracy: 0.7906 - lr: 0.0010\n",
      "Epoch 39/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.4546 - sparse_categorical_accuracy: 0.8128 - val_loss: 0.5461 - val_sparse_categorical_accuracy: 0.7904 - lr: 0.0010\n",
      "Epoch 40/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.4494 - sparse_categorical_accuracy: 0.8153 - val_loss: 0.4841 - val_sparse_categorical_accuracy: 0.8133 - lr: 0.0010\n",
      "Epoch 41/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.4470 - sparse_categorical_accuracy: 0.8176 - val_loss: 0.5116 - val_sparse_categorical_accuracy: 0.8078 - lr: 0.0010\n",
      "Epoch 42/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.4418 - sparse_categorical_accuracy: 0.8162 - val_loss: 0.5068 - val_sparse_categorical_accuracy: 0.8039 - lr: 0.0010\n",
      "Epoch 43/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.4396 - sparse_categorical_accuracy: 0.8188 - val_loss: 0.4641 - val_sparse_categorical_accuracy: 0.8215 - lr: 0.0010\n",
      "Epoch 44/120\n",
      "443/443 [==============================] - 14s 28ms/step - loss: 0.4155 - sparse_categorical_accuracy: 0.8287 - val_loss: 0.6583 - val_sparse_categorical_accuracy: 0.7798 - lr: 5.0000e-04\n",
      "Epoch 45/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.4104 - sparse_categorical_accuracy: 0.8300 - val_loss: 0.4103 - val_sparse_categorical_accuracy: 0.8375 - lr: 5.0000e-04\n",
      "Epoch 46/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.4080 - sparse_categorical_accuracy: 0.8319 - val_loss: 0.4278 - val_sparse_categorical_accuracy: 0.8340 - lr: 5.0000e-04\n",
      "Epoch 47/120\n",
      "443/443 [==============================] - 14s 28ms/step - loss: 0.4022 - sparse_categorical_accuracy: 0.8346 - val_loss: 0.4749 - val_sparse_categorical_accuracy: 0.8185 - lr: 5.0000e-04\n",
      "Epoch 48/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.4022 - sparse_categorical_accuracy: 0.8337 - val_loss: 0.4061 - val_sparse_categorical_accuracy: 0.8423 - lr: 5.0000e-04\n",
      "Epoch 49/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.3996 - sparse_categorical_accuracy: 0.8336 - val_loss: 0.3979 - val_sparse_categorical_accuracy: 0.8403 - lr: 5.0000e-04\n",
      "Epoch 50/120\n",
      "443/443 [==============================] - 13s 29ms/step - loss: 0.3953 - sparse_categorical_accuracy: 0.8375 - val_loss: 0.4110 - val_sparse_categorical_accuracy: 0.8408 - lr: 5.0000e-04\n",
      "Epoch 51/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.3928 - sparse_categorical_accuracy: 0.8370 - val_loss: 0.4509 - val_sparse_categorical_accuracy: 0.8253 - lr: 5.0000e-04\n",
      "Epoch 52/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.3899 - sparse_categorical_accuracy: 0.8390 - val_loss: 0.4133 - val_sparse_categorical_accuracy: 0.8421 - lr: 5.0000e-04\n",
      "Epoch 53/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.3915 - sparse_categorical_accuracy: 0.8392 - val_loss: 0.4554 - val_sparse_categorical_accuracy: 0.8291 - lr: 5.0000e-04\n",
      "Epoch 54/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.3895 - sparse_categorical_accuracy: 0.8392 - val_loss: 0.4062 - val_sparse_categorical_accuracy: 0.8417 - lr: 5.0000e-04\n",
      "Epoch 55/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.3854 - sparse_categorical_accuracy: 0.8401 - val_loss: 0.4256 - val_sparse_categorical_accuracy: 0.8412 - lr: 5.0000e-04\n",
      "Epoch 56/120\n",
      "443/443 [==============================] - 14s 30ms/step - loss: 0.3845 - sparse_categorical_accuracy: 0.8418 - val_loss: 0.4258 - val_sparse_categorical_accuracy: 0.8407 - lr: 5.0000e-04\n",
      "Epoch 57/120\n",
      "443/443 [==============================] - 14s 30ms/step - loss: 0.3833 - sparse_categorical_accuracy: 0.8422 - val_loss: 0.4020 - val_sparse_categorical_accuracy: 0.8477 - lr: 5.0000e-04\n",
      "Epoch 58/120\n",
      "443/443 [==============================] - 14s 28ms/step - loss: 0.3819 - sparse_categorical_accuracy: 0.8411 - val_loss: 0.4029 - val_sparse_categorical_accuracy: 0.8420 - lr: 5.0000e-04\n",
      "Epoch 59/120\n",
      "443/443 [==============================] - 14s 28ms/step - loss: 0.3813 - sparse_categorical_accuracy: 0.8430 - val_loss: 0.4680 - val_sparse_categorical_accuracy: 0.8198 - lr: 5.0000e-04\n",
      "Epoch 60/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.3788 - sparse_categorical_accuracy: 0.8429 - val_loss: 0.3932 - val_sparse_categorical_accuracy: 0.8426 - lr: 5.0000e-04\n",
      "Epoch 61/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.3794 - sparse_categorical_accuracy: 0.8433 - val_loss: 0.4496 - val_sparse_categorical_accuracy: 0.8255 - lr: 5.0000e-04\n",
      "Epoch 62/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.3750 - sparse_categorical_accuracy: 0.8453 - val_loss: 0.4240 - val_sparse_categorical_accuracy: 0.8398 - lr: 5.0000e-04\n",
      "Epoch 63/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.3745 - sparse_categorical_accuracy: 0.8443 - val_loss: 0.4000 - val_sparse_categorical_accuracy: 0.8437 - lr: 5.0000e-04\n",
      "Epoch 64/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.3754 - sparse_categorical_accuracy: 0.8448 - val_loss: 0.4587 - val_sparse_categorical_accuracy: 0.8310 - lr: 5.0000e-04\n",
      "Epoch 65/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.3748 - sparse_categorical_accuracy: 0.8451 - val_loss: 0.4053 - val_sparse_categorical_accuracy: 0.8474 - lr: 5.0000e-04\n",
      "Epoch 66/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.3716 - sparse_categorical_accuracy: 0.8459 - val_loss: 0.4123 - val_sparse_categorical_accuracy: 0.8436 - lr: 5.0000e-04\n",
      "Epoch 67/120\n",
      "443/443 [==============================] - 14s 28ms/step - loss: 0.3710 - sparse_categorical_accuracy: 0.8454 - val_loss: 0.3883 - val_sparse_categorical_accuracy: 0.8437 - lr: 5.0000e-04\n",
      "Epoch 68/120\n",
      "443/443 [==============================] - 14s 28ms/step - loss: 0.3538 - sparse_categorical_accuracy: 0.8541 - val_loss: 0.3945 - val_sparse_categorical_accuracy: 0.8461 - lr: 2.5000e-04\n",
      "Epoch 69/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.3504 - sparse_categorical_accuracy: 0.8545 - val_loss: 0.3900 - val_sparse_categorical_accuracy: 0.8502 - lr: 2.5000e-04\n",
      "Epoch 70/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.3478 - sparse_categorical_accuracy: 0.8547 - val_loss: 0.3738 - val_sparse_categorical_accuracy: 0.8525 - lr: 2.5000e-04\n",
      "Epoch 71/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.3497 - sparse_categorical_accuracy: 0.8549 - val_loss: 0.4052 - val_sparse_categorical_accuracy: 0.8426 - lr: 2.5000e-04\n",
      "Epoch 72/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.3461 - sparse_categorical_accuracy: 0.8564 - val_loss: 0.3936 - val_sparse_categorical_accuracy: 0.8490 - lr: 2.5000e-04\n",
      "Epoch 73/120\n",
      "443/443 [==============================] - 14s 28ms/step - loss: 0.3444 - sparse_categorical_accuracy: 0.8572 - val_loss: 0.3905 - val_sparse_categorical_accuracy: 0.8509 - lr: 2.5000e-04\n",
      "Epoch 74/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.3466 - sparse_categorical_accuracy: 0.8575 - val_loss: 0.3937 - val_sparse_categorical_accuracy: 0.8497 - lr: 2.5000e-04\n",
      "Epoch 75/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.3417 - sparse_categorical_accuracy: 0.8583 - val_loss: 0.3863 - val_sparse_categorical_accuracy: 0.8505 - lr: 2.5000e-04\n",
      "Epoch 76/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.3415 - sparse_categorical_accuracy: 0.8593 - val_loss: 0.4577 - val_sparse_categorical_accuracy: 0.8378 - lr: 2.5000e-04\n",
      "Epoch 77/120\n",
      "443/443 [==============================] - 13s 29ms/step - loss: 0.3392 - sparse_categorical_accuracy: 0.8599 - val_loss: 0.4053 - val_sparse_categorical_accuracy: 0.8481 - lr: 2.5000e-04\n",
      "Epoch 78/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.3385 - sparse_categorical_accuracy: 0.8598 - val_loss: 0.3861 - val_sparse_categorical_accuracy: 0.8513 - lr: 2.5000e-04\n",
      "Epoch 79/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.3410 - sparse_categorical_accuracy: 0.8582 - val_loss: 0.3893 - val_sparse_categorical_accuracy: 0.8507 - lr: 2.5000e-04\n",
      "Epoch 80/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.3373 - sparse_categorical_accuracy: 0.8614 - val_loss: 0.3928 - val_sparse_categorical_accuracy: 0.8458 - lr: 2.5000e-04\n",
      "Epoch 81/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.3310 - sparse_categorical_accuracy: 0.8638 - val_loss: 0.3730 - val_sparse_categorical_accuracy: 0.8537 - lr: 1.2500e-04\n",
      "Epoch 82/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.3282 - sparse_categorical_accuracy: 0.8626 - val_loss: 0.3788 - val_sparse_categorical_accuracy: 0.8509 - lr: 1.2500e-04\n",
      "Epoch 83/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.3279 - sparse_categorical_accuracy: 0.8633 - val_loss: 0.3716 - val_sparse_categorical_accuracy: 0.8556 - lr: 1.2500e-04\n",
      "Epoch 84/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.3274 - sparse_categorical_accuracy: 0.8652 - val_loss: 0.3795 - val_sparse_categorical_accuracy: 0.8547 - lr: 1.2500e-04\n",
      "Epoch 85/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.3269 - sparse_categorical_accuracy: 0.8640 - val_loss: 0.3853 - val_sparse_categorical_accuracy: 0.8524 - lr: 1.2500e-04\n",
      "Epoch 86/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.3255 - sparse_categorical_accuracy: 0.8668 - val_loss: 0.3706 - val_sparse_categorical_accuracy: 0.8526 - lr: 1.2500e-04\n",
      "Epoch 87/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.3198 - sparse_categorical_accuracy: 0.8653 - val_loss: 0.3729 - val_sparse_categorical_accuracy: 0.8568 - lr: 1.2500e-04\n",
      "Epoch 88/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.3229 - sparse_categorical_accuracy: 0.8662 - val_loss: 0.3770 - val_sparse_categorical_accuracy: 0.8572 - lr: 1.2500e-04\n",
      "Epoch 89/120\n",
      "443/443 [==============================] - 14s 28ms/step - loss: 0.3218 - sparse_categorical_accuracy: 0.8663 - val_loss: 0.3877 - val_sparse_categorical_accuracy: 0.8525 - lr: 1.2500e-04\n",
      "Epoch 90/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.3191 - sparse_categorical_accuracy: 0.8671 - val_loss: 0.3811 - val_sparse_categorical_accuracy: 0.8535 - lr: 1.2500e-04\n",
      "Epoch 91/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.3205 - sparse_categorical_accuracy: 0.8659 - val_loss: 0.3783 - val_sparse_categorical_accuracy: 0.8518 - lr: 1.2500e-04\n",
      "Epoch 92/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.3208 - sparse_categorical_accuracy: 0.8678 - val_loss: 0.3900 - val_sparse_categorical_accuracy: 0.8474 - lr: 1.2500e-04\n",
      "Epoch 93/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.3219 - sparse_categorical_accuracy: 0.8664 - val_loss: 0.3780 - val_sparse_categorical_accuracy: 0.8522 - lr: 1.2500e-04\n",
      "Epoch 94/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.3187 - sparse_categorical_accuracy: 0.8666 - val_loss: 0.3823 - val_sparse_categorical_accuracy: 0.8498 - lr: 1.2500e-04\n",
      "Epoch 95/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.3157 - sparse_categorical_accuracy: 0.8681 - val_loss: 0.3751 - val_sparse_categorical_accuracy: 0.8531 - lr: 1.2500e-04\n",
      "Epoch 96/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.3150 - sparse_categorical_accuracy: 0.8679 - val_loss: 0.3800 - val_sparse_categorical_accuracy: 0.8538 - lr: 1.2500e-04\n",
      "Epoch 97/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.3168 - sparse_categorical_accuracy: 0.8682 - val_loss: 0.3724 - val_sparse_categorical_accuracy: 0.8559 - lr: 1.2500e-04\n",
      "Epoch 98/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.3149 - sparse_categorical_accuracy: 0.8689 - val_loss: 0.3907 - val_sparse_categorical_accuracy: 0.8503 - lr: 1.2500e-04\n",
      "Epoch 99/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.3100 - sparse_categorical_accuracy: 0.8717 - val_loss: 0.3756 - val_sparse_categorical_accuracy: 0.8548 - lr: 6.2500e-05\n",
      "Epoch 100/120\n",
      "443/443 [==============================] - 13s 28ms/step - loss: 0.3135 - sparse_categorical_accuracy: 0.8708 - val_loss: 0.3707 - val_sparse_categorical_accuracy: 0.8561 - lr: 6.2500e-05\n",
      "Epoch 101/120\n",
      "443/443 [==============================] - 14s 28ms/step - loss: 0.3104 - sparse_categorical_accuracy: 0.8711 - val_loss: 0.3748 - val_sparse_categorical_accuracy: 0.8556 - lr: 6.2500e-05\n",
      "Epoch 102/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.3072 - sparse_categorical_accuracy: 0.8732 - val_loss: 0.3777 - val_sparse_categorical_accuracy: 0.8537 - lr: 6.2500e-05\n",
      "Epoch 103/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.3075 - sparse_categorical_accuracy: 0.8720 - val_loss: 0.3793 - val_sparse_categorical_accuracy: 0.8543 - lr: 6.2500e-05\n",
      "Epoch 104/120\n",
      "443/443 [==============================] - 14s 28ms/step - loss: 0.3108 - sparse_categorical_accuracy: 0.8704 - val_loss: 0.3703 - val_sparse_categorical_accuracy: 0.8558 - lr: 6.2500e-05\n",
      "Epoch 105/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.3097 - sparse_categorical_accuracy: 0.8716 - val_loss: 0.3826 - val_sparse_categorical_accuracy: 0.8533 - lr: 6.2500e-05\n",
      "Epoch 106/120\n",
      "443/443 [==============================] - 14s 29ms/step - loss: 0.3106 - sparse_categorical_accuracy: 0.8700 - val_loss: 0.3728 - val_sparse_categorical_accuracy: 0.8561 - lr: 6.2500e-05\n",
      "Epoch 107/120\n",
      "443/443 [==============================] - 13s 29ms/step - loss: 0.3067 - sparse_categorical_accuracy: 0.8710 - val_loss: 0.3737 - val_sparse_categorical_accuracy: 0.8541 - lr: 6.2500e-05\n",
      "Epoch 108/120\n",
      "443/443 [==============================] - 13s 29ms/step - loss: 0.3095 - sparse_categorical_accuracy: 0.8713 - val_loss: 0.3787 - val_sparse_categorical_accuracy: 0.8534 - lr: 6.2500e-05\n",
      "\n",
      "📊 测试集准确率: 0.8535\n",
      "\n",
      "✅ 训练完成！模型已保存至 models/resnet_classifier_final.keras\n"
     ]
    }
   ],
   "source": [
    "# train_resnet_classifier.py\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Conv1D, MaxPool1D, Dense, \n",
    "                                   Dropout, BatchNormalization, ReLU,\n",
    "                                   GlobalAveragePooling1D, Add, Reshape)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import (EarlyStopping, ReduceLROnPlateau, \n",
    "                                      ModelCheckpoint)\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# ---------- GPU配置 ----------\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# ---------- 中文字体设置 ----------\n",
    "def set_chinese_font():\n",
    "    \"\"\"安全设置中文字体\"\"\"\n",
    "    try:\n",
    "        font_paths = ['/usr/share/fonts/truetype/wqy/wqy-microhei.ttc',\n",
    "                     'C:/Windows/Fonts/simhei.ttf',\n",
    "                     '/System/Library/Fonts/PingFang.ttc']\n",
    "        for path in font_paths:\n",
    "            if os.path.exists(path):\n",
    "                fm.fontManager.addfont(path)\n",
    "                plt.rcParams['font.family'] = fm.FontProperties(fname=path).get_name()\n",
    "                plt.rcParams['axes.unicode_minus'] = False\n",
    "                print(f\"✅ 成功设置中文字体: {plt.rcParams['font.family']}\")\n",
    "                return True\n",
    "        plt.rcParams['font.family'] = ['SimHei', 'Arial Unicode MS']\n",
    "        plt.rcParams['axes.unicode_minus'] = False\n",
    "        print(\"⚠️ 使用系统默认中文字体\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 字体设置失败: {e}\")\n",
    "        return False\n",
    "set_chinese_font()\n",
    "\n",
    "# ---------- ResNet块定义 ----------\n",
    "def residual_block(x, filters, kernel_size=3, stride=1, conv_shortcut=False, name=None):\n",
    "    \"\"\"残差块实现（简化版）\"\"\"\n",
    "    shortcut = x\n",
    "    if conv_shortcut:\n",
    "        shortcut = Conv1D(filters, 1, strides=stride, name=name+'_shortcut')(x)\n",
    "        shortcut = BatchNormalization(name=name+'_bn_shortcut')(shortcut)\n",
    "    \n",
    "    x = Conv1D(filters, kernel_size, strides=stride, padding='same', name=name+'_conv1')(x)\n",
    "    x = BatchNormalization(name=name+'_bn1')(x)\n",
    "    x = ReLU(name=name+'_relu1')(x)\n",
    "    \n",
    "    x = Conv1D(filters, kernel_size, padding='same', name=name+'_conv2')(x)\n",
    "    x = BatchNormalization(name=name+'_bn2')(x)\n",
    "    \n",
    "    x = Add(name=name+'_add')([shortcut, x])\n",
    "    x = ReLU(name=name+'_out')(x)\n",
    "    return x\n",
    "\n",
    "# ---------- ResNet分类模型 ----------\n",
    "def build_resnet(input_shape, num_classes):\n",
    "    \"\"\"构建纯分类的ResNet模型\"\"\"\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # 重塑输入以增加特征维度\n",
    "    x = Reshape((input_shape[0], 1))(inputs)\n",
    "    \n",
    "    # 初始卷积层\n",
    "    x = Conv1D(64, 7, strides=2, padding='same', name='conv1')(x)\n",
    "    x = BatchNormalization(name='bn1')(x)\n",
    "    x = ReLU(name='relu1')(x)\n",
    "    x = MaxPool1D(3, strides=2, padding='same', name='pool1')(x)\n",
    "    \n",
    "    # 残差块堆叠\n",
    "    x = residual_block(x, 64, name='resblock1_1')\n",
    "    x = residual_block(x, 64, name='resblock1_2')\n",
    "    \n",
    "    x = residual_block(x, 128, stride=2, conv_shortcut=True, name='resblock2_1')\n",
    "    x = residual_block(x, 128, name='resblock2_2')\n",
    "    \n",
    "    x = residual_block(x, 256, stride=2, conv_shortcut=True, name='resblock3_1')\n",
    "    x = residual_block(x, 256, name='resblock3_2')\n",
    "    \n",
    "    # 全局平均池化\n",
    "    x = GlobalAveragePooling1D(name='global_avg_pool')(x)\n",
    "    \n",
    "    # 分类头\n",
    "    x = Dense(512, activation='relu', name='fc1')(x)\n",
    "    x = Dropout(0.5, name='dropout1')(x)\n",
    "    outputs = Dense(num_classes, activation='softmax', name='classification')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(\n",
    "        optimizer=Adam(1e-3),\n",
    "        loss=SparseCategoricalCrossentropy(),\n",
    "        metrics=[SparseCategoricalAccuracy()]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# ---------- 加载数据集 ----------\n",
    "def load_dataset(npz_path):\n",
    "    \"\"\"加载数据集并处理键名差异\"\"\"\n",
    "    data = np.load(npz_path, allow_pickle=True)\n",
    "    \n",
    "    # 基础数据\n",
    "    dataset = {\n",
    "        \"signals\": data[\"signals\"],\n",
    "        \"labels\": data[\"labels\"].astype(np.int32),\n",
    "        \"jnr_values\": data[\"jnr_values\"].astype(np.float32),\n",
    "        \"fs\": float(data[\"fs\"]),\n",
    "        \"L\": int(data[\"L\"])\n",
    "    }\n",
    "    \n",
    "    # 处理干扰类型名称\n",
    "    if \"interference_type_names\" in data:\n",
    "        type_names = data[\"interference_type_names\"].item() if isinstance(data[\"interference_type_names\"], np.ndarray) else data[\"interference_type_names\"]\n",
    "    else:\n",
    "        type_names = {\n",
    "            \"satellite_signal\": \"Satellite_Signal\",\n",
    "            \"single_tone\": \"Single_Tone\",\n",
    "            \"comb_spectra\": \"Comb_Spectra\",\n",
    "            \"sweeping\": \"Sweeping-LFM\",\n",
    "            \"pulse\": \"Pulse\",\n",
    "            \"frequency_hopping\": \"Frequency_Hopping\",\n",
    "            \"noise_fm\": \"Noise_FM\",\n",
    "            \"noise_am\": \"Noise_AM\",\n",
    "            \"random_combination\": \"Random_Combination\"\n",
    "        }\n",
    "    \n",
    "    # 创建标签映射\n",
    "    if \"type_to_label\" in data:\n",
    "        type2label = data[\"type_to_label\"].item() if isinstance(data[\"type_to_label\"], np.ndarray) else data[\"type_to_label\"]\n",
    "    else:\n",
    "        type2label = {\n",
    "            \"satellite_signal\": 0,\n",
    "            \"single_tone\": 1,\n",
    "            \"comb_spectra\": 2,\n",
    "            \"sweeping\": 3,\n",
    "            \"pulse\": 4,\n",
    "            \"frequency_hopping\": 5,\n",
    "            \"noise_fm\": 6,\n",
    "            \"noise_am\": 7,\n",
    "            \"random_combination\": 8\n",
    "        }\n",
    "    \n",
    "    label2name = {int(i): str(type_names[k]) for k, i in type2label.items()}\n",
    "    \n",
    "    dataset.update({\n",
    "        \"type2label\": type2label,\n",
    "        \"label2name\": label2name\n",
    "    })\n",
    "    return dataset\n",
    "\n",
    "# ---------- 数据预处理 ----------\n",
    "def preprocess_data(dataset):\n",
    "    \"\"\"预处理数据（仅分类任务）\"\"\"\n",
    "    # 信号标准化\n",
    "    signals = np.array([StandardScaler().fit_transform(s.reshape(-1, 1)).ravel() \n",
    "                       for s in dataset[\"signals\"]])\n",
    "    \n",
    "    # 数据集分割（保持分层抽样）\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        signals, dataset[\"labels\"],\n",
    "        test_size=0.3, random_state=42, \n",
    "        stratify=dataset[\"labels\"]\n",
    "    )\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_test, y_test,\n",
    "        test_size=0.5, random_state=42,\n",
    "        stratify=y_test\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"X_train\": X_train, \"X_val\": X_val, \"X_test\": X_test,\n",
    "        \"y_train\": y_train, \"y_val\": y_val, \"y_test\": y_test,\n",
    "        \"label2name\": dataset[\"label2name\"],\n",
    "        \"L\": dataset[\"L\"]\n",
    "    }\n",
    "\n",
    "# ---------- 数据增强 ----------\n",
    "@tf.function\n",
    "def aug_fn(x):\n",
    "    \"\"\"信号增强函数\"\"\"\n",
    "    x = tf.cast(x, tf.float32)\n",
    "    if tf.random.uniform([]) > 0.2:\n",
    "        snr = tf.random.uniform([], 5., 25.)\n",
    "        noise = tf.random.normal(tf.shape(x)) * tf.math.reduce_std(x) * 10.0**(-snr/20.0)\n",
    "        x = x + noise\n",
    "    if tf.random.uniform([]) > 0.3:\n",
    "        shift = tf.random.uniform([], -100, 100, dtype=tf.int32)\n",
    "        x = tf.roll(x, shift=shift, axis=0)\n",
    "    if tf.random.uniform([]) > 0.3:\n",
    "        scale = tf.random.uniform([], 0.7, 1.3)\n",
    "        x = x * scale\n",
    "    return x\n",
    "\n",
    "# ---------- 训练单个模型 ----------\n",
    "def train_single_model(data, model_idx=0, epochs=120, batch=128):\n",
    "    \"\"\"训练单个ResNet分类模型\"\"\"\n",
    "    model = build_resnet((data[\"L\"],), len(data[\"label2name\"]))\n",
    "    \n",
    "    # 类别权重（处理不平衡）\n",
    "    cls_weights = compute_class_weight('balanced', \n",
    "                                     classes=np.unique(data['y_train']), \n",
    "                                     y=data['y_train'])\n",
    "    sample_weights = np.array([cls_weights[lab] for lab in data['y_train']])\n",
    "    \n",
    "    # 数据管道\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "        (data['X_train'], data['y_train'], sample_weights)\n",
    "    )\n",
    "    train_ds = train_ds.map(lambda x, y, w: (aug_fn(x), y, w))\n",
    "    train_ds = train_ds.shuffle(10000).batch(batch).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    val_ds = tf.data.Dataset.from_tensor_slices(\n",
    "        (data['X_val'], data['y_val'])\n",
    "    ).batch(batch).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    # 回调函数\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    ckpt = f\"models/resnet_classifier_{model_idx}.keras\"\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_sparse_categorical_accuracy', patience=20, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_sparse_categorical_accuracy', factor=0.5, patience=10),\n",
    "        ModelCheckpoint(ckpt, save_best_only=True, monitor='val_sparse_categorical_accuracy')\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\n🔥 训练ResNet模型 {model_idx + 1}...\")\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# ---------- 主函数 ----------\n",
    "def main():\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    os.makedirs(\"visualizations\", exist_ok=True)\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"🚀 开始训练ResNet干扰分类模型\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # 加载数据\n",
    "    print(\"⏳ 加载数据集...\")\n",
    "    dataset = load_dataset(\"/root/yxun/20250826/dataset/interference_signals_natural_same_freq_1019.npz\")\n",
    "    data = preprocess_data(dataset)\n",
    "    \n",
    "    # 训练参数\n",
    "    n_models = 3\n",
    "    epochs = 120\n",
    "    batch_size = 128\n",
    "\n",
    "    # 训练模型\n",
    "    model = train_single_model(data, model_idx=0, epochs=epochs, batch=batch_size)\n",
    "    \n",
    "    # 评估测试集\n",
    "    test_loss, test_acc = model.evaluate(data['X_test'], data['y_test'], verbose=0)\n",
    "    print(f\"\\n📊 测试集准确率: {test_acc:.4f}\")\n",
    "    \n",
    "    # 保存最终模型\n",
    "    model.save(\"models/resnet_classifier_final.keras\")\n",
    "    print(\"\\n✅ 训练完成！模型已保存至 models/resnet_classifier_final.keras\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b0394cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 成功设置中文字体: ['WenQuanYi Micro Hei']\n",
      "================================================================================\n",
      "🚀 ResNet干扰分类模型评估\n",
      "================================================================================\n",
      "⏳ 加载数据集...\n",
      "⏳ 加载模型...\n",
      "✅ 成功加载模型: models/resnet_classifier_final.keras\n",
      "⏳ 进行预测...\n",
      "2532/2532 [==============================] - 13s 5ms/step\n",
      "⏳ 计算各JNR下的准确率...\n",
      "⏳ 生成混淆矩阵...\n",
      "⏳ 生成JNR准确率曲线...\n",
      "⏳ 生成评估报告...\n",
      "\n",
      "==================================================\n",
      "📊 评估结果摘要\n",
      "==================================================\n",
      "整体分类准确率: 0.8979\n",
      "\n",
      "各JNR下的分类准确率:\n",
      "  JNR=-10dB: 0.6414\n",
      "  JNR=-5dB: 0.7700\n",
      "  JNR=0dB: 0.8640\n",
      "  JNR=5dB: 0.9216\n",
      "  JNR=10dB: 0.9456\n",
      "  JNR=15dB: 0.9739\n",
      "  JNR=20dB: 0.9872\n",
      "  JNR=25dB: 0.9883\n",
      "  JNR=30dB: 0.9893\n",
      "\n",
      "✅ 评估完成！结果已保存至 reports/resnet_evaluation_report.json\n"
     ]
    }
   ],
   "source": [
    "# evaluate_resnet_classifier.py\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (accuracy_score, confusion_matrix, \n",
    "                           classification_report)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# ---------- 中文字体设置 ----------\n",
    "def set_chinese_font():\n",
    "    \"\"\"安全设置中文字体\"\"\"\n",
    "    try:\n",
    "        font_paths = ['/usr/share/fonts/truetype/wqy/wqy-microhei.ttc',\n",
    "                     'C:/Windows/Fonts/simhei.ttf',\n",
    "                     '/System/Library/Fonts/PingFang.ttc']\n",
    "        for path in font_paths:\n",
    "            if os.path.exists(path):\n",
    "                fm.fontManager.addfont(path)\n",
    "                plt.rcParams['font.family'] = fm.FontProperties(fname=path).get_name()\n",
    "                plt.rcParams['axes.unicode_minus'] = False\n",
    "                print(f\"✅ 成功设置中文字体: {plt.rcParams['font.family']}\")\n",
    "                return True\n",
    "        plt.rcParams['font.family'] = ['SimHei', 'Arial Unicode MS']\n",
    "        plt.rcParams['axes.unicode_minus'] = False\n",
    "        print(\"⚠️ 使用系统默认中文字体\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 字体设置失败: {e}\")\n",
    "        return False\n",
    "set_chinese_font()\n",
    "\n",
    "# ---------- 加载数据集 ----------\n",
    "def load_dataset(npz_path):\n",
    "    \"\"\"加载数据集并处理键名差异\"\"\"\n",
    "    data = np.load(npz_path, allow_pickle=True)\n",
    "    \n",
    "    # 基础数据\n",
    "    dataset = {\n",
    "        \"signals\": data[\"signals\"],\n",
    "        \"labels\": data[\"labels\"].astype(np.int32),\n",
    "        \"jnr_values\": data[\"jnr_values\"].astype(np.float32),\n",
    "        \"fs\": float(data[\"fs\"]),\n",
    "        \"L\": int(data[\"L\"])\n",
    "    }\n",
    "    \n",
    "    # 处理干扰类型名称\n",
    "    if \"interference_type_names\" in data:\n",
    "        type_names = data[\"interference_type_names\"].item() if isinstance(data[\"interference_type_names\"], np.ndarray) else data[\"interference_type_names\"]\n",
    "    else:\n",
    "        type_names = {\n",
    "            \"satellite_signal\": \"Satellite_Signal\",\n",
    "            \"single_tone\": \"Single_Tone\",\n",
    "            \"comb_spectra\": \"Comb_Spectra\",\n",
    "            \"sweeping\": \"Sweeping-LFM\",\n",
    "            \"pulse\": \"Pulse\",\n",
    "            \"frequency_hopping\": \"Frequency_Hopping\",\n",
    "            \"noise_fm\": \"Noise_FM\",\n",
    "            \"noise_am\": \"Noise_AM\",\n",
    "            \"random_combination\": \"Random_Combination\"\n",
    "        }\n",
    "        print(\"⚠️ 未找到干扰类型名称，使用默认值\")\n",
    "    \n",
    "    # 创建标签映射\n",
    "    if \"type_to_label\" in data:\n",
    "        type2label = data[\"type_to_label\"].item() if isinstance(data[\"type_to_label\"], np.ndarray) else data[\"type_to_label\"]\n",
    "    else:\n",
    "        type2label = {\n",
    "            \"satellite_signal\": 0,\n",
    "            \"single_tone\": 1,\n",
    "            \"comb_spectra\": 2,\n",
    "            \"sweeping\": 3,\n",
    "            \"pulse\": 4,\n",
    "            \"frequency_hopping\": 5,\n",
    "            \"noise_fm\": 6,\n",
    "            \"noise_am\": 7,\n",
    "            \"random_combination\": 8\n",
    "        }\n",
    "    \n",
    "    label2name = {int(i): str(type_names[k]) for k, i in type2label.items()}\n",
    "    \n",
    "    return {\n",
    "        \"signals\": data[\"signals\"],\n",
    "        \"labels\": data[\"labels\"].astype(np.int32),\n",
    "        \"jnr_values\": data[\"jnr_values\"].astype(np.float32),\n",
    "        \"label2name\": label2name,\n",
    "        \"L\": int(data[\"L\"])\n",
    "    }\n",
    "\n",
    "# ---------- 数据预处理 ----------\n",
    "def preprocess_data(dataset):\n",
    "    \"\"\"预处理数据\"\"\"\n",
    "    # 信号标准化\n",
    "    signals = np.array([StandardScaler().fit_transform(s.reshape(-1, 1)).ravel() \n",
    "                       for s in dataset[\"signals\"]])\n",
    "    \n",
    "    return signals, dataset[\"labels\"], dataset[\"jnr_values\"], dataset[\"label2name\"]\n",
    "\n",
    "# ---------- 加载模型 ----------\n",
    "def load_model(model_path):\n",
    "    \"\"\"加载训练好的ResNet模型\"\"\"\n",
    "    if os.path.exists(model_path):\n",
    "        try:\n",
    "            model = tf.keras.models.load_model(model_path)\n",
    "            print(f\"✅ 成功加载模型: {model_path}\")\n",
    "            return model\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 加载模型失败: {e}\")\n",
    "            return None\n",
    "    print(f\"⚠️ 未找到模型: {model_path}\")\n",
    "    return None\n",
    "\n",
    "# ---------- 计算JNR准确率 ----------\n",
    "def calculate_jnr_accuracy(y_true, y_pred, jnr_values, jnr_range):\n",
    "    \"\"\"计算每个JNR下的分类准确率\"\"\"\n",
    "    jnr_acc = {}\n",
    "    for jnr in jnr_range:\n",
    "        mask = jnr_values == jnr\n",
    "        if np.sum(mask) > 0:\n",
    "            jnr_acc[jnr] = accuracy_score(y_true[mask], y_pred[mask])\n",
    "        else:\n",
    "            jnr_acc[jnr] = np.nan\n",
    "    return jnr_acc\n",
    "\n",
    "# ---------------------- 绘制混淆矩阵 ----------------------\n",
    "def plot_confusion_matrix(cm, labels, title, xlabel, ylabel, filename, dpi=150, rotate_x=False):\n",
    "    \"\"\"专业混淆矩阵可视化\"\"\"\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
    "    cm_normalized = np.nan_to_num(cm_normalized)\n",
    "\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    ax = sns.heatmap(cm_normalized,\n",
    "                     annot=True,\n",
    "                     fmt='.2f',\n",
    "                     cmap='Blues',\n",
    "                     xticklabels=labels,\n",
    "                     yticklabels=labels,\n",
    "                     square=True,\n",
    "                     annot_kws={\"size\": 14})\n",
    "    cbar = ax.collections[0].colorbar\n",
    "    cbar.ax.tick_params(labelsize=14)\n",
    "\n",
    "    plt.title(title, pad=20, fontsize=18)\n",
    "    plt.xlabel(xlabel, fontsize=16)\n",
    "    plt.ylabel(ylabel, fontsize=16)\n",
    "    plt.xticks(rotation=45 if rotate_x else 0, ha='right' if rotate_x else 'center', fontsize=14)\n",
    "    plt.yticks(rotation=0, fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, dpi=dpi)\n",
    "    plt.close()\n",
    "\n",
    "# ---------- 绘制JNR准确率曲线 ----------\n",
    "def plot_jnr_accuracy(jnr_acc, filename):\n",
    "    \"\"\"绘制JNR-准确率曲线\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    valid_jnr = [j for j in jnr_acc if not np.isnan(jnr_acc[j])]\n",
    "    valid_acc = [jnr_acc[j] for j in valid_jnr]\n",
    "    \n",
    "    plt.plot(valid_jnr, valid_acc, 'o-', linewidth=2, markersize=8)\n",
    "    plt.xlabel('JNR (dB)', fontsize=12)\n",
    "    plt.ylabel('分类准确率', fontsize=12)\n",
    "    plt.title('不同JNR下的干扰识别准确率', fontsize=14)\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.xticks(list(jnr_acc.keys()))\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.savefig(filename, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "# ---------- 主评估函数 ----------\n",
    "def evaluate(model_path=\"models/resnet_classifier_final.keras\", \n",
    "             npz_path=\"/path/to/dataset.npz\"):\n",
    "    \"\"\"主评估流程\"\"\"\n",
    "    os.makedirs(\"visualizations\", exist_ok=True)\n",
    "    os.makedirs(\"reports\", exist_ok=True)\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"🚀 ResNet干扰分类模型评估\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # 1. 加载数据\n",
    "    print(\"⏳ 加载数据集...\")\n",
    "    dataset = load_dataset(npz_path)\n",
    "    X_test, y_test, jnr_test, label2name = preprocess_data(dataset)\n",
    "    \n",
    "    # 2. 加载模型\n",
    "    print(\"⏳ 加载模型...\")\n",
    "    model = load_model(model_path)\n",
    "    if not model:\n",
    "        print(\"❌ 评估终止：无法加载模型\")\n",
    "        return\n",
    "    \n",
    "    # 3. 预测\n",
    "    print(\"⏳ 进行预测...\")\n",
    "    y_pred = np.argmax(model.predict(X_test, verbose=1), axis=1)\n",
    "    \n",
    "    # 4. 计算JNR准确率\n",
    "    print(\"⏳ 计算各JNR下的准确率...\")\n",
    "    jnr_range = np.arange(-10, 31, 5)  # [-10, -5, 0, 5, ..., 30]\n",
    "    jnr_acc = calculate_jnr_accuracy(y_test, y_pred, jnr_test, jnr_range)\n",
    "    \n",
    "    # 5. 生成混淆矩阵\n",
    "    print(\"⏳ 生成混淆矩阵...\")\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    class_names = [label2name[i] for i in sorted(label2name.keys())]\n",
    "    plot_confusion_matrix(\n",
    "        cm=cm,\n",
    "        labels=class_names,\n",
    "        title=\"ResNet Classfication Confusion Matrix\",\n",
    "        xlabel=\"Predicted\",\n",
    "        ylabel=\"True\",\n",
    "        filename=\"visualizations/ResNet_confusion_matrix.png\",\n",
    "        dpi=300,\n",
    "        rotate_x=True\n",
    "    )\n",
    "    \n",
    "    # 6. 绘制JNR准确率曲线\n",
    "    print(\"⏳ 生成JNR准确率曲线...\")\n",
    "    plot_jnr_accuracy(jnr_acc, \"visualizations/resnet_jnr_accuracy.png\")\n",
    "    \n",
    "    # 7. 保存评估报告\n",
    "    print(\"⏳ 生成评估报告...\")\n",
    "    report = {\n",
    "        \"overall_accuracy\": float(accuracy_score(y_test, y_pred)),\n",
    "        \"jnr_accuracy\": {int(j): float(acc) if not np.isnan(acc) else None \n",
    "                         for j, acc in jnr_acc.items()},\n",
    "        \"confusion_matrix\": cm.tolist(),\n",
    "        \"class_names\": class_names,\n",
    "        \"classification_report\": classification_report(\n",
    "            y_test, y_pred, \n",
    "            target_names=class_names,\n",
    "            output_dict=True\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    with open(\"reports/resnet_evaluation_report.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(report, f, indent=4, ensure_ascii=False)\n",
    "    \n",
    "    # 8. 打印结果\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"📊 评估结果摘要\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"整体分类准确率: {report['overall_accuracy']:.4f}\")\n",
    "    \n",
    "    print(\"\\n各JNR下的分类准确率:\")\n",
    "    for jnr in sorted(jnr_acc.keys()):\n",
    "        acc = jnr_acc[jnr]\n",
    "        acc_str = f\"{acc:.4f}\" if not np.isnan(acc) else \"N/A\"\n",
    "        print(f\"  JNR={jnr}dB: {acc_str}\")\n",
    "    \n",
    "    print(\"\\n✅ 评估完成！结果已保存至 reports/resnet_evaluation_report.json\")\n",
    "\n",
    "# ---------- 主程序 ----------\n",
    "if __name__ == \"__main__\":\n",
    "    evaluate(\n",
    "        model_path=\"models/resnet_classifier_final.keras\",\n",
    "        npz_path=\"/root/yxun/20250826/dataset/interference_signals_natural_same_freq_1019.npz\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01aeae90",
   "metadata": {},
   "source": [
    "🚀 ResNet干扰分类模型评估\n",
    "整体分类准确率: 0.8979\n",
    "\n",
    "各JNR下的分类准确率:\n",
    "  JNR=-10dB: 0.6414\n",
    "  JNR=-5dB: 0.7702\n",
    "  JNR=0dB: 0.8639\n",
    "  JNR=5dB: 0.9216\n",
    "  JNR=10dB: 0.9456\n",
    "  JNR=15dB: 0.9739\n",
    "  JNR=20dB: 0.9872\n",
    "  JNR=25dB: 0.9883\n",
    "  JNR=30dB: 0.9893"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
