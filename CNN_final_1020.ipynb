{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d583876-3dc0-429c-b990-384da1b79d99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 16:37:30.690459: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-21 16:37:30.731162: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-21 16:37:31.300378: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 成功设置中文字体: ['WenQuanYi Micro Hei']\n",
      "================================================================================\n",
      "🚀 开始训练CNN干扰分类模型\n",
      "================================================================================\n",
      "⏳ 加载数据集...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 16:37:50.868823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44081 MB memory:  -> device: 0, name: NVIDIA vGPU-48GB, pci bus id: 0000:b8:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔥 训练CNN分类模型 1...\n",
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 16:37:52.534501: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int32 and shape [56700]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2025-10-21 16:37:52.534731: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype double and shape [56700]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2025-10-21 16:37:54.726106: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2025-10-21 16:37:54.926029: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-10-21 16:37:54.951294: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f13e6988510 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-10-21 16:37:54.951311: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA vGPU-48GB, Compute Capability 8.9\n",
      "2025-10-21 16:37:54.955011: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-10-21 16:37:55.068485: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "443/443 [==============================] - ETA: 0s - loss: 1.1929 - sparse_categorical_accuracy: 0.5499"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 16:38:03.604008: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int32 and shape [12150]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "443/443 [==============================] - 12s 18ms/step - loss: 1.1929 - sparse_categorical_accuracy: 0.5499 - val_loss: 1.0328 - val_sparse_categorical_accuracy: 0.5697 - lr: 0.0010\n",
      "Epoch 2/120\n",
      "443/443 [==============================] - 7s 14ms/step - loss: 0.9522 - sparse_categorical_accuracy: 0.6271 - val_loss: 0.8418 - val_sparse_categorical_accuracy: 0.6677 - lr: 0.0010\n",
      "Epoch 3/120\n",
      "443/443 [==============================] - 6s 12ms/step - loss: 0.8889 - sparse_categorical_accuracy: 0.6533 - val_loss: 0.7957 - val_sparse_categorical_accuracy: 0.6960 - lr: 0.0010\n",
      "Epoch 4/120\n",
      "443/443 [==============================] - 8s 14ms/step - loss: 0.8374 - sparse_categorical_accuracy: 0.6725 - val_loss: 0.7384 - val_sparse_categorical_accuracy: 0.7151 - lr: 0.0010\n",
      "Epoch 5/120\n",
      "443/443 [==============================] - 8s 16ms/step - loss: 0.8066 - sparse_categorical_accuracy: 0.6827 - val_loss: 0.7256 - val_sparse_categorical_accuracy: 0.7145 - lr: 0.0010\n",
      "Epoch 6/120\n",
      "443/443 [==============================] - 8s 15ms/step - loss: 0.7838 - sparse_categorical_accuracy: 0.6935 - val_loss: 0.6948 - val_sparse_categorical_accuracy: 0.7263 - lr: 0.0010\n",
      "Epoch 7/120\n",
      "443/443 [==============================] - 8s 15ms/step - loss: 0.7574 - sparse_categorical_accuracy: 0.7047 - val_loss: 0.7175 - val_sparse_categorical_accuracy: 0.7347 - lr: 0.0010\n",
      "Epoch 8/120\n",
      "443/443 [==============================] - 8s 15ms/step - loss: 0.7448 - sparse_categorical_accuracy: 0.7131 - val_loss: 0.7471 - val_sparse_categorical_accuracy: 0.7109 - lr: 0.0010\n",
      "Epoch 9/120\n",
      "443/443 [==============================] - 8s 16ms/step - loss: 0.7252 - sparse_categorical_accuracy: 0.7184 - val_loss: 0.6432 - val_sparse_categorical_accuracy: 0.7458 - lr: 0.0010\n",
      "Epoch 10/120\n",
      "443/443 [==============================] - 8s 15ms/step - loss: 0.7171 - sparse_categorical_accuracy: 0.7214 - val_loss: 0.6289 - val_sparse_categorical_accuracy: 0.7496 - lr: 0.0010\n",
      "Epoch 11/120\n",
      "443/443 [==============================] - 6s 12ms/step - loss: 0.7088 - sparse_categorical_accuracy: 0.7228 - val_loss: 0.6442 - val_sparse_categorical_accuracy: 0.7426 - lr: 0.0010\n",
      "Epoch 12/120\n",
      "443/443 [==============================] - 8s 16ms/step - loss: 0.6938 - sparse_categorical_accuracy: 0.7309 - val_loss: 0.6263 - val_sparse_categorical_accuracy: 0.7481 - lr: 0.0010\n",
      "Epoch 13/120\n",
      "443/443 [==============================] - 8s 17ms/step - loss: 0.6858 - sparse_categorical_accuracy: 0.7340 - val_loss: 0.6002 - val_sparse_categorical_accuracy: 0.7604 - lr: 0.0010\n",
      "Epoch 14/120\n",
      "443/443 [==============================] - 7s 13ms/step - loss: 0.6785 - sparse_categorical_accuracy: 0.7377 - val_loss: 0.6142 - val_sparse_categorical_accuracy: 0.7565 - lr: 0.0010\n",
      "Epoch 15/120\n",
      "443/443 [==============================] - 8s 16ms/step - loss: 0.6734 - sparse_categorical_accuracy: 0.7417 - val_loss: 0.6433 - val_sparse_categorical_accuracy: 0.7495 - lr: 0.0010\n",
      "Epoch 16/120\n",
      "443/443 [==============================] - 8s 15ms/step - loss: 0.6718 - sparse_categorical_accuracy: 0.7403 - val_loss: 0.5744 - val_sparse_categorical_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 17/120\n",
      "443/443 [==============================] - 8s 16ms/step - loss: 0.6657 - sparse_categorical_accuracy: 0.7437 - val_loss: 0.6146 - val_sparse_categorical_accuracy: 0.7620 - lr: 0.0010\n",
      "Epoch 18/120\n",
      "443/443 [==============================] - 7s 14ms/step - loss: 0.6609 - sparse_categorical_accuracy: 0.7439 - val_loss: 0.5802 - val_sparse_categorical_accuracy: 0.7755 - lr: 0.0010\n",
      "Epoch 19/120\n",
      "443/443 [==============================] - 8s 16ms/step - loss: 0.6498 - sparse_categorical_accuracy: 0.7480 - val_loss: 0.5867 - val_sparse_categorical_accuracy: 0.7676 - lr: 0.0010\n",
      "Epoch 20/120\n",
      "443/443 [==============================] - 8s 16ms/step - loss: 0.6499 - sparse_categorical_accuracy: 0.7500 - val_loss: 0.5816 - val_sparse_categorical_accuracy: 0.7773 - lr: 0.0010\n",
      "Epoch 21/120\n",
      "443/443 [==============================] - 8s 16ms/step - loss: 0.6419 - sparse_categorical_accuracy: 0.7502 - val_loss: 0.5960 - val_sparse_categorical_accuracy: 0.7714 - lr: 0.0010\n",
      "Epoch 22/120\n",
      "443/443 [==============================] - 6s 11ms/step - loss: 0.6381 - sparse_categorical_accuracy: 0.7544 - val_loss: 0.5498 - val_sparse_categorical_accuracy: 0.7824 - lr: 0.0010\n",
      "Epoch 23/120\n",
      "443/443 [==============================] - 8s 16ms/step - loss: 0.6352 - sparse_categorical_accuracy: 0.7546 - val_loss: 0.6131 - val_sparse_categorical_accuracy: 0.7613 - lr: 0.0010\n",
      "Epoch 24/120\n",
      "443/443 [==============================] - 7s 15ms/step - loss: 0.6323 - sparse_categorical_accuracy: 0.7561 - val_loss: 0.5691 - val_sparse_categorical_accuracy: 0.7784 - lr: 0.0010\n",
      "Epoch 25/120\n",
      "443/443 [==============================] - 8s 15ms/step - loss: 0.6259 - sparse_categorical_accuracy: 0.7578 - val_loss: 0.5489 - val_sparse_categorical_accuracy: 0.7856 - lr: 0.0010\n",
      "Epoch 26/120\n",
      "443/443 [==============================] - 8s 16ms/step - loss: 0.6252 - sparse_categorical_accuracy: 0.7558 - val_loss: 0.5664 - val_sparse_categorical_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 27/120\n",
      "443/443 [==============================] - 8s 16ms/step - loss: 0.6255 - sparse_categorical_accuracy: 0.7569 - val_loss: 0.6067 - val_sparse_categorical_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 28/120\n",
      "443/443 [==============================] - 7s 15ms/step - loss: 0.6165 - sparse_categorical_accuracy: 0.7617 - val_loss: 0.5757 - val_sparse_categorical_accuracy: 0.7763 - lr: 0.0010\n",
      "Epoch 29/120\n",
      "443/443 [==============================] - 8s 16ms/step - loss: 0.6147 - sparse_categorical_accuracy: 0.7620 - val_loss: 0.5243 - val_sparse_categorical_accuracy: 0.7984 - lr: 0.0010\n",
      "Epoch 30/120\n",
      "443/443 [==============================] - 7s 14ms/step - loss: 0.6131 - sparse_categorical_accuracy: 0.7628 - val_loss: 0.5809 - val_sparse_categorical_accuracy: 0.7723 - lr: 0.0010\n",
      "Epoch 31/120\n",
      "443/443 [==============================] - 7s 14ms/step - loss: 0.6101 - sparse_categorical_accuracy: 0.7632 - val_loss: 0.5558 - val_sparse_categorical_accuracy: 0.7881 - lr: 0.0010\n",
      "Epoch 32/120\n",
      "443/443 [==============================] - 8s 15ms/step - loss: 0.6066 - sparse_categorical_accuracy: 0.7651 - val_loss: 0.5188 - val_sparse_categorical_accuracy: 0.7981 - lr: 0.0010\n",
      "Epoch 33/120\n",
      "443/443 [==============================] - 9s 17ms/step - loss: 0.6028 - sparse_categorical_accuracy: 0.7677 - val_loss: 0.5885 - val_sparse_categorical_accuracy: 0.7752 - lr: 0.0010\n",
      "Epoch 34/120\n",
      "443/443 [==============================] - 6s 12ms/step - loss: 0.6081 - sparse_categorical_accuracy: 0.7645 - val_loss: 0.5252 - val_sparse_categorical_accuracy: 0.7971 - lr: 0.0010\n",
      "Epoch 35/120\n",
      "443/443 [==============================] - 7s 12ms/step - loss: 0.6026 - sparse_categorical_accuracy: 0.7649 - val_loss: 0.5992 - val_sparse_categorical_accuracy: 0.7674 - lr: 0.0010\n",
      "Epoch 36/120\n",
      "443/443 [==============================] - 8s 16ms/step - loss: 0.6014 - sparse_categorical_accuracy: 0.7688 - val_loss: 0.5779 - val_sparse_categorical_accuracy: 0.7812 - lr: 0.0010\n",
      "Epoch 37/120\n",
      "443/443 [==============================] - 9s 17ms/step - loss: 0.5991 - sparse_categorical_accuracy: 0.7679 - val_loss: 0.5243 - val_sparse_categorical_accuracy: 0.8019 - lr: 0.0010\n",
      "Epoch 38/120\n",
      "443/443 [==============================] - 6s 12ms/step - loss: 0.5924 - sparse_categorical_accuracy: 0.7696 - val_loss: 0.5097 - val_sparse_categorical_accuracy: 0.8040 - lr: 0.0010\n",
      "Epoch 39/120\n",
      "443/443 [==============================] - 8s 16ms/step - loss: 0.5921 - sparse_categorical_accuracy: 0.7702 - val_loss: 0.5537 - val_sparse_categorical_accuracy: 0.7919 - lr: 0.0010\n",
      "Epoch 40/120\n",
      "443/443 [==============================] - 8s 15ms/step - loss: 0.5886 - sparse_categorical_accuracy: 0.7729 - val_loss: 0.5108 - val_sparse_categorical_accuracy: 0.8037 - lr: 0.0010\n",
      "Epoch 41/120\n",
      "443/443 [==============================] - 6s 13ms/step - loss: 0.5907 - sparse_categorical_accuracy: 0.7699 - val_loss: 0.5352 - val_sparse_categorical_accuracy: 0.7938 - lr: 0.0010\n",
      "Epoch 42/120\n",
      "443/443 [==============================] - 8s 16ms/step - loss: 0.5888 - sparse_categorical_accuracy: 0.7715 - val_loss: 0.5427 - val_sparse_categorical_accuracy: 0.7932 - lr: 0.0010\n",
      "Epoch 43/120\n",
      "443/443 [==============================] - 8s 15ms/step - loss: 0.5886 - sparse_categorical_accuracy: 0.7718 - val_loss: 0.5016 - val_sparse_categorical_accuracy: 0.8077 - lr: 0.0010\n",
      "Epoch 44/120\n",
      "443/443 [==============================] - 7s 14ms/step - loss: 0.5845 - sparse_categorical_accuracy: 0.7749 - val_loss: 0.5176 - val_sparse_categorical_accuracy: 0.8007 - lr: 0.0010\n",
      "Epoch 45/120\n",
      "443/443 [==============================] - 7s 14ms/step - loss: 0.5871 - sparse_categorical_accuracy: 0.7738 - val_loss: 0.5775 - val_sparse_categorical_accuracy: 0.7754 - lr: 0.0010\n",
      "Epoch 46/120\n",
      "443/443 [==============================] - 8s 16ms/step - loss: 0.5813 - sparse_categorical_accuracy: 0.7728 - val_loss: 0.6956 - val_sparse_categorical_accuracy: 0.7402 - lr: 0.0010\n",
      "Epoch 47/120\n",
      "443/443 [==============================] - 8s 14ms/step - loss: 0.5767 - sparse_categorical_accuracy: 0.7753 - val_loss: 0.4854 - val_sparse_categorical_accuracy: 0.8135 - lr: 0.0010\n",
      "Epoch 48/120\n",
      "443/443 [==============================] - 7s 12ms/step - loss: 0.5763 - sparse_categorical_accuracy: 0.7765 - val_loss: 0.5327 - val_sparse_categorical_accuracy: 0.7964 - lr: 0.0010\n",
      "Epoch 49/120\n",
      "443/443 [==============================] - 8s 15ms/step - loss: 0.5723 - sparse_categorical_accuracy: 0.7775 - val_loss: 0.5417 - val_sparse_categorical_accuracy: 0.7904 - lr: 0.0010\n",
      "Epoch 50/120\n",
      "443/443 [==============================] - 7s 13ms/step - loss: 0.5770 - sparse_categorical_accuracy: 0.7767 - val_loss: 0.5179 - val_sparse_categorical_accuracy: 0.7996 - lr: 0.0010\n",
      "Epoch 51/120\n",
      "443/443 [==============================] - 8s 16ms/step - loss: 0.5752 - sparse_categorical_accuracy: 0.7754 - val_loss: 0.5022 - val_sparse_categorical_accuracy: 0.8053 - lr: 0.0010\n",
      "Epoch 52/120\n",
      "443/443 [==============================] - 8s 15ms/step - loss: 0.5732 - sparse_categorical_accuracy: 0.7778 - val_loss: 0.5192 - val_sparse_categorical_accuracy: 0.7967 - lr: 0.0010\n",
      "Epoch 53/120\n",
      "443/443 [==============================] - 8s 16ms/step - loss: 0.5720 - sparse_categorical_accuracy: 0.7778 - val_loss: 0.5263 - val_sparse_categorical_accuracy: 0.7974 - lr: 0.0010\n",
      "Epoch 54/120\n",
      "443/443 [==============================] - 8s 15ms/step - loss: 0.5744 - sparse_categorical_accuracy: 0.7754 - val_loss: 0.5059 - val_sparse_categorical_accuracy: 0.8040 - lr: 0.0010\n",
      "Epoch 55/120\n",
      "443/443 [==============================] - 8s 16ms/step - loss: 0.5713 - sparse_categorical_accuracy: 0.7754 - val_loss: 0.4986 - val_sparse_categorical_accuracy: 0.8095 - lr: 0.0010\n",
      "Epoch 56/120\n",
      "443/443 [==============================] - 5s 10ms/step - loss: 0.5642 - sparse_categorical_accuracy: 0.7783 - val_loss: 0.6459 - val_sparse_categorical_accuracy: 0.7571 - lr: 0.0010\n",
      "Epoch 57/120\n",
      "443/443 [==============================] - 8s 16ms/step - loss: 0.5671 - sparse_categorical_accuracy: 0.7787 - val_loss: 0.5462 - val_sparse_categorical_accuracy: 0.7912 - lr: 0.0010\n",
      "Epoch 58/120\n",
      "443/443 [==============================] - 8s 16ms/step - loss: 0.5540 - sparse_categorical_accuracy: 0.7843 - val_loss: 0.4976 - val_sparse_categorical_accuracy: 0.8134 - lr: 5.0000e-04\n",
      "Epoch 59/120\n",
      "443/443 [==============================] - 8s 16ms/step - loss: 0.5443 - sparse_categorical_accuracy: 0.7891 - val_loss: 0.4999 - val_sparse_categorical_accuracy: 0.8109 - lr: 5.0000e-04\n",
      "Epoch 60/120\n",
      "443/443 [==============================] - 8s 16ms/step - loss: 0.5470 - sparse_categorical_accuracy: 0.7876 - val_loss: 0.4741 - val_sparse_categorical_accuracy: 0.8182 - lr: 5.0000e-04\n",
      "Epoch 61/120\n",
      "443/443 [==============================] - 6s 12ms/step - loss: 0.5450 - sparse_categorical_accuracy: 0.7869 - val_loss: 0.4802 - val_sparse_categorical_accuracy: 0.8138 - lr: 5.0000e-04\n",
      "Epoch 62/120\n",
      "443/443 [==============================] - 8s 16ms/step - loss: 0.5413 - sparse_categorical_accuracy: 0.7887 - val_loss: 0.4822 - val_sparse_categorical_accuracy: 0.8137 - lr: 5.0000e-04\n",
      "Epoch 63/120\n",
      "443/443 [==============================] - 8s 16ms/step - loss: 0.5401 - sparse_categorical_accuracy: 0.7905 - val_loss: 0.4742 - val_sparse_categorical_accuracy: 0.8192 - lr: 5.0000e-04\n",
      "Epoch 64/120\n",
      "443/443 [==============================] - 8s 15ms/step - loss: 0.5402 - sparse_categorical_accuracy: 0.7899 - val_loss: 0.4715 - val_sparse_categorical_accuracy: 0.8187 - lr: 5.0000e-04\n",
      "Epoch 65/120\n",
      "443/443 [==============================] - 8s 17ms/step - loss: 0.5382 - sparse_categorical_accuracy: 0.7906 - val_loss: 0.4722 - val_sparse_categorical_accuracy: 0.8154 - lr: 5.0000e-04\n",
      "Epoch 66/120\n",
      "443/443 [==============================] - 8s 16ms/step - loss: 0.5411 - sparse_categorical_accuracy: 0.7881 - val_loss: 0.4674 - val_sparse_categorical_accuracy: 0.8183 - lr: 5.0000e-04\n",
      "Epoch 67/120\n",
      "443/443 [==============================] - 8s 16ms/step - loss: 0.5389 - sparse_categorical_accuracy: 0.7903 - val_loss: 0.4661 - val_sparse_categorical_accuracy: 0.8196 - lr: 5.0000e-04\n",
      "Epoch 68/120\n",
      "443/443 [==============================] - 8s 15ms/step - loss: 0.5382 - sparse_categorical_accuracy: 0.7883 - val_loss: 0.4656 - val_sparse_categorical_accuracy: 0.8214 - lr: 5.0000e-04\n",
      "Epoch 69/120\n",
      "443/443 [==============================] - 7s 14ms/step - loss: 0.5360 - sparse_categorical_accuracy: 0.7914 - val_loss: 0.4873 - val_sparse_categorical_accuracy: 0.8119 - lr: 5.0000e-04\n",
      "Epoch 70/120\n",
      "443/443 [==============================] - 8s 16ms/step - loss: 0.5382 - sparse_categorical_accuracy: 0.7903 - val_loss: 0.4755 - val_sparse_categorical_accuracy: 0.8178 - lr: 5.0000e-04\n",
      "Epoch 71/120\n",
      "443/443 [==============================] - 9s 17ms/step - loss: 0.5401 - sparse_categorical_accuracy: 0.7909 - val_loss: 0.4859 - val_sparse_categorical_accuracy: 0.8091 - lr: 5.0000e-04\n",
      "Epoch 72/120\n",
      "443/443 [==============================] - 8s 15ms/step - loss: 0.5357 - sparse_categorical_accuracy: 0.7920 - val_loss: 0.4822 - val_sparse_categorical_accuracy: 0.8147 - lr: 5.0000e-04\n",
      "Epoch 73/120\n",
      "443/443 [==============================] - 7s 14ms/step - loss: 0.5308 - sparse_categorical_accuracy: 0.7944 - val_loss: 0.4702 - val_sparse_categorical_accuracy: 0.8196 - lr: 5.0000e-04\n",
      "Epoch 74/120\n",
      "443/443 [==============================] - 7s 14ms/step - loss: 0.5326 - sparse_categorical_accuracy: 0.7929 - val_loss: 0.4713 - val_sparse_categorical_accuracy: 0.8168 - lr: 5.0000e-04\n",
      "Epoch 75/120\n",
      "443/443 [==============================] - 8s 16ms/step - loss: 0.5378 - sparse_categorical_accuracy: 0.7908 - val_loss: 0.4970 - val_sparse_categorical_accuracy: 0.8063 - lr: 5.0000e-04\n",
      "Epoch 76/120\n",
      "443/443 [==============================] - 8s 16ms/step - loss: 0.5348 - sparse_categorical_accuracy: 0.7909 - val_loss: 0.4699 - val_sparse_categorical_accuracy: 0.8207 - lr: 5.0000e-04\n",
      "Epoch 77/120\n",
      "443/443 [==============================] - 7s 15ms/step - loss: 0.5336 - sparse_categorical_accuracy: 0.7931 - val_loss: 0.4735 - val_sparse_categorical_accuracy: 0.8147 - lr: 5.0000e-04\n",
      "Epoch 78/120\n",
      "443/443 [==============================] - 8s 16ms/step - loss: 0.5309 - sparse_categorical_accuracy: 0.7933 - val_loss: 0.4729 - val_sparse_categorical_accuracy: 0.8180 - lr: 5.0000e-04\n",
      "Epoch 79/120\n",
      "443/443 [==============================] - 9s 17ms/step - loss: 0.5232 - sparse_categorical_accuracy: 0.7946 - val_loss: 0.4565 - val_sparse_categorical_accuracy: 0.8230 - lr: 2.5000e-04\n",
      "Epoch 80/120\n",
      "443/443 [==============================] - 8s 16ms/step - loss: 0.5228 - sparse_categorical_accuracy: 0.7944 - val_loss: 0.4547 - val_sparse_categorical_accuracy: 0.8223 - lr: 2.5000e-04\n",
      "Epoch 81/120\n",
      "443/443 [==============================] - 8s 16ms/step - loss: 0.5183 - sparse_categorical_accuracy: 0.7981 - val_loss: 0.4496 - val_sparse_categorical_accuracy: 0.8252 - lr: 2.5000e-04\n",
      "Epoch 82/120\n",
      "443/443 [==============================] - 8s 15ms/step - loss: 0.5199 - sparse_categorical_accuracy: 0.7973 - val_loss: 0.4569 - val_sparse_categorical_accuracy: 0.8224 - lr: 2.5000e-04\n",
      "Epoch 83/120\n",
      "443/443 [==============================] - 8s 15ms/step - loss: 0.5145 - sparse_categorical_accuracy: 0.7988 - val_loss: 0.4516 - val_sparse_categorical_accuracy: 0.8263 - lr: 2.5000e-04\n",
      "Epoch 84/120\n",
      "443/443 [==============================] - 8s 16ms/step - loss: 0.5170 - sparse_categorical_accuracy: 0.7988 - val_loss: 0.4572 - val_sparse_categorical_accuracy: 0.8194 - lr: 2.5000e-04\n",
      "Epoch 85/120\n",
      "443/443 [==============================] - 7s 14ms/step - loss: 0.5180 - sparse_categorical_accuracy: 0.7978 - val_loss: 0.4525 - val_sparse_categorical_accuracy: 0.8228 - lr: 2.5000e-04\n",
      "Epoch 86/120\n",
      "443/443 [==============================] - 8s 16ms/step - loss: 0.5156 - sparse_categorical_accuracy: 0.7985 - val_loss: 0.4497 - val_sparse_categorical_accuracy: 0.8274 - lr: 2.5000e-04\n",
      "Epoch 87/120\n",
      "443/443 [==============================] - 8s 16ms/step - loss: 0.5149 - sparse_categorical_accuracy: 0.7977 - val_loss: 0.4541 - val_sparse_categorical_accuracy: 0.8247 - lr: 2.5000e-04\n",
      "Epoch 88/120\n",
      "443/443 [==============================] - 7s 14ms/step - loss: 0.5150 - sparse_categorical_accuracy: 0.7991 - val_loss: 0.4527 - val_sparse_categorical_accuracy: 0.8252 - lr: 2.5000e-04\n",
      "Epoch 89/120\n",
      "443/443 [==============================] - 8s 16ms/step - loss: 0.5157 - sparse_categorical_accuracy: 0.7993 - val_loss: 0.4632 - val_sparse_categorical_accuracy: 0.8217 - lr: 2.5000e-04\n",
      "Epoch 90/120\n",
      "443/443 [==============================] - 8s 15ms/step - loss: 0.5137 - sparse_categorical_accuracy: 0.7996 - val_loss: 0.4587 - val_sparse_categorical_accuracy: 0.8244 - lr: 2.5000e-04\n",
      "Epoch 91/120\n",
      "443/443 [==============================] - 9s 16ms/step - loss: 0.5146 - sparse_categorical_accuracy: 0.7984 - val_loss: 0.4543 - val_sparse_categorical_accuracy: 0.8230 - lr: 2.5000e-04\n",
      "Epoch 92/120\n",
      "443/443 [==============================] - 7s 15ms/step - loss: 0.5148 - sparse_categorical_accuracy: 0.7975 - val_loss: 0.4677 - val_sparse_categorical_accuracy: 0.8173 - lr: 2.5000e-04\n",
      "Epoch 93/120\n",
      "443/443 [==============================] - 8s 16ms/step - loss: 0.5148 - sparse_categorical_accuracy: 0.7981 - val_loss: 0.4529 - val_sparse_categorical_accuracy: 0.8258 - lr: 2.5000e-04\n",
      "Epoch 94/120\n",
      "443/443 [==============================] - 6s 12ms/step - loss: 0.5172 - sparse_categorical_accuracy: 0.7987 - val_loss: 0.4539 - val_sparse_categorical_accuracy: 0.8253 - lr: 2.5000e-04\n",
      "Epoch 95/120\n",
      "443/443 [==============================] - 8s 16ms/step - loss: 0.5160 - sparse_categorical_accuracy: 0.8006 - val_loss: 0.4549 - val_sparse_categorical_accuracy: 0.8214 - lr: 2.5000e-04\n",
      "Epoch 96/120\n",
      "443/443 [==============================] - 7s 14ms/step - loss: 0.5111 - sparse_categorical_accuracy: 0.7983 - val_loss: 0.4518 - val_sparse_categorical_accuracy: 0.8260 - lr: 2.5000e-04\n",
      "Epoch 97/120\n",
      "443/443 [==============================] - 8s 15ms/step - loss: 0.5076 - sparse_categorical_accuracy: 0.8019 - val_loss: 0.4489 - val_sparse_categorical_accuracy: 0.8252 - lr: 1.2500e-04\n",
      "Epoch 98/120\n",
      "443/443 [==============================] - 8s 17ms/step - loss: 0.5068 - sparse_categorical_accuracy: 0.8015 - val_loss: 0.4440 - val_sparse_categorical_accuracy: 0.8276 - lr: 1.2500e-04\n",
      "Epoch 99/120\n",
      "443/443 [==============================] - 7s 13ms/step - loss: 0.5087 - sparse_categorical_accuracy: 0.8018 - val_loss: 0.4436 - val_sparse_categorical_accuracy: 0.8285 - lr: 1.2500e-04\n",
      "Epoch 100/120\n",
      "443/443 [==============================] - 8s 15ms/step - loss: 0.5089 - sparse_categorical_accuracy: 0.8005 - val_loss: 0.4447 - val_sparse_categorical_accuracy: 0.8296 - lr: 1.2500e-04\n",
      "Epoch 101/120\n",
      "443/443 [==============================] - 7s 14ms/step - loss: 0.5045 - sparse_categorical_accuracy: 0.8008 - val_loss: 0.4454 - val_sparse_categorical_accuracy: 0.8293 - lr: 1.2500e-04\n",
      "Epoch 102/120\n",
      "443/443 [==============================] - 7s 12ms/step - loss: 0.5096 - sparse_categorical_accuracy: 0.7998 - val_loss: 0.4483 - val_sparse_categorical_accuracy: 0.8256 - lr: 1.2500e-04\n",
      "Epoch 103/120\n",
      "443/443 [==============================] - 8s 15ms/step - loss: 0.5079 - sparse_categorical_accuracy: 0.8033 - val_loss: 0.4450 - val_sparse_categorical_accuracy: 0.8296 - lr: 1.2500e-04\n",
      "Epoch 104/120\n",
      "443/443 [==============================] - 6s 12ms/step - loss: 0.5091 - sparse_categorical_accuracy: 0.8014 - val_loss: 0.4441 - val_sparse_categorical_accuracy: 0.8272 - lr: 1.2500e-04\n",
      "Epoch 105/120\n",
      "443/443 [==============================] - 8s 15ms/step - loss: 0.5036 - sparse_categorical_accuracy: 0.8022 - val_loss: 0.4466 - val_sparse_categorical_accuracy: 0.8254 - lr: 1.2500e-04\n",
      "Epoch 106/120\n",
      "443/443 [==============================] - 7s 13ms/step - loss: 0.5061 - sparse_categorical_accuracy: 0.8009 - val_loss: 0.4441 - val_sparse_categorical_accuracy: 0.8280 - lr: 1.2500e-04\n",
      "Epoch 107/120\n",
      "443/443 [==============================] - 8s 15ms/step - loss: 0.5066 - sparse_categorical_accuracy: 0.8009 - val_loss: 0.4426 - val_sparse_categorical_accuracy: 0.8281 - lr: 1.2500e-04\n",
      "Epoch 108/120\n",
      "443/443 [==============================] - 8s 15ms/step - loss: 0.5018 - sparse_categorical_accuracy: 0.8043 - val_loss: 0.4455 - val_sparse_categorical_accuracy: 0.8255 - lr: 1.2500e-04\n",
      "Epoch 109/120\n",
      "443/443 [==============================] - 7s 14ms/step - loss: 0.5068 - sparse_categorical_accuracy: 0.8020 - val_loss: 0.4424 - val_sparse_categorical_accuracy: 0.8304 - lr: 1.2500e-04\n",
      "Epoch 110/120\n",
      "443/443 [==============================] - 7s 13ms/step - loss: 0.5045 - sparse_categorical_accuracy: 0.8031 - val_loss: 0.4409 - val_sparse_categorical_accuracy: 0.8314 - lr: 1.2500e-04\n",
      "Epoch 111/120\n",
      "443/443 [==============================] - 8s 15ms/step - loss: 0.5024 - sparse_categorical_accuracy: 0.8050 - val_loss: 0.4453 - val_sparse_categorical_accuracy: 0.8283 - lr: 1.2500e-04\n",
      "Epoch 112/120\n",
      "443/443 [==============================] - 8s 16ms/step - loss: 0.5040 - sparse_categorical_accuracy: 0.8017 - val_loss: 0.4449 - val_sparse_categorical_accuracy: 0.8282 - lr: 1.2500e-04\n",
      "Epoch 113/120\n",
      "443/443 [==============================] - 8s 16ms/step - loss: 0.5070 - sparse_categorical_accuracy: 0.8007 - val_loss: 0.4439 - val_sparse_categorical_accuracy: 0.8295 - lr: 1.2500e-04\n",
      "Epoch 114/120\n",
      "443/443 [==============================] - 8s 16ms/step - loss: 0.5041 - sparse_categorical_accuracy: 0.8029 - val_loss: 0.4440 - val_sparse_categorical_accuracy: 0.8300 - lr: 1.2500e-04\n",
      "Epoch 115/120\n",
      "443/443 [==============================] - 8s 16ms/step - loss: 0.5045 - sparse_categorical_accuracy: 0.8023 - val_loss: 0.4429 - val_sparse_categorical_accuracy: 0.8303 - lr: 1.2500e-04\n",
      "Epoch 116/120\n",
      "443/443 [==============================] - 6s 12ms/step - loss: 0.5038 - sparse_categorical_accuracy: 0.8037 - val_loss: 0.4418 - val_sparse_categorical_accuracy: 0.8308 - lr: 1.2500e-04\n",
      "Epoch 117/120\n",
      "443/443 [==============================] - 8s 16ms/step - loss: 0.5000 - sparse_categorical_accuracy: 0.8039 - val_loss: 0.4425 - val_sparse_categorical_accuracy: 0.8286 - lr: 1.2500e-04\n",
      "Epoch 118/120\n",
      "443/443 [==============================] - 7s 14ms/step - loss: 0.5046 - sparse_categorical_accuracy: 0.8030 - val_loss: 0.4430 - val_sparse_categorical_accuracy: 0.8277 - lr: 1.2500e-04\n",
      "Epoch 119/120\n",
      "443/443 [==============================] - 7s 14ms/step - loss: 0.5052 - sparse_categorical_accuracy: 0.8034 - val_loss: 0.4514 - val_sparse_categorical_accuracy: 0.8234 - lr: 1.2500e-04\n",
      "Epoch 120/120\n",
      "443/443 [==============================] - 6s 12ms/step - loss: 0.5065 - sparse_categorical_accuracy: 0.8017 - val_loss: 0.4429 - val_sparse_categorical_accuracy: 0.8298 - lr: 1.2500e-04\n",
      "✅ 模型训练完成，耗时 921.25 秒\n",
      "\n",
      "📊 测试集准确率: 0.8282\n",
      "\n",
      "✅ 训练完成！模型已保存至 models/cnn_classifier_final.keras\n"
     ]
    }
   ],
   "source": [
    "# train_cnn_classifier.py\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Conv1D, MaxPooling1D,\n",
    "                                     Dense, Dropout, BatchNormalization,\n",
    "                                     Reshape, GlobalAveragePooling1D)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import (EarlyStopping, ReduceLROnPlateau, \n",
    "                                      ModelCheckpoint)\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# ---------- 中文字体设置 ----------\n",
    "def set_chinese_font():\n",
    "    \"\"\"安全设置中文字体\"\"\"\n",
    "    try:\n",
    "        font_paths = ['/usr/share/fonts/truetype/wqy/wqy-microhei.ttc',\n",
    "                     'C:/Windows/Fonts/simhei.ttf',\n",
    "                     '/System/Library/Fonts/PingFang.ttc']\n",
    "        for path in font_paths:\n",
    "            if os.path.exists(path):\n",
    "                fm.fontManager.addfont(path)\n",
    "                plt.rcParams['font.family'] = fm.FontProperties(fname=path).get_name()\n",
    "                plt.rcParams['axes.unicode_minus'] = False\n",
    "                print(f\"✅ 成功设置中文字体: {plt.rcParams['font.family']}\")\n",
    "                return True\n",
    "        plt.rcParams['font.family'] = ['SimHei', 'Arial Unicode MS']\n",
    "        plt.rcParams['axes.unicode_minus'] = False\n",
    "        print(\"⚠️ 使用系统默认中文字体\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 字体设置失败: {e}\")\n",
    "        return False\n",
    "set_chinese_font()\n",
    "\n",
    "# ---------- 加载数据集 ----------\n",
    "def load_dataset(npz_path):\n",
    "    \"\"\"加载数据集（保持原结构）\"\"\"\n",
    "    data = np.load(npz_path, allow_pickle=True)\n",
    "    \n",
    "    # 基础数据\n",
    "    dataset = {\n",
    "        \"signals\": data[\"signals\"],\n",
    "        \"labels\": data[\"labels\"].astype(np.int32),\n",
    "        \"fs\": float(data[\"fs\"]),\n",
    "        \"L\": int(data[\"L\"])\n",
    "    }\n",
    "    \n",
    "    # 处理干扰类型名称\n",
    "    if \"interference_type_names\" in data:\n",
    "        type_names = data[\"interference_type_names\"].item() if isinstance(data[\"interference_type_names\"], np.ndarray) else data[\"interference_type_names\"]\n",
    "    else:\n",
    "        type_names = {\n",
    "            \"satellite_signal\": \"Satellite_Signal\",\n",
    "            \"single_tone\": \"Single_Tone\",\n",
    "            \"comb_spectra\": \"Comb_Spectra\",\n",
    "            \"sweeping\": \"Sweeping-LFM\",\n",
    "            \"pulse\": \"Pulse\",\n",
    "            \"frequency_hopping\": \"Frequency_Hopping\",\n",
    "            \"noise_fm\": \"Noise_FM\",\n",
    "            \"noise_am\": \"Noise_AM\",\n",
    "            \"random_combination\": \"Random_Combination\"\n",
    "        }\n",
    "        print(\"⚠️ 未找到干扰类型名称，使用默认值\")\n",
    "    \n",
    "    # 创建标签映射\n",
    "    if \"type_to_label\" in data:\n",
    "        type2label = data[\"type_to_label\"].item() if isinstance(data[\"type_to_label\"], np.ndarray) else data[\"type_to_label\"]\n",
    "    else:\n",
    "        type2label = {\n",
    "            \"satellite_signal\": 0,\n",
    "            \"single_tone\": 1,\n",
    "            \"comb_spectra\": 2,\n",
    "            \"sweeping\": 3,\n",
    "            \"pulse\": 4,\n",
    "            \"frequency_hopping\": 5,\n",
    "            \"noise_fm\": 6,\n",
    "            \"noise_am\": 7,\n",
    "            \"random_combination\": 8\n",
    "        }\n",
    "    \n",
    "    label2name = {i: type_names[k] for k, i in type2label.items()}\n",
    "    \n",
    "    dataset.update({\n",
    "        \"type2label\": type2label,\n",
    "        \"label2name\": label2name\n",
    "    })\n",
    "    return dataset\n",
    "\n",
    "# ---------- 数据预处理 ----------\n",
    "def preprocess_data(dataset):\n",
    "    \"\"\"预处理数据（仅分类任务）\"\"\"\n",
    "    # 信号标准化\n",
    "    signals = np.array([StandardScaler().fit_transform(s.reshape(-1, 1)).ravel() \n",
    "                       for s in dataset[\"signals\"]])\n",
    "    \n",
    "    # 数据集分割（保持分层抽样）\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        signals, dataset[\"labels\"],\n",
    "        test_size=0.3, random_state=42, \n",
    "        stratify=dataset[\"labels\"]\n",
    "    )\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_test, y_test,\n",
    "        test_size=0.5, random_state=42,\n",
    "        stratify=y_test\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"X_train\": X_train, \"X_val\": X_val, \"X_test\": X_test,\n",
    "        \"y_train\": y_train, \"y_val\": y_val, \"y_test\": y_test,\n",
    "        \"label2name\": dataset[\"label2name\"],\n",
    "        \"L\": dataset[\"L\"]\n",
    "    }\n",
    "\n",
    "# ---------- CNN分类模型 ----------\n",
    "def build_cnn_model(input_shape, num_classes):\n",
    "    \"\"\"构建纯CNN分类模型\"\"\"\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Reshape((input_shape[0], 1))(inputs)  # [batch, length, 1]\n",
    "    \n",
    "    # CNN特征提取\n",
    "    x = Conv1D(32, 7, activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    \n",
    "    x = Conv1D(64, 5, activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    \n",
    "    x = Conv1D(128, 3, activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    \n",
    "    # 全局特征\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    \n",
    "    # 分类头\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(\n",
    "        optimizer=Adam(1e-3),\n",
    "        loss=SparseCategoricalCrossentropy(),\n",
    "        metrics=[SparseCategoricalAccuracy()]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# ---------- 数据增强 ----------\n",
    "@tf.function\n",
    "def aug_fn(x):\n",
    "    \"\"\"信号增强\"\"\"\n",
    "    x = tf.cast(x, tf.float32)\n",
    "    if tf.random.uniform([]) > 0.2:\n",
    "        snr = tf.random.uniform([], 5., 25.)\n",
    "        noise = tf.random.normal(tf.shape(x)) * tf.math.reduce_std(x) * 10.0**(-snr/20.0)\n",
    "        x = x + noise\n",
    "    if tf.random.uniform([]) > 0.3:\n",
    "        shift = tf.random.uniform([], -100, 100, dtype=tf.int32)\n",
    "        x = tf.roll(x, shift=shift, axis=0)\n",
    "    if tf.random.uniform([]) > 0.3:\n",
    "        scale = tf.random.uniform([], 0.7, 1.3)\n",
    "        x = x * scale\n",
    "    return x\n",
    "\n",
    "# ---------- 训练单个模型 ----------\n",
    "def train_single_model(data, model_idx=0, epochs=120, batch=128):\n",
    "    \"\"\"训练单个CNN分类模型\"\"\"\n",
    "    model = build_cnn_model((data[\"L\"],), len(data[\"label2name\"]))\n",
    "    \n",
    "    # 类别权重（处理不平衡）\n",
    "    cls_weights = compute_class_weight('balanced', \n",
    "                                     classes=np.unique(data['y_train']), \n",
    "                                     y=data['y_train'])\n",
    "    sample_weights = np.array([cls_weights[lab] for lab in data['y_train']])\n",
    "    \n",
    "    # 数据管道\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "        (data['X_train'], data['y_train'], sample_weights)\n",
    "    )\n",
    "    train_ds = train_ds.map(lambda x, y, w: (aug_fn(x), y, w))\n",
    "    train_ds = train_ds.shuffle(10000).batch(batch).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    val_ds = tf.data.Dataset.from_tensor_slices(\n",
    "        (data['X_val'], data['y_val'])\n",
    "    ).batch(batch).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    # 回调函数\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    ckpt = f\"models/cnn_classifier_{model_idx}.keras\"\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_sparse_categorical_accuracy', patience=20, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_sparse_categorical_accuracy', factor=0.5, patience=10),\n",
    "        ModelCheckpoint(ckpt, save_best_only=True, monitor='val_sparse_categorical_accuracy')\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\n🔥 训练CNN分类模型 {model_idx + 1}...\")\n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    print(f\"✅ 模型训练完成，耗时 {training_time:.2f} 秒\")\n",
    "    \n",
    "    return model, training_time\n",
    "\n",
    "# ---------- 主函数 ----------\n",
    "def main():\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    os.makedirs(\"visualizations\", exist_ok=True)\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"🚀 开始训练CNN干扰分类模型\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # 加载数据\n",
    "    print(\"⏳ 加载数据集...\")\n",
    "    dataset = load_dataset(\"/root/yxun/20250826/dataset/interference_signals_natural_same_freq_1019.npz\")\n",
    "    data = preprocess_data(dataset)\n",
    "\n",
    "    # 训练参数\n",
    "    n_models = 1  # 训练单个模型（如需集成可改为3）\n",
    "    epochs = 120\n",
    "    batch_size = 128\n",
    "\n",
    "    # 训练模型\n",
    "    model, training_time = train_single_model(data, model_idx=0, epochs=epochs, batch=batch_size)\n",
    "\n",
    "    # 评估测试集\n",
    "    test_loss, test_acc = model.evaluate(data['X_test'], data['y_test'], verbose=0)\n",
    "    print(f\"\\n📊 测试集准确率: {test_acc:.4f}\")\n",
    "\n",
    "    # 保存模型\n",
    "    model.save(\"models/cnn_classifier_final.keras\")\n",
    "    print(\"\\n✅ 训练完成！模型已保存至 models/cnn_classifier_final.keras\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c37dc184-e9b8-411e-b764-0bd750f10ac7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 成功设置中文字体: ['WenQuanYi Micro Hei']\n",
      "⏳ 加载数据集...\n",
      "⏳ 加载模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 23:09:21.703594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 895 MB memory:  -> device: 0, name: NVIDIA vGPU-48GB, pci bus id: 0000:d8:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 成功加载模型: models/cnn_classifier_final.keras\n",
      "⏳ 进行预测...\n",
      "  1/760 [..............................] - ETA: 4:22"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 23:09:22.123736: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2025-10-21 23:09:22.276764: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 2s 2ms/step\n",
      "⏳ 生成混淆矩阵...\n",
      "⏳ 生成JNR准确率曲线...\n",
      "⏳ 生成评估报告...\n",
      "\n",
      "==================================================\n",
      "📊 评估结果摘要\n",
      "==================================================\n",
      "整体分类准确率: 0.8269\n",
      "\n",
      "各JNR下的分类准确率:\n",
      "  JNR=-10dB: 0.4066\n",
      "  JNR=-5dB: 0.5908\n",
      "  JNR=0dB: 0.7669\n",
      "  JNR=5dB: 0.8595\n",
      "  JNR=10dB: 0.9250\n",
      "  JNR=15dB: 0.9587\n",
      "  JNR=20dB: 0.9777\n",
      "  JNR=25dB: 0.9781\n",
      "  JNR=30dB: 0.9738\n",
      "\n",
      "✅ 评估完成！结果已保存至 reports/cnn_classification_report.json\n"
     ]
    }
   ],
   "source": [
    "# evaluate_cnn_classifier.py\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (accuracy_score, confusion_matrix, \n",
    "                            classification_report)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split \n",
    "import matplotlib.font_manager as fm\n",
    "# ---------- 中文字体设置 ----------\n",
    "def set_chinese_font():\n",
    "    \"\"\"安全设置中文字体\"\"\"\n",
    "    try:\n",
    "        font_paths = ['/usr/share/fonts/truetype/wqy/wqy-microhei.ttc',\n",
    "                     'C:/Windows/Fonts/simhei.ttf',\n",
    "                     '/System/Library/Fonts/PingFang.ttc']\n",
    "        for path in font_paths:\n",
    "            if os.path.exists(path):\n",
    "                fm.fontManager.addfont(path)\n",
    "                plt.rcParams['font.family'] = fm.FontProperties(fname=path).get_name()\n",
    "                plt.rcParams['axes.unicode_minus'] = False\n",
    "                print(f\"✅ 成功设置中文字体: {plt.rcParams['font.family']}\")\n",
    "                return True\n",
    "        plt.rcParams['font.family'] = ['SimHei', 'Arial Unicode MS']\n",
    "        plt.rcParams['axes.unicode_minus'] = False\n",
    "        print(\"⚠️ 使用系统默认中文字体\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 字体设置失败: {e}\")\n",
    "        return False\n",
    "set_chinese_font()\n",
    "\n",
    "# ---------- 加载数据集 ----------\n",
    "def load_dataset(npz_path):\n",
    "    \"\"\"加载并处理数据集\"\"\"\n",
    "    data = np.load(npz_path, allow_pickle=True)\n",
    "    \n",
    "    # 基础数据\n",
    "    dataset = {\n",
    "        \"signals\": data[\"signals\"],\n",
    "        \"labels\": data[\"labels\"].astype(np.int32),\n",
    "        \"jnr_values\": data[\"jnr_values\"].astype(np.float32),\n",
    "        \"fs\": float(data[\"fs\"]),\n",
    "        \"L\": int(data[\"L\"])\n",
    "    }\n",
    "    \n",
    "    # 处理干扰类型名称\n",
    "    if \"interference_type_names\" in data:\n",
    "        type_names = data[\"interference_type_names\"].item() if isinstance(data[\"interference_type_names\"], np.ndarray) else data[\"interference_type_names\"]\n",
    "    else:\n",
    "        type_names = {\n",
    "            \"satellite_signal\": \"Satellite_Signal\",\n",
    "            \"single_tone\": \"Single_Tone\",\n",
    "            \"comb_spectra\": \"Comb_Spectra\",\n",
    "            \"sweeping\": \"Sweeping-LFM\",\n",
    "            \"pulse\": \"Pulse\",\n",
    "            \"frequency_hopping\": \"Frequency_Hopping\",\n",
    "            \"noise_fm\": \"Noise_FM\",\n",
    "            \"noise_am\": \"Noise_AM\",\n",
    "            \"random_combination\": \"Random_Combination\"\n",
    "        }\n",
    "        print(\"⚠️ 未找到干扰类型名称，使用默认值\")\n",
    "    \n",
    "    # 创建标签映射\n",
    "    if \"type_to_label\" in data:\n",
    "        type2label = data[\"type_to_label\"].item() if isinstance(data[\"type_to_label\"], np.ndarray) else data[\"type_to_label\"]\n",
    "        label2name = {int(i): str(type_names[k]) for k, i in type2label.items()}\n",
    "    else:\n",
    "        type2label = {\n",
    "            \"satellite_signal\": 0,\n",
    "            \"single_tone\": 1,\n",
    "            \"comb_spectra\": 2,\n",
    "            \"sweeping\": 3,\n",
    "            \"pulse\": 4,\n",
    "            \"frequency_hopping\": 5,\n",
    "            \"noise_fm\": 6,\n",
    "            \"noise_am\": 7,\n",
    "            \"random_combination\": 8\n",
    "        }\n",
    "        label2name = {int(i): str(type_names[k]) for k, i in type2label.items()}\n",
    "    \n",
    "    dataset.update({\n",
    "        \"type2label\": type2label,\n",
    "        \"label2name\": label2name\n",
    "    })\n",
    "    return dataset\n",
    "\n",
    "# ---------- 数据预处理 ----------\n",
    "def preprocess_data(dataset):\n",
    "    \"\"\"预处理数据\"\"\"\n",
    "    # 信号标准化\n",
    "    signals = np.array([StandardScaler().fit_transform(s.reshape(-1, 1)).ravel() \n",
    "                       for s in dataset[\"signals\"]])\n",
    "    \n",
    "    # 数据集分割\n",
    "    X_train, X_test, y_train, y_test, jnr_train, jnr_test = train_test_split(\n",
    "        signals, dataset[\"labels\"], dataset[\"jnr_values\"],\n",
    "        test_size=0.3, random_state=42, stratify=dataset[\"labels\"]\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"X_test\": X_test,\n",
    "        \"y_test\": y_test,\n",
    "        \"jnr_test\": jnr_test,\n",
    "        \"label2name\": dataset[\"label2name\"]\n",
    "    }\n",
    "\n",
    "# ---------- 加载模型 ----------\n",
    "def load_model(model_path):\n",
    "    \"\"\"加载训练好的CNN模型\"\"\"\n",
    "    if os.path.exists(model_path):\n",
    "        try:\n",
    "            model = tf.keras.models.load_model(model_path)\n",
    "            print(f\"✅ 成功加载模型: {model_path}\")\n",
    "            return model\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 加载模型失败: {e}\")\n",
    "            return None\n",
    "    print(f\"⚠️ 未找到模型: {model_path}\")\n",
    "    return None\n",
    "\n",
    "# ---------- 计算JNR准确率 ----------\n",
    "def calculate_jnr_accuracy(y_true, y_pred, jnr_values, jnr_range):\n",
    "    \"\"\"计算每个JNR下的分类准确率\"\"\"\n",
    "    jnr_acc = {}\n",
    "    for jnr in jnr_range:\n",
    "        mask = jnr_values == jnr\n",
    "        if np.sum(mask) > 0:\n",
    "            jnr_acc[jnr] = accuracy_score(y_true[mask], y_pred[mask])\n",
    "        else:\n",
    "            jnr_acc[jnr] = np.nan\n",
    "    return jnr_acc\n",
    "\n",
    "# ---------------------- 绘制混淆矩阵 ----------------------\n",
    "def plot_confusion_matrix(cm, labels, title, xlabel, ylabel, filename, dpi=150, rotate_x=False):\n",
    "    \"\"\"专业混淆矩阵可视化\"\"\"\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
    "    cm_normalized = np.nan_to_num(cm_normalized)\n",
    "\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    ax = sns.heatmap(cm_normalized,\n",
    "                     annot=True,\n",
    "                     fmt='.2f',\n",
    "                     cmap='Blues',\n",
    "                     xticklabels=labels,\n",
    "                     yticklabels=labels,\n",
    "                     square=True,\n",
    "                     annot_kws={\"size\": 14})\n",
    "    cbar = ax.collections[0].colorbar\n",
    "    cbar.ax.tick_params(labelsize=14)\n",
    "\n",
    "    plt.title(title, pad=20, fontsize=18)\n",
    "    plt.xlabel(xlabel, fontsize=16)\n",
    "    plt.ylabel(ylabel, fontsize=16)\n",
    "    plt.xticks(rotation=45 if rotate_x else 0, \n",
    "               ha='right' if rotate_x else 'center', \n",
    "               fontsize=14)\n",
    "    plt.yticks(rotation=0, fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, dpi=dpi)\n",
    "    plt.close()\n",
    "\n",
    "# ---------- 绘制JNR准确率曲线 ----------\n",
    "def plot_jnr_accuracy(jnr_acc, filename):\n",
    "    \"\"\"绘制JNR-准确率曲线\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    valid_jnr = [j for j in jnr_acc if not np.isnan(jnr_acc[j])]\n",
    "    valid_acc = [jnr_acc[j] for j in valid_jnr]\n",
    "    \n",
    "    plt.plot(valid_jnr, valid_acc, 'o-', linewidth=2, markersize=8)\n",
    "    plt.xlabel('JNR (dB)', fontsize=12)\n",
    "    plt.ylabel('分类准确率', fontsize=12)\n",
    "    plt.title('不同JNR下的干扰识别准确率', fontsize=14)\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.xticks(list(jnr_acc.keys()))\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.savefig(filename, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "# ---------- 主评估函数 ----------\n",
    "def evaluate(model_path=\"models/cnn_classifier_final.keras\", \n",
    "             npz_path=\"/root/yxun/20250826/dataset/interference_signals_natural_same_freq_1019.npz\"):\n",
    "    \"\"\"主评估流程\"\"\"\n",
    "    os.makedirs(\"visualizations\", exist_ok=True)\n",
    "    os.makedirs(\"reports\", exist_ok=True)\n",
    "    \n",
    "    # 1. 加载数据\n",
    "    print(\"⏳ 加载数据集...\")\n",
    "    dataset = load_dataset(npz_path)\n",
    "    data = preprocess_data(dataset)\n",
    "    \n",
    "    # 2. 加载模型\n",
    "    print(\"⏳ 加载模型...\")\n",
    "    model = load_model(model_path)\n",
    "    if model is None:\n",
    "        print(\"❌ 无法加载模型，评估终止\")\n",
    "        return\n",
    "    \n",
    "    # 3. 预测\n",
    "    print(\"⏳ 进行预测...\")\n",
    "    y_pred = np.argmax(model.predict(data[\"X_test\"], verbose=1), axis=1)\n",
    "    \n",
    "    # 4. 计算JNR准确率\n",
    "    jnr_range = np.arange(-10, 31, 5)  # [-10, -5, 0, 5, ..., 30]\n",
    "    jnr_acc = calculate_jnr_accuracy(data[\"y_test\"], y_pred, data[\"jnr_test\"], jnr_range)\n",
    "    \n",
    "    # 5. 生成混淆矩阵\n",
    "    print(\"⏳ 生成混淆矩阵...\")\n",
    "    cm = confusion_matrix(data[\"y_test\"], y_pred)\n",
    "    class_names = [data[\"label2name\"][i] for i in sorted(data[\"label2name\"].keys())]\n",
    "    plot_confusion_matrix(\n",
    "        cm=cm,\n",
    "        labels=class_names,\n",
    "        title=\"CNN Classification Confusion Matrix\",\n",
    "        xlabel=\"Predicted\",\n",
    "        ylabel=\"True\",\n",
    "        filename=\"visualizations/cnn_confusion_matrix.png\",\n",
    "        dpi=300,\n",
    "        rotate_x=True\n",
    "    )\n",
    "    \n",
    "    # 6. 绘制JNR准确率曲线\n",
    "    print(\"⏳ 生成JNR准确率曲线...\")\n",
    "    plot_jnr_accuracy(jnr_acc, \"visualizations/cnn_jnr_accuracy.png\")\n",
    "    \n",
    "    # 7. 保存评估报告\n",
    "    print(\"⏳ 生成评估报告...\")\n",
    "    report = {\n",
    "        \"overall_accuracy\": float(accuracy_score(data[\"y_test\"], y_pred)),\n",
    "        \"jnr_accuracy\": {int(j): float(acc) if not np.isnan(acc) else None \n",
    "                         for j, acc in jnr_acc.items()},\n",
    "        \"confusion_matrix\": cm.tolist(),\n",
    "        \"class_names\": class_names,\n",
    "        \"classification_report\": classification_report(\n",
    "            data[\"y_test\"], y_pred, \n",
    "            target_names=class_names,\n",
    "            output_dict=True\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    with open(\"reports/cnn_classification_report.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(report, f, indent=4, ensure_ascii=False)\n",
    "    \n",
    "    # 8. 打印结果\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"📊 评估结果摘要\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"整体分类准确率: {report['overall_accuracy']:.4f}\")\n",
    "    \n",
    "    print(\"\\n各JNR下的分类准确率:\")\n",
    "    for jnr in sorted(jnr_acc.keys()):\n",
    "        acc = jnr_acc[jnr]\n",
    "        acc_str = f\"{acc:.4f}\" if not np.isnan(acc) else \"N/A\"\n",
    "        print(f\"  JNR={jnr}dB: {acc_str}\")\n",
    "    \n",
    "    print(\"\\n✅ 评估完成！结果已保存至 reports/cnn_classification_report.json\")\n",
    "\n",
    "# ---------- 主程序 ----------\n",
    "if __name__ == \"__main__\":\n",
    "    evaluate(\n",
    "        model_path=\"models/cnn_classifier_final.keras\",\n",
    "        npz_path=\"/root/yxun/20250826/dataset/interference_signals_natural_same_freq_1019.npz\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fc98bc",
   "metadata": {},
   "source": [
    "CNN整体分类准确率: 0.8269\n",
    "\n",
    "各JNR下的分类准确率:\n",
    "  JNR=-10dB: 0.4066\n",
    "  JNR=-5dB: 0.5908\n",
    "  JNR=0dB: 0.7669\n",
    "  JNR=5dB: 0.8595\n",
    "  JNR=10dB: 0.9250\n",
    "  JNR=15dB: 0.9587\n",
    "  JNR=20dB: 0.9777\n",
    "  JNR=25dB: 0.9781\n",
    "  JNR=30dB: 0.9738"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
